[{"categories":["Platform"],"content":"Canary Release dengan Traefik berbasis pembobotan round robin hingga mirroring traffic","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"Saat kita melakukan deployment aplikasi ke versi terbaru pada Kubernetes, mungkin muncul kecemasan akan adanya insiden tak terduga walaupun versi terbaru sudah lolos tahap testing. Guna mengurangi kemungkinan insiden dalam skala besar, kita dapat memakai skenario bernama Canary. ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:0:0","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"Canary Idiom Frasa Canary dalam deployment aplikasi berasal dari sejarah penambang batu bara di awal abad 20. Pekerja tambang membawa burung kenari dalam sangkar ke terowongan bawah tanah, sehingga ketika muncul gas berbahaya seperti karbon monoksida maka burung kenari akan mati dan menjadi peringatan bagi para pekerja untuk segera evakuasi. ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:1:0","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"Kubernetes’s Canary Fitur canary pada Kubernetes biasanya tersedia jika kita menggunakan solusi service mesh. Namun sebenarnya canary dapat diimplementasikan tanpanya. Sebagai contohnya adalah menggunakan Ingress Nginx, HAProxy Ingress, hingga Traefik. Jika tertarik, silahkan cari Kubernetes Ingress Controller lainnya yang mendukung fitur canary pada tabel berikut. ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:1:1","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"Traefik Traefik adalah Cloud Native Edge Router salah satu reverse proxy dan load balancer. Terlepas dari gimmick cloud-native, yang menjadikan Traefik berbeda dari Nginx, HAproxy, dan yang lain adalah tersedianya configurability secara otomatis dan dinamis. Bagian paling menonjol darinya mungkin adalah kemampuan automatic service discovery. Jika kita menggunakan Traefik di atas Docker, Kubernetes, atau bahkan cara lama seperti sekedar VM dan bare-metal untuk menjajakan service yang berjalan di dalamnya. Layaknya sulap, Traefik akan me-expose service tersebut ke dunia luar. Tentu jika kita mengikuti dokumentasi dengan benar. Traefik V2 ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:2:0","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"Prerequisites Untuk mempersingkat artikel ini, maka saya anggap beberapa hal ini sudah terpenuhi. Kubernetes cluster telah tersedia. Traefik sudah terpasang pada Kubernetes. Pemahaman mengenai Ingress, Service, dan Deployment pada Kubernetes. ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:3:0","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"Scenario ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:4:0","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"Tanpa Canary Existing release Pada contoh di atas, terlihat saya mempunyai sebuah service dengan aplikasi versi pertama yang anggaplah sudah mengudara dan menerima request dari user. Kurang lebih seperti inilah bagaimana service tersebut dapat berjalan. kubectl create deployment deployment-app-current --image=trianwar/hello-app:1.0 -n default kubectl expose deployment deployment-app-current --name service-app-current --type ClusterIP --port 8080 -n default Selanjutnya kita buat sebuah IngressRoute dengan Traefik. apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: ingressroute-app spec: entryPoints: - web routes: - kind: Rule match: Host(`app.minikube1.local`) services: - name: service-app-current namespace: default port: 8080 Simpan misalnya dengan nama ingressroute-app.yaml dan terapkan konfigurasi di atas kubectl create -f ingressroute-app.yam -n default Jika dilakukan request dengan curl maka akan menjawab seperti berikut. Trafik diarahkan ke versi aplikasi pertama Dari sini mari kita berasumsi bahwa aplikasi kita telah menerima aliran trafik sepenuhnya. Lalu suatu ketika saya ingin melakukan merilis versi aplikasi kedua. kubectl set image deployment/deployment-app-current hello-app=trianwar/hello-app:2.0 -n default kubectl rollout restart deployment/deployment-app-current -n default Kita dapat melakukan rolling release ke versi terbaru tanpa canary, yang hasilnya tentu saja trafik akan sepenuhnya dialirkan ke satu-satunya rilis yang tersedia yaitu misalkan versi 2.0.0 seperti berikut. Trafik diarahkan ke versi aplikasi kedua Perhatian Dari sini, lebih baiknya kita kembalikan image tag dari deployment-app-current ke versi 1.0.0 agar praktik selanjutnya sesuai dengan skenario. ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:4:1","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"Weighted Canary Alih - alih langsung mengganti rilis pertama ke versi terbaru sekaligus, di sini kita akan mendeploy aplikasi versi kedua sebagai rilisan baru. Dan selanjutnya kita manipulasi besaran traffic yang dialirkan. Weighted Canary Untuk menggunakan fitur canary kita perlu memisahkan rilis terbaru ke deployment dan service baru. Besar aliran trafik akan kita tentukan dengan pembobotan. Pada diagram di atas, terlihat bahwa 80% traffic akan diarahkan ke versi pertama, sisanya sebesar 20% diarahkan ke versi kedua. kubectl create deployment deployment-app-canary --image=trianwar/hello-app:2.0 -n default kubectl expose deployment deployment-app-canary --name service-app-canary --type ClusterIP --port 8080 -n default Kemudian modifikasi file manifest ingressroute-app.yaml tadi menjadi seperti berikut. apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: ingressroute-app spec: entryPoints: - web routes: - kind: Rule match: Host(`app.minikube1.local`) services: - name: service-app-current namespace: default port: 8080 weight: 80 - name: service-app-canary namespace: default port: 8080 weight: 20 Jangan lupa kita terapkan perubahannya. kubectl appy -f ingressroute-app.yaml Mari kita jalankan 100 request dengan menggunakan curl seperti berikut. for i in {1..100}; do curl -s app.minikube1.local | grep Version; done | sort | uniq -c Akan terhitung bahwa trafik sebanyak 80% dialirkan ke aplikasi versi pertama, dan sisanya 20% ke versi kedua. Weighted Canary Result ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:4:2","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"Canary by Header Semisal yang kita inginkan adalah melakukan canary namun bukan untuk end-user langsung, melainkan untuk kebutuhan testing. Traefik juga mendukung manipulasi trafik berdasarkan Request Header dengan menggunakan objek Middleware. Canary by Header Contoh file manifest untuk membuat middleware adalah sebagai berikut, simpan dengan nama misalnya middleware-app-canary.yaml. apiVersion: traefik.containo.us/v1alpha1 kind: Middleware metadata: name: middleware-app-canary spec: headers: customRequestHeaders: X-Canary: \"enabled\" Kemudian modifikasi file ingressroute-app.yaml tadi menjadi seperti di bawah ini. apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: ingressroute-app spec: entryPoints: - web routes: - kind: Rule match: Host(`app.minikube1.local`) services: - name: service-app-current namespace: default port: 8080 - kind: Rule match: Host(`app.minikube1.local`) \u0026\u0026 HeadersRegexp(`X-Canary`, `enabled`) services: - name: service-app-canary namespace: default port: 8080 Terapkan konfigurasi di atas pada Kubernetes. kubectl apply -f middleware-app-canary.yaml -f ingressroute-app.yaml -n default Sekarang mari kita lakukan pengujian dengan melakukan 10 request tanpa header, dan 10 request lagi dengan menggunakan header. Canary by Header result ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:4:3","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"Mirroring Sekenario lainnya yang disediakan adalah melakukan mirroring atau shadowing. Traffic Mirroring Selain dialirkan ke service - service canary tadi, Traefik juga dapat memanipulasi trafik yang lewat untuk menciptakan bayangannya, dan bayangan itu akan dialirkan ke service versi lain dengan persentase yang bisa ditentukan juga. kubectl create deployment deployment-app-mirror --image=trianwar/hello-app:3.0 -n default kubectl expose deployment deployment-app-mirror --name service-app-mirror --type ClusterIP --port 8080 -n default Modifikasi file ingressroute-app.yaml yang telah dibuat sebelumnya. apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: ingressroute-app spec: entryPoints: - web routes: - kind: Rule match: Host(`app.minikube1.local`) services: - name: mirroring-app namespace: default kind: TraefikService Untuk menerapkan mirroring, kita juga perlu membuat objek bertipe TraefikService (bukan kubernetes service, kali ini adalah Custom Resource Definition milik Traefik). apiVersion: traefik.containo.us/v1alpha1 kind: TraefikService metadata: name: canary-app namespace: default spec: weighted: services: - name: service-app-current port: 8080 weight: 80 - name: service-app-canary weight: 20 port: 8080 --- apiVersion: traefik.containo.us/v1alpha1 kind: TraefikService metadata: name: mirroring-app namespace: default spec: mirroring: name: canary-app kind: TraefikService mirrors: - name: service-app-mirror percent: 10 port: 8080 Simpan saja misalnya dengan nama traefikservice-app.yaml kemudian terapkan ke kubernetes. kubectl apply -f ingressroute-app.yaml -f traefikservice-app.yaml -n default Lalu kita uji dengan melakukan 10 kali request. for i in {1..10}; do curl -s app.minikube1.local | grep Version; done; kcmini logs $(kcmini get pods -l app=deployment-app-mirror -o name) Akan terlihat bahwa rilis versi pertama menerima 8 request, sedangkan sisanya sebanyak 2 request ditangani oleh rilis versi kedua. Sementara itu, traffic sebanyak 10% atau dalam kasus ini setara 1 request dibuat bayangannya dan dialirkan ke rilis mirror. Hasil Mirroring Dengan mirroring service akan menerima bayangan request dari user, aplikasi akan melayaninya. Namun user tidak akan menerima balikan dari service mirror karena traffic yang mengalir hanyalah sebuah request bayangan. ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:4:4","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"Advantages Beberapa manfaat yang kita peroleh dari penerapan canary dan traffic mirroring adalah sebagai berikut: Minimalisir resiko/insiden dari rilisan baru di environment production. Reduksi cost dan effort karena tidak perlu membangun cluster lain untuk environment pre-production. Mengalirkan sebagian kecil realtime traffic ke rilisan baru untuk testing. Mempercepat identifikasi terhadap Bug/Issue aplikasi. ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:5:0","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Platform"],"content":"References blog.scienceandindustrymuseum.org.uk/canary-resuscitator traefik.io/glossary/kubernetes-deployment-strategies-blue-green-canary doc.traefik.io/traefik/v2.4/routing/providers/kubernetes-crd/#custom-resource-definition-crd doc.traefik.io/traefik/middlewares/http/headers “Kubernetes Ingress Controllers” List by learnk8s ","date":"2022-06-26","objectID":"/canary-deployment-dan-mirroring-dengan-traefik/:6:0","tags":["Traefik","Ingress","Deployment","Kubernetes"],"title":"Canary Deployment dan Mirroring Dengan Traefik","uri":"/canary-deployment-dan-mirroring-dengan-traefik/"},{"categories":["Tools"],"content":"Use Ansible Playbook to setup a Gitlab Server","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Selain Gitlab SaaS yang biasa kita akses dari gitlab.com, kita membangun sebuah server Gitlab secara manual ataupun otomatis, salah satunya adalah menggunakan Ansible Playbook. Gitlab dapat di-install dengan beberapa metode seperti Docker dengan Docker Compose, Helm charts jika ingin berjalan di atas Kubernetes, Operator jika berjalan di atas OpenShift, hingga instalasi dari sourcecode untuk dapat berjalan di atas berbagai platform yang tidak didukung. Pada artikel kali ini saya akan menggunakan package official untuk distro Linux, dan sebagian besar proses akan dilakukan secara otomatis menggunakan Ansible. ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:0:0","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Outset Sekilas detail dari environment yang akan saya gunakan untuk instalasi Gitlab CE (Community Edition). ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:1:0","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Arsitektur Secara default Gitlab menyediakan semua komponen yang dibutuhkan dalam binary package nya, namun kita bisa juga menggunakan komponen eksternal jika dibutuhkan. Contohnya adalah database server dengan PostgreSQL, dan server LDAP yang akan diintegrasikan dengan server Gitlab. Dalam artikel ini, keseluruhan server yang saya punya adalah VM (Virtual Machine) dengan RHEL 7.7 Maipo. Managed Hosts +------------------------------------------+ | | | +------------+ | | | | | +--------+----+ GitLab | frontend.1238.internal | | | | Server | | | | | | | | | +------------+ | | | | | | +------------+ | | | | | | +--------+----+ PostgreSQL | appdb1.1238.internal | Controller Host | | | Server | | | | | | | +------------+ | | +------------+ | | | | | | | Bastion +-------+ | | | | | | | +------------+ | | +------------+ | | | | | | bastion.1238.internal | | | LDAP | app1.1238.internal | +--------+----+ Server | | | | | | | | | +------------+ | | | | | | +------------+ | | | | | | +--------+----+ GitLab | app2.1238.internal | | | Runner | | | | | | | +------------+ | | | +------------------------------------------+ ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:1:1","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Inventory Berikut ini adalah list server yang saya masukan ke dalam inventory untuk Ansible. [gitlab] frontend1.1238.internal [ldap] app1.1238.internal [runner] app2.1238.internal [db] appdb1.1238.internal [bastion] bastion.1238.internal [allserver:children] gitlab ldap runner db bastion [allserver:vars] timeout=60 ansible_user=ec2-user ansible_ssh_private_key_file=\"~/.ssh/1238key.pem\" ansible_ssh_common_args=\"-o StrictHostKeyChecking=no\" Pada umumnya kita semestinya sudah mempersiapkan sebuah dedicated user dengan kemampuan sudoers pada tiap server yang akan kita manage. Dalam kasus kali ini, saya menggunakan user bernama ec2-user dan dapat diakses melalui ssh secara passwordless. Untuk sudo juga sudah dikonfigurasi agar tidak perlu menginput password. ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:1:2","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Setup PostgreSQL Server Untuk database yang akan digunakan oleh server Gitlab, harus dikonfigurasi sesuai dengan requirements yang telah ditentukan di dokumentasi berikut. Berikut ini adalah beberapa hal yang mungkin perlu dicatat. ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:2:0","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"User Service Saya buat terlebih dahulu dedicated user untuk server appdb1.1238.internal yang akan kita gunakan khusus untuk mengakses service PostgreSQL. sudo useradd -s /usr/sbin/nologin -c 'GitLab' git echo 'rahasiabanget' | sudo passwd git --stdin ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:2:1","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Package Dependency Pada RHEL 7.7 atau CentOS 7.7 saya mendapati dependency dari package PostgreSQL yang tidak ada dalam official repository, yaitu llvm-toolset-7-clang di mana packge ini dapat kita dapatkan dari package SCLo RH repository bernama centos-release-scl-rh seperti berikut. curl -k -O http://mirror.centos.org/centos/7/extras/x86_64/Packages/centos-release-scl-rh-2-3.el7.centos.noarch.rpm sudo rpm -iv centos-release-scl-rh*.rpm Dan nantinya dependency akan dapat dipasang. ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:2:2","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Install Packages Kita akan langsung mengikuti panduan dari situs official PostgreSQL seperti berikut. sudo yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm sudo yum install -y postgresql12 postgresql12-contrib postgresql12-devel postgresql12-libs postgresql12-server ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:2:3","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Allow Remote Connection Karena service PostgreSQL akan diakses dari luar server appdb1.1238.internal maka kita perlu ubah konfigurasi file postgresql.conf milik PostgreSQL. sudo sed -i \"s/#listen_addresses = 'localhost'/listen_addresses = '*'/g\" $(sudo find / -name \"postgresql.conf\") Ada satu file lagi bernama pg_hba.conf yang perlu kita ubah. echo \"host all all 0.0.0.0/0 md5\" | sudo tee -a $(sudo find / -name \"pg_hba.conf\") ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:2:4","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Enable Service Sebelum menyalakan service kita perlu menginiasi terlebih dahulu. sudo postgresql-12-setup initdb Barulah kita bisa menyalakan servicenya. sudo systemctl enable --now postgresql-12 ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:2:5","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Create DB User Kita akan membuat user database yang akan digunakan oleh GitLab server. sudo -u postgres psql -d template1 -c \"CREATE USER git CREATEDB;\" sudo -u postgres psql -U postgres Lalu set password baru untuk user database yang baru kita buat. ALTER USER git with password 'rahasiabanget'; \\q Jangan lupa untuk restart service. sudo systemctl restart postgresql-12 ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:2:6","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Create DB and Extensions Ada beberapa extension yang perlu kita buat sesuai dengan requirement GitLab. sudo -u postgres psql -d template1 -c \"CREATE EXTENSION IF NOT EXISTS pg_trgm;\" sudo -u postgres psql -d template1 -c \"CREATE EXTENSION IF NOT EXISTS btree_gist;\" Lalu buat sebuah database baru. sudo -u postgres psql -d template1 -c \"CREATE DATABASE gitlabhq_production OWNER git;\" ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:2:7","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Setup LDAP Server Saya akan menggunakan Free IPA untuk server LDAP. Lalu karena saya tidak mempunyai DNS, maka cukup dengan menambahkan baris konfigurasi pada /etc/hosts di server app1.1238.internal seperti berikut. ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:3:0","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Host File echo \"192.168.0.7 app1.1238.internal\" | sudo tee -a /etc/hosts Pastikan juga hostname server sudah sesuai. sudo hostnamectl set-hostname app1.1238.internal ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:3:1","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Install Packages Kemudian install package yang dibutuhkan sudo yum install -y ipa-server ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:3:2","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Configure FreeIPA Pertama jalankan command berikut untuk menginisiasi service FreeIPA. sudo ipa-server-install Akan muncul beberapa pertanyaan, kurang lebih seperti berikut. [ec2-user@app1 ~]$ sudo ipa-server-install Do you want to configure integrated DNS (BIND)? [no]: no Server host name [app1.1238.internal]: app1.1238.internal Please confirm the domain name [1238.internal]: 1238.internal Please provide a realm name [1238.INTERNAL]: 1238.INTERNAL Directory Manager password: rahasiabanget Password (confirm): rahasiabanget IPA admin password: rahasiabanget Password (confirm): rahasiabanget Continue to configure the system with these values? [no]: yes Done. Client hostname: app1.1238.internal Realm: 1238.INTERNAL DNS Domain: 1238.internal IPA Server: app1.1238.internal BaseDN: dc=1238,dc=internal Jika kita mempunyai service firewall yang berjalan pada server ini, maka ijinkan beberapa port terkait service LDAP. Dibawah ini jika kita menggunakan firewalld untuk mengelola firewall. sudo firewall-cmd --permanent --add-service={dns,freeipa-ldap,freeipa-ldaps} sudo firewall-cmd --reload Aktifkan juga modul pam_oddjob_mkhomedir agar home directory terbuat otomatis. sudo authconfig --enablemkhomedir --update ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:3:3","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Create LDAP User Kita akan mencoba membuat sebuah user LDAP, namun pertama kita perlu mendapatkan ticket Kerberos untuk dapat mengoperasikan command ipa seperti berikut. kinit admin Masukkan password yang sebelumnya telah kita setup, kemudian kita bisa membuat user baru. ipa user-add trianwar --cn=Trianwar --first=Tri --last=Anwar --email=trianwar@protonmail.com --shell=/usr/bin/bash --homedir=/home/trianwar --password Jika sudah, uji apakah user berhasil terbuat. [ec2-user@app1 ~]$ ssh trianwar@localhost The authenticity of host 'localhost (\u003cno hostip for proxy command\u003e)' can't be established. ECDSA key fingerprint is SHA256:ky80bwa7by4uqlsVOIV08mVwhsCVcBYPuJpOyaxscNo. ECDSA key fingerprint is MD5:b6:d0:f1:22:ed:12:15:10:6d:63:65:d2:1f:c1:c5:88. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added 'localhost' (ECDSA) to the list of known hosts. Password: rahasiabanget Password expired. Change your password now. Current Password: rahasiabanget New password: rahasiabanget Retype new password: rahasiabanget Creating home directory for trianwar. [trianwar@app1 ~]$ Biasanya pada login pertama, kita akan dipaksa untuk mengganti password. Namun kita dapat memasukkan password lama agar tidak terganti. ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:3:4","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Setup GitLab Akhirnya kita telah sampai pada bagian ini, pertama kita perlu mempersiapkan certificate untuk service GitLab server. Sebenarnya playbook Ansible bisa membuatnya secara otomatis saat dijalankan, namun kali ini saya ingin membuatnya secara mandiri. Perlu diperhatikan bahwa sekarang saya sedang berada pada server frontend1.1238.internal yang akan menjadi server GitLab. ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:4:0","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Prepare Self-signed Certificate Saya menggunakan easy-rsa untuk membuat certificate. sudo yum install -y easy-rsa mkdir -p ~/easy-rsa; cd ~/easy-rsa ln -s /usr/share/easy-rsa/* ~/easy-rsa ./easyrsa init-pki touch -f vars Edit file vars sesuai kebutuhan kita, kurang lebih seperti berikut. set_var EASYRSA_REQ_COUNTRY \"ID\" set_var EASYRSA_REQ_PROVINCE \"Jakarta\" set_var EASYRSA_REQ_CITY \"South Jakarta\" set_var EASYRSA_REQ_ORG \"GitLab\" set_var EASYRSA_REQ_EMAIL \"trianwar@protonmail.com\" set_var EASYRSA_REQ_OU \"Community\" set_var EASYRSA_ALGO \"rsa\" set_var EASYRSA_DIGEST \"sha512\" Kemudian kita lanjutkan dengan command berikut. ./easy-rsa build-ca nopass Akan muncul beberapa tampilan berikut, masukkan saja informasi yang diperlukan seperti domain name yang akan dipakai untuk mengakses GitLab dan password untuk certificate. [ec2-user@frontend1 ~/easy-rsa]$ ./easyrsa build-ca Common Name (eg: your user, host, or server name) [Easy-RSA CA]: frontend1.1238.internal CA creation complete and you may now import and sign cert requests. Your new CA certificate file for publishing is at: /home/ec2-user/easy-rsa/pki/ca.crt Salin file yang berhasil di-generate untuk digunakan. cat ~/easy-rsa/pki/ca.crt | sudo tee /etc/pki/ca-trust/source/anchors/frontend1.1238.internal.crt sudo update-ca-trust openssl req -new -key frontend1.1238.internal.key -out frontend1.1238.internal.req -subj /C=ID/ST=Jakarta/L=South\\ Jakarta/O=init.web.id/OU=Community/CN=frontend1.1238.internal/emailAddress=trianwar@protonmail.com ./easyrsa import-req frontend1.1238.internal.req.req frontend1.1238.internal ./easyrsa sign-req server frontend1.1238.internal sudo mkdir -p /etc/gitlab/ssl cat frontend1.1238.internal.key | sudo tee /etc/gitlab/ssl/frontend1.1238.internal.key cat pki/issued/frontend1.1238.internal.crt | sudo tee /etc/gitlab/ssl/frontend1.1238.internal.crt ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:4:1","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Playbook Clone Playbook dari repository Git yang sudah saya siapkan. cd ~ git clone https://github.com/anwareset/ansible-gitlab-setup.git cd ansible-gitlab-setup Playbook ini sebenarnya adalah Roles yang awalnya dibuat oleh geerlingguy, kita dapat menggunakannya dalam bentuk Roles. Tapi saya memodifikasi sedikit sesuai kebutuhan saya. Kurang lebih struktur Playbook yang akan kita gunakan. . ├── ansible.cfg \u003c---- Ansible Configuration File ├── gitlab-setup.yml \u003c---- Playbook ├── hosts \u003c---- Inventory ├── LICENSE ├── README.md ├── templates │ ├── backup.sh.j2 \u003c---- Custom shell script for autobackup │ └── gitlab.rb.j2 \u003c---- Gitlab Configuration File └── vars ├── Debian.yml ├── main.yml \u003c---- User Variables └── RedHat.yml Edit file vars/main.yml dan sesuaikan dengan beberapa server yang telah kita konfigurasi sebelumnya (LDAP dan PostgreSQL), jangan lupa untuk merubah opsi certificate. Kurang lebihnya seperti berikut. # General Configuration gitlab_domain: frontend.1238.internal # Database Configuration postgresql_enable: true postgresql_host: \"appdb1.1238.internal\" postgresql_port: 5432 postgresql_username: \"git\" postgresql_password: \"rahasiabanget\" # LDAP Configuration gitlab_ldap_enabled: true gitlab_ldap_host: \"app1.1238.internal\" gitlab_ldap_port: 389 gitlab_ldap_uid: \"uid\" gitlab_ldap_encryption: \"plain\" gitlab_ldap_verify_certificates: false gitlab_ldap_bind_dn: \"CN=admin,DC=1238,DC=internal\" gitlab_ldap_password: \"rahasiabanget\" gitlab_ldap_active_directory: \"\" gitlab_ldap_base: \"DC=1238,DC=internal\" gitlab_ldap_user_filter: \"\" gitlab_ldap_lowercase_username: false gitlab_ldap_allow_email: true # SSL Configuration gitlab_redirect_http_to_https: true gitlab_ssl_certificate: \"/etc/gitlab/ssl/{{ gitlab_domain }}.crt\" gitlab_ssl_certificate_key: \"/etc/gitlab/ssl/{{ gitlab_domain }}.key\" gitlab_ssl_protocols: \"TLSv1.1 TLSv1.2\" # SSL Self-signed Certificate Configuration gitlab_create_self_signed_cert: false Jika sudah dirasa cukup, kita lanjutkan untuk menjalankan Ansible Playbook dengan command berikut. ansible-playbook gitlab-setup.yml --syntax-check ansible-playbook gitlab-setup.yml -vv Untuk durasi dari proses setup sangat variatif tergantung dari spesifikasi dan koneksi yang dimiliki oleh server. Jika berhasil, kita dapat melakukan pengecekan seperti berikut. sudo gitlab-ctl status Kurang lebih outputnya seperti berikut. run: alertmanager: (pid 16114) 440s; run: log: (pid 14417) 639s run: gitaly: (pid 16107) 440s; run: log: (pid 11898) 792s run: gitlab-exporter: (pid 18438) 266s; run: log: (pid 13953) 663s run: gitlab-kas: (pid 18292) 288s; run: log: (pid 12454) 772s run: gitlab-workhorse: (pid 15997) 445s; run: log: (pid 13566) 687s run: grafana: (pid 18440) 266s; run: log: (pid 15289) 495s run: logrotate: (pid 11610) 809s; run: log: (pid 11619) 805s run: nginx: (pid 19808) 64s; run: log: (pid 13696) 680s run: node-exporter: (pid 16025) 445s; run: log: (pid 13841) 669s run: postgres-exporter: (pid 16121) 440s; run: log: (pid 14568) 633s run: postgresql: (pid 12167) 779s; run: log: (pid 12254) 777s run: prometheus: (pid 16084) 443s; run: log: (pid 14249) 646s run: puma: (pid 18536) 262s; run: log: (pid 13345) 699s run: redis: (pid 11714) 802s; run: log: (pid 11777) 799s run: redis-exporter: (pid 16078) 444s; run: log: (pid 14084) 656s run: sidekiq: (pid 18196) 312s; run: log: (pid 13480) 693s Coba buka domain yang kita gunakan untuk server Gitlab pada web browser. Jika berhasil maka kurang lebih akan seperti berikut. Coba untuk login menggunakan user LDAP yang telah kita buat sebelumnya. Gitlab Login Gitlab Login LDAP ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:4:2","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Reset Root Password Sedangkan untuk password user root kita perlu melakukan reset terlebih dahulu menggunakan Rake task. sudo gitlab-rake \"gitlab:password:reset\" ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:4:3","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Setup GitLab Runner Selanjutnya kita akan menggunakan Playbook lain untuk registrasi Gitlab Runner. cd ~ git clone https://github.com/anwareset/ansible-gitlab-runner-setup.git cd ansible-gitlab-runner-setup Dan karena server Gitlab tadi menggunakan self-signed certificate, maka kita perlu menyalinnya ke tempat yang bisa dijangkau oleh VM Gitlab Runner. cat ~/easy-rsa/pki/issued/frontend1.1238.internal.crt \u003e /tmp/frontend1.1238.internal.pem cat ~/easy-rsa/frontend1.1238.internal.key \u003e /tmp/frontend1.1238.internal.pem ansible -m file -a \"path=/etc/ssl/private state=directory mode='0755'\" runner ansible -m copy -a \"src=/tmp/frontend1.1238.internal.pem dest=/etc/ssl/private/frontend1.1238.internal.pem mode='0644'\" runner Dapatkan registration token dari Gitlab server di web browser. Get Registration Token Edit file vars/main.yml sesuaikan beberapa variabel seperti domain server Gitlab dan registration token. # GitLab coordinator URL gitlab_runner_coordinator_url: 'https://frontend1.1238.internal/' # GitLab registration token gitlab_runner_registration_token: 'JhgmzZqths-gLPSH_kKx' # A list of runners to register and configure gitlab_runner_runners: state: present executor: 'docker' tls_ca_file: \"/etc/ssl/private/frontend1.1238.internal.pem\" Jika sudah langsung saja kita run dengan command seperti berikut. ansible-playbook gitlab-runner.yml --syntax-check ansible-playbook gitlab-runner.yml -vv Setelah berhasil, akan bisa kita cek di web browser dan hasilnya seperti seperti berikut. Runner Registrated ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:5:0","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["Tools"],"content":"Referensi docs.gitlab.com/ee/install/installation.html#6-database www.digitalocean.com/community/tutorials/how-to-set-up-and-configure-a-certificate-authority-ca-on-ubuntu-20-04 easy-rsa.readthedocs.io/en/latest/advanced access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/identity_management_guide/users access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/linux_domain_identity_authentication_and_policy_guide/installing-ipa access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/linux_domain_identity_authentication_and_policy_guide/required-packages galaxy.ansible.com/geerlingguy/gitlab galaxy.ansible.com/riemers/gitlab-runner centos.pkgs.org/7/centos-extras-x86_64/centos-release-scl-rh-2-3.el7.centos.noarch.rpm.html docs.gitlab.com/runner/install/ stackoverflow.com/questions/18580066/how-to-allow-remote-access-to-postgresql-database docs.gitlab.com/ee/security/reset_user_password.html#use-a-rake-task ","date":"2022-04-10","objectID":"/setup-gitlab-server-with-ansible/:6:0","tags":["Gitlab","Asible","Automation","Playbook"],"title":"Setup Gitlab Server with Ansible","uri":"/setup-gitlab-server-with-ansible/"},{"categories":["GNU/Linux"],"content":"Deteksi dan respon otomatis terhadap perangkat USB menggunakan Udev pada sistem operasi GNU/Linux","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Perangkat USB yang terpasang ke komputer dengan sistem operasi GNU/Linux akan dimonitor oleh daemon dari Udev. Saya baru saja membeli sebuah USB Mouse hybrid yaitu Rexus Arka RX107 yang mendukung dual-mode di mana kita dapat menggunakannya secara nirkabel maupun berkabel. Dalam kasus ini mouse dapat terdeteksi dan digunakan secara langsung, namun ada beberapa hal yang saya butuhkan, seperti mengatur beberapa properties pada mouse. Yang saya maksud misalnya akselerasi kursor, kecepatan double-click, hingga kecepatan scroll. Konfigurasi semacam itu terkadang perlu kita adjust secara mandiri dan tidak dapat serta merta dilakukan begitu saja dari System Settings (contohnya xfce4-mouse-settings) di DE (Desktop Environment) XFCE. Terlebih saya tidak menggunakan DE, hanya Window Manager saja. ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:0:0","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Xinput Biasanya saya menggunakan xinput untuk melakukan konfigurasi pada properties milik mouse. ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:1:0","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Listing Kita dapat melihat perangkat apa saja yang terhubung seperti berikut. xinput list Dan di sini saya mempunyai beberapa perangkat input, kita akan berfokus pada perangkat yang namanya mengandung kata Wireless dan pointer karena kita membahas tentang akselerasi mouse. ⎡ Virtual core pointer id=2 [master pointer (3)] ⎜ ↳ LXDDZ 2.4G Wireless Mouse id=19 [slave pointer (2)] ⎜ ↳ LXDDZ 2.4G Wireless Mouse Consumer Control id=12 [slave pointer (2)] ... ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:1:1","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Properties Untuk melihat properties apa saja yang mungkin dapat kita set, jalankan perintah berikut. xinput list-props 19 Angka 19 adalah id dari pointer LXDDZ 2.4G Wireless Mouse. Kurang lebih outputnya seperti dibawah ini, cukup cari kata yang berhubungan dengan Speed atau Accel. Device 'LXDDZ 2.4G Wireless Mouse': ... libinput Accel Speed (321): 0.000000 libinput Accel Speed Default (322): 0.000000 ... Dari sini kita akan mendapatkan id dari properties Accel Speed adalah 321. Kita akan membutuhkannya untuk melakukan adjustment pada mouse. ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:1:2","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Set Mouse Properties Untuk memberikan value baru pada properties di atas, kita dapat menggunakan perintah berikut. xinput set-prop 19 321 --type=float -0.575 Saya memberikan value sebesar -0.575 bertipe float atau pecahan, untuk menurunkan kecepatan akselerasi pada mouse. Dari sini seharusnya mouse akan terasa lebih lambat untuk digerakkan, sesuaikan dengan preferensi kalian. Kita perlu mengatur properties tersebut tiap kali mouse reconnected, tentu saja sangat melelahkan. Maka dari itu, mari membuatnya menjadi otomatis. ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:1:3","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Deteksi USB Mouse Saya mencoba membaca perangkat USB yang terhubung menggunakan perintah lsusb, beberapa informasi yang kita butuhkan adalah Device ID dan Vendor ID. ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:2:0","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"lsusb Informasi terkait dapat kita dapatkan dengan perintah berikut. sudo lsusb -v | grep -iE 'idproduct|idvendor' Berikut ini adalah sebelum Mouse USB terpasang. ... idVendor 0x1d6b Linux Foundation idProduct 0x0003 3.0 root hub idVendor 0x138a Validity Sensors, Inc. idProduct 0x0017 VFS 5011 fingerprint sensor idVendor 0x04ca Lite-On Technology Corp. idProduct 0x7035 ... Kemudian saya menghubungkan Mouse USB, dan inilah outputnya. ... idVendor 0x1d6b Linux Foundation idProduct 0x0003 3.0 root hub idVendor 0x138a Validity Sensors, Inc. idProduct 0x0017 VFS 5011 fingerprint sensor idVendor 0x1d57 Xenta idProduct 0xfa60 idVendor 0x04ca Lite-On Technology Corp. idProduct 0x7035 ... Berdasarkan output diatas, dapat kita ambil value yang baru muncul (bernama Xenta). Key Value idVendor 0x1d57 idProduct 0xfa60 ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:2:1","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"udevadm Sekarang mari kita monitor path dari pertangkat USB yang terhubung. Tapi sebelumnya saya akan mencabut mouse terlebih dahulu, barulah menjalankan perintah berikut. udevadm monitor Setelah mouse kembali dihubungkan ke komputer, saya mendapatkan output seperti berikut. monitor will print the received events for: UDEV - the event which udev sends out after rule processing KERNEL - the kernel uevent KERNEL[2977.046735] add /devices/pci0000:00/0000:00:14.0/usb3/3-3 (usb) KERNEL[2977.049111] change /devices/pci0000:00/0000:00:14.0/usb3/3-3 (usb) KERNEL[2977.049159] add /devices/pci0000:00/0000:00:14.0/usb3/3-3/3-3:1.0 (usb) KERNEL[2977.050130] add /devices/pci0000:00/0000:00:14.0/usb3/3-3/3-3:1.0/0003:1D57:FA60.0011 (hid) KERNEL[2977.050251] add /devices/pci0000:00/0000:00:14.0/usb3/3-3/wakeup/wakeup25 (wakeup) KERNEL[2977.050369] add /devices/pci0000:00/0000:00:14.0/usb3/3-3/3-3:1.0/0003:1D57:FA60.0011/input/input44 (input) Kita hanya perlu mencari path yang berhubungan dengan idVendor dan idProduct yang telah kita dapatkan sebelumnya. Maka kita akan menggunakan baris berikut. KERNEL[2977.049159] add /devices/pci0000:00/0000:00:14.0/usb3/3-3/3-3:1.0 (usb) KERNEL[2977.050130] add /devices/pci0000:00/0000:00:14.0/usb3/3-3/3-3:1.0/0003:1D57:FA60.0011 (hid) Lalu kita cari informasi lebih lanjut tentang path tersebut menggunakan perintah berikut. udevadm info -a -p /devices/pci0000:00/0000:00:14.0/usb3/3-3/3-3:1.0 Maka kita akan mendapatkan banyak sekali output seperti berikut. looking at parent device '/devices/pci0000:00/0000:00:14.0/usb3/3-3': KERNELS==\"3-3\" SUBSYSTEMS==\"usb\" DRIVERS==\"usb\" ATTRS{authorized}==\"1\" ATTRS{avoid_reset_quirk}==\"0\" ATTRS{bConfigurationValue}==\"1\" ATTRS{bDeviceClass}==\"00\" ATTRS{bDeviceProtocol}==\"00\" ATTRS{bDeviceSubClass}==\"00\" ATTRS{bMaxPacketSize0}==\"64\" ATTRS{bMaxPower}==\"100mA\" ATTRS{bNumConfigurations}==\"1\" ATTRS{bNumInterfaces}==\" 4\" ATTRS{bcdDevice}==\"2003\" ATTRS{bmAttributes}==\"a0\" ATTRS{busnum}==\"3\" ATTRS{configuration}==\"\" ATTRS{devnum}==\"9\" ATTRS{devpath}==\"3\" ATTRS{idProduct}==\"fa60\" ATTRS{idVendor}==\"1d57\" ATTRS{ltm_capable}==\"no\" ATTRS{manufacturer}==\"LXDDZ\" ATTRS{maxchild}==\"0\" ATTRS{power/active_duration}==\"553324\" ATTRS{power/autosuspend}==\"2\" ATTRS{power/autosuspend_delay_ms}==\"2000\" ATTRS{power/connected_duration}==\"553324\" ATTRS{power/control}==\"on\" ATTRS{power/level}==\"on\" ATTRS{power/persist}==\"1\" ATTRS{power/runtime_active_time}==\"553060\" ATTRS{power/runtime_status}==\"active\" ATTRS{power/runtime_suspended_time}==\"0\" ATTRS{power/wakeup}==\"enabled\" ATTRS{power/wakeup_abort_count}==\"0\" ATTRS{power/wakeup_active}==\"0\" ATTRS{power/wakeup_active_count}==\"0\" ATTRS{power/wakeup_count}==\"0\" ATTRS{power/wakeup_expire_count}==\"0\" ATTRS{power/wakeup_last_time_ms}==\"0\" ATTRS{power/wakeup_max_time_ms}==\"0\" ATTRS{power/wakeup_total_time_ms}==\"0\" ATTRS{product}==\"2.4G Wireless Mouse\" ATTRS{quirks}==\"0x0\" ATTRS{removable}==\"removable\" ATTRS{remove}==\"(write-only)\" ATTRS{rx_lanes}==\"1\" ATTRS{speed}==\"12\" ATTRS{tx_lanes}==\"1\" ATTRS{urbnum}==\"22306\" ATTRS{version}==\" 1.10\" Kita dapat melihat lebih detail informasi yang tentang perangkat USB Mouse yang baru saja saya beli, untuk membuat Udev rules saya membutuhkan value dari SUBSYSTEMS pada output di atas. ... looking at parent device '/devices/pci0000:00/0000:00:14.0/usb3/3-3': KERNELS==\"3-3\" SUBSYSTEMS==\"usb\" DRIVERS==\"usb\" ... Value dari SUBSYSTEMS adalah usb. ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:2:2","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Symlink Mari kita buktikan dengan langsung membuat sebuah Udev rules yang akan menciptakan sebuah symlink path pada /dev/ ketika perangkat terhubung, dan hilang saat perangkat tercabut. echo 'SUBSYSTEM==\"usb\", ATTRS{idVendor}==\"1d57\", ATTRS{idProduct}==\"fa61\", SYMLINK+=\"usb_mouse_rexus_wired\"' | sudo tee -a /etc/udev/rules.d/83-hybrid-wireless-mouse-rexus-rx107.rules Dengan perintah di atas, saya membuat file baru di direktori /etc/udev/rules.d yang bernama 83-hybrid-wireless-mouse-rexus-rx107.rules. Untuk format nama file pada Udev selalu diawali dengan angka yang akan menjadi nomor urut dari rules tersebut untuk dieksekusi. Kemudian jalankan ujicoba pada path yang kita dapatkan sebelumnya. sudo udevadm test -a /devices/pci0000:00/0000:00:14.0/usb3/3-3 Jika Udev rules berhasil, maka kita akan mendapatkan output seperti berikut. ... Reading rules file: /etc/udev/rules.d/83-hybrid-wireless-mouse-rexus-rx107.rules ... 3-3: /etc/udev/rules.d/83-hybrid-wireless-mouse-rexus-rx107.rules:6 LINK 'usb_mouse_rexus_wireless' ... ID_VENDOR_ID=1d57 ID_MODEL_ID=fa60 DEVLINKS=/dev/usb_mouse_rexus_wireless ... Periksa juga apakah symlink telah terbuat di direktori /dev/. $ ls -l /dev/usb_mouse_rexus_wireless lrwxrwxrwx 1 root root 15 Jan 21 20:24 /dev/usb_mouse_rexus_wireless -\u003e bus/usb/003/009 Dan saat mouse dicabut, symlink tersebut akan hilang. ls -l /dev/usb_mouse_rexus_wireless ls: cannot access '/dev/usb_mouse_rexus_wireless': No such file or directory ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:2:3","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Plug And Play Sebenarnya menggunakan istilah PnP atau Plug and Play kurang tepat, karena mouse langsung dapat digunakan tanpa perlu memasang driver dan sebagainya. Hanya saja, seperti yang saya tulis sebelumnya bahwa konfigurasi properties pada mouse perlu tidaklah permanen. Artinya saya perlu melakukannya setiap kali reconnecting mouse, namun terimakasih kepada udev dan shell script sederhana yang akan melakukannya secara otomatis. ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:3:0","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Udev rules Sebelumnya kita telah mencoba membuat rules untuk path symlink, kali ini kita akan menambahkan beberapa baris rules lagi untuk mengeksekusi sebuah shell script yang berisi perintah xinput untuk konfigurasi properties pada mouse. # Wired SUBSYSTEM==\"usb\", ATTRS{idVendor}==\"1d57\", ATTRS{idProduct}==\"fa61\", SYMLINK+=\"usb_mouse_rexus_wired\" ACTION==\"add\", SUBSYSTEM==\"usb\", ATTRS{idVendor}==\"1d57\", ATTRS{idProduct}==\"fa61\", ENV{DISPLAY}=\":0.0\", ENV{XAUTHORITY}=\"/home/pwn3r/.Xauthority\", RUN+=\"/usr/local/bin/set-prop-rexus-mouse\" # Wireless SUBSYSTEM==\"usb\", ATTRS{idVendor}==\"1d57\", ATTRS{idProduct}==\"fa60\", SYMLINK+=\"usb_mouse_rexus_wireless\" ACTION==\"add\", SUBSYSTEM==\"usb\", ATTRS{idVendor}==\"1d57\", ATTRS{idProduct}==\"fa60\", ENV{DISPLAY}=\":0.0\", ENV{XAUTHORITY}=\"/home/pwn3r/.Xauthority\", RUN+=\"/usr/local/bin/set-prop-rexus-mouse\" Kenapa saya membuat dua symlink dan terdapat dua idProduct yang berbeda? Hal ini karena ketika mouse mempunyai dual-mode, yang ternyata memiliki idProduct berbeda saat dioperasikan secara nirkabel ataupun berkabel. Lalu kita dapat melihat ACTION==\"add\" yang artinya rules akan mulai menjalankan RUN saat mendeteksi action berupa add pada atribut yang sesuai dengan SUBSYSTEM, idVendor dan idProduct. Sementara ENV adalah environment variable yang akan dilewatkan ketika RUN dieksekusi, hal ini diperlukan karena perintah xinput pada shell script akan dieksekusi oleh sistem (root). Maka udev perlu tahu mana user yang dimaksud, dan mana letak sesi display manager user tersebut. Selanjutnya muat ulang Udev rules yang telah kita buat supaya daemon akan menerapkannya. sudo udevadm control --reload ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:3:1","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Response Dari sini kita akan melakukan sedikit shell scripting, kurang lebih seperti berikut. #!/usr/bin/bash export DISPLAY=${DISPLAY} export HOME=/home/pwn3r export XAUTHORITY=$HOME/.Xauthority /usr/local/bin/set-prop-rexus-mouse-worker \u0026 Namun file tersebut tidak akan menjalankan perintah xinput. Karena mouse belum terdeteksi pada xinput list ketika Udev rules pertama kali dieksekusi. Maka kita akan memanggil shell script lain di background seperti berikut. #!/usr/bin/bash sleep 2 for i in $(xinput list | grep -i \"LXDDZ 2.4G Wireless Mouse\" | grep -iEv \"Consumer|Control|keyboard\" | sed -e 's/^.*id=\\([0-9]*.\\).*$/\\1/') do xinput set-prop $i 321 --type=float -0.6 done Perhatian Perhatikan argumen dari perintah grep di atas, kita perlu menyesuaikannya untuk mendapatkan id dari perangkat yang terdeteksi oleh xinput list. Artinya setiap perangkat memiliki karakteristik yang berbeda, dan silahkan bermain-main untuk mencari value yang sesuai dengan perangkat kalian. Saya menyimpan kedua file shell script tersebut ke direktori /usr/local/bin dan jangan lupa tambahkan executable permission. sudo chmod +x /usr/local/bin/set-prop-rexus-mouse.sh sudo chmod +x /usr/local/bin/set-prop-rexus-mouse-worker.sh Dari sini kita dapat memicu Udev rules dengan perintah berikut. Atau sederhana saja, cukup cabut dan hubungkan kembali mouse. Maka kedua shell script tersebut akan dieksekusi oleh Udev rules. sudo udevadm trigger -c add ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:3:2","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Kesimpulan Sebenarnya udev tidak terlalu rumit untuk digunakan, hanya sedikit susah dalam hal debug perangkat. Faktanya udev juga dapat digunakan untuk berbagai macam perangkat dengan interface lain seperti SCSI, SATA/eSATA, PCI, hingga VGA dan HDMI. Jadi tidak untuk USB saja, udev dipakai oleh sistem operasi untuk handling berbagai peripheral yang terhubung ke komputer. ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:4:0","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["GNU/Linux"],"content":"Referensi granjow.net/udev-rules.html man7.org/linux/man-pages/man8/udevadm.8.html wiki.archlinux.org/title/udev bootlin.com/doc/legacy/udev/udev.pdf wiki.archlinux.org/title/xinput ","date":"2022-01-21","objectID":"/plug-and-play-usb-devices-dengan-udev-rules/:5:0","tags":["Environment","Review"],"title":"Plug and Play USB Devices dengan Udev Rules","uri":"/plug-and-play-usb-devices-dengan-udev-rules/"},{"categories":["Platform"],"content":"Mengelola Virtualisasi Infrastruktur Datacenter menggunakan oVirt","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"oVirt adalah virtualization platform untuk mengelola infrastruktur datacenter. Hypervisor yang dipakai adalah KVM, lalu libvirt digunakan sebagai interface lewat API dan berkomunikasi dengan VDSM sehingga dapat hadir dalam bentuk tampilan Web. Artikel ini hanya membahas setup oVirt Node dengan Self-hosted Engine hingga menjalankan guest VM. ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:0:0","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Tentang oVirt Pada awalnya oVirt adalah project open source bernama Solid ICE, dikembangkan oleh perusahaan Qumranet. Lalu Red Hat mengakuisisi project tersebut dan mengganti namanya menjadi oVirt, kedepannya oVirt menjadi upstream dari produk bernama Red Hat Enterprise Virtualization (biasa disingkat sebagai RHEV atau RHV). Pada saat artikel ini diterbitkan, installer atau ISO dari Red Hat Virtualization versi latest stable yang tersedia adalah RHVH 4.4 (Red Hat Virtualization Host), sedangkan dalam artikel ini saya akan menggunakan oVirt Node 4.4.9. Sebetulnya kita dapat membangun klaster oVirt dan RHV menggunakan distro Enterprise Linux seperti CentOS atau RHEL, tapi saya rasa akan lebih mudah jika memakai distro yang disediakan oleh oVirt atau RHV, yang memang sudah didesain sedemikian rupa sehingga memudahkan kita dalam proses setup. ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:1:0","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Fitur Dasar Berikut ini adalah beberapa fitur dasar yang akan memudahkan kita dalam mengelola virtualisasi infrastruktur ketika menggunakan oVirt. Web Interface yang ramah pengguna bagi administrator dan user non-admin Manajemen terintegrasi bagi host, storage, dan konfigurasi network Live Migration bagi virtual machine dan disk antar host dan storage High availability bagi virtual machine ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:1:1","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Prerequisites ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:2:0","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Metode Kita dapat melakukan instalasi file ISO oVirt Node ke komputer fisik (baremetal) pada datacenter, namun karena keterbatasan resource saya akan melakukannya dalam VM di komputer supaya lebih fleksibel. Ada beberapa macam jenis instalasi yang bisa kita lakukan, kurang lebihnya seperti: Self-hosted Engine. Cara inilah yang akan kita terapkan, karena cenderung lebih simple. Pertama kita lakukan instalasi file ISO oVirt Node, lalu dalam OS tersebut kita deploy sebuah VM yang bertugas sebagai Engine atau Manager. Standalone Manager. Menurut saya cara ini lebih rumit, namun akan cocok jika ingin mencapai performa yang lebih baik. Karena satu mesin tersebut hanya didedikasikan untuk fokus menjalankan satu OS sebagai Engine atau Manager. ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:2:1","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Host Sebuah Host dalam oVirt mirip seperti Worker Node pada klaster Kubernetes. Jika Worker Node di Kubernetes menjalankan Pod, maka Host di oVirt akan menjalankan VM. Terlalu menyederhanakan, tapi kurang lebih bagi saya memang seperti itu tugasnya. Ibarat sebuah Pod, kelak VM dalam Host bisa di-migrate ke Host lain. Saya akan menggunakan dua VM sebagai Host oVirt. VM ini berjalan di atas komputer saya menggunakan KVM dengan bantuan virsh. Kedua VM akan saya sebut sebagai host dan kita install ISO oVirt Node. Nantinya salah satu dari host ini akan menjalankan sebuah VM di dalamnya yang dijuluki Self-hosted Engine sebagai Manager dari keseluruhan oVirt. Manager tersebut akan kita pakai untuk mengelola klaster oVirt. Jika digambarkan kurang lebih akan terlihat seperti berikut. Self-hosted Engine Untuk proses instalasi ISO oVirt Node pada masing-masing host terbilang relatif mudah, karenanya saya anggap tidak perlu dijelaskan pada artikel ini. ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:2:2","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Network Saya tidak ingin IP kedua host tersebut berubah, maka kita perlu menyesuaikan konfigurasi virtual network KVM pada komputer menggunakan virsh seperti berikut. sudo virsh net-edit default Masukkan masing-masing MAC address dari virtual NIC kedua VM host, misalnya seperti berikut. \u003cnetwork\u003e \u003cname\u003edefault\u003c/name\u003e \u003cuuid\u003e85633c91-ef79-4ab7-8835-295b046c7xxx\u003c/uuid\u003e \u003cforward mode='nat'/\u003e \u003cbridge name='virbr0' stp='on' delay='0'/\u003e \u003cmac address='52:54:00:bn:6f:15'/\u003e \u003cip address='192.168.122.1' netmask='255.255.255.0'\u003e \u003cdhcp\u003e \u003crange start='192.168.122.50' end='192.168.122.159'/\u003e \u003chost mac='52:54:00:b8:77:94' name='host1.ovirt.local' ip='192.168.122.20'/\u003e \u003chost mac='52:54:00:fa:df:2d' name='host2.ovirt.local' ip='192.168.122.21'/\u003e \u003c/dhcp\u003e \u003c/ip\u003e \u003c/network\u003e Artinya virtual network KVM pada komputer kita hanya akan memulai alokasi DHCP dari 192.168.122.50 sampai 192.168.122.159, sementara kedua MAC yang kita masukkan tidak berubah karena dijadikan static, dengan IP 192.168.122.20 untuk host1.ovirt.local dan IP 192.168.122.21 untuk host2.ovirt.local. Karena deployment hosted-engine nantinya akan melakukan lookup hostname dan kita tidak menggunakan server DNS pada artikel ini, maka selanjutnya kita perlu menambahkan konfigurasi pada /etc/hosts di komputer, kedua host, serta VM Self-hosted Engine seperti berikut. 192.168.122.20 host1.ovirt.local 192.168.122.21 host2.ovirt.local 192.168.122.15 hosted-engine.ovirt.local ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:2:3","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Spesifikasi Host Karena hanya untuk keperluan belajar, saya meminimalisir penggunakan resource agar efisien. Kedua host yang sudah saya persiapkan menggunakan spesifikasi seperti berikut. Host vCPU cores Memory Disk Additional Disk host1.ovirt.local 1 8 GB 65 GB 65 GB host2.ovirt.local 1 2 GB 65 GB - Tips Pada host1.ovirt.local diperlukan tambahan disk yang nantinya dijadikan sebagai NFS server. Setelah instalasi VM Self-hosted Engine selesai, memori pada host ini juga dapat kita resize sesuai kebutuhan, misalnya kita turunkan menjadi 5 GB. Jumlah memori awal sebesar 8 GB hanyalah untuk mencegah terjadinya kegagalan ketika proses deployment yang disebabkan oleh minimnya ketersediaan memori. ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:2:4","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"NFS Server Setidaknya sebuah Storage Domain dibutuhkan dalam Datacenter oVirt, dan kita dapat menambahkan beberapa jenis storage seperti misalnya NFS server. Pada sebelumnya kita telah menambahkan disk tambahan pada host1.ovirt.local anggaplah terbaca sebagai /dev/vdb dan akan kita gunakan sebagai filesystem bagi NFS. Supaya lebih efisien, dalam artikel ini NFS server akan saya bangun juga pada host1.ovirt.local. [root@host1 ~]# parted /dev/vdb GNU Parted 3.2 Using /dev/vdb Welcome to GNU Parted! Type 'help' to view a list of commands. (parted) mklabel msdos Warning: The existing disk label on /dev/vdb will be destroyed and all data on this disk will be lost. Do you want to continue? Yes/No? Yes (parted) mkpart Partition type? primary/extended? primary File system type? [ext2]? xfs Start? 0% End? 100% (parted) print Model: Virtio Block Device (virtblk) Disk /dev/vdb: 69.8GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags: Number Start End Size Type File system Flags 1 1049kB 69.8GB 69.8GB primary xfs lba (parted) quit Information: You may need to update /etc/fstab. Tambahkan partisi tersebut ke dalam konfigurasi /etc/fstab. # Mount partition for NFS server /dev/vdb1 /mnt/storage1 xfs defaults 0 0 Kemudian refresh partition table dengan udevadm dan format partisi dengan mkfs lalu buat direktori untuk mountpoint pada /mnt/storage1, jangan lupa lakukan mount. udevadm settle mkfs.xfs /dev/vdb1 mkdir -p /mnt/storage1 mount -av chmod 777 -R /mnt/storage1 Jika mount partition berhasil, akan muncul output seperti berikut. mount: /mnt/storage1 does not contain SELinux labels. You just mounted an file system that supports labels which does not contain labels, onto an SELinux box. It is likely that confined applications will generate AVC messages and not be allowed access to this file system. For more details see restorecon(8) and mount(8). /mnt/storage1 : successfully mounted Tambahkan mountpoint tersebut ke dalam konfigurasi NFS server, lakukan export dengan exportfs dan jalankan service nfs-server dengan systemd. echo \"/mnt/storage1 *(rw,sync)\" \u003e\u003e /etc/exports exportfs -arv systemctl enable --now nfs-server.service systemctl status nfs-server.service Sesuaikan service yang diperbolehkan oleh firewalld, cukup lakukan ini di sisi host1.ovirt.local saja. firewall-cmd --permanent --add-service=nfs firewall-cmd --permanent --add-service=mountd firewall-cmd --permanent --add-service=rpc-bind firewall-cmd --reload Sekarang cek dari kedua sisi host apakah NFS server sudah terdeteksi. for i in host{1..2}.ovirt.local; do ssh root@$i \"showmount -e host1.ovirt.local\"; done ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:2:5","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Self-hosted Engine ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:3:0","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"VM Settings Buka cockpit lewat web browser dengan URL https://host1.ovirt.local:9090/ovirt-dashboard#/he untuk deploy VM Self-hosted Engine. Gunakan username root dan kata sandi yang telah dibuat ketika instalasi oVirt Node. Setelah berhasil login, klik Start pada Hosted Engine. Deploy Self-hosted Engine Sesuaikan Engine VM FQDN dan VM IP Address dengan konfigurasi yang sudah dibuat pada /etc/hosts. Resize Memory Size (MiB) ke batas terendah (4096) serta Number of Virtual CPUs menjadi 1 saja, namun hal ini dapat disesuaikan dengan spesifikasi host yang kita hendaki. Self-hosted Engine Configuration Prepare Self-hosted Engine VM ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:3:1","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Deployment Progress Jika kita lihat dari output log, deployment dijalankan oleh Ansible. Durasi yang diperlukan untuk deployment sangat bergantung pada kecepatan koneksi jaringan internet, spesifikasi VM host, serta hardware komputer yang kita miliki. Dalam kasus saya, internet berkecepatan sekitar 5MB/s dengan spesifikasi host pada artikel ini, memakan waktu hingga sekitar 1 jam. Self-hosted Engine Deployment Progess ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:3:2","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Storage Domain Seusai VM Self-hosted Engine sudah berhasil dinyalakan, kita lanjutkan dengan membuat Storage Domain. Fungsinya nanti adalah untuk menampung berbagai images baik file ISO Installer maupun virtual disk bagi VM yang akan dibuat. Karena sebelumnya kita sudah membuat NFS server, maka seharusnya sekarang tinggal kita hubungkan saja seperti berikut. Add NFS as Storage Domain ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:3:3","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Healthcheck Hosted Engine Masuk ke shell untuk user root pada host1.ovirt.local misalnya dengan SSH, dan periksa apakah VM Self-hosted Enginer dalam keadaan baik. [root@host1 ~]# hosted-engine --vm-status --== Host host1.ovirt.local (id: 1) status ==-- Host ID : 1 Host timestamp : 10187 Score : 3400 Engine status : {\"vm\": \"up\", \"health\": \"good\", \"detail\": \"Up\"} Hostname : host1.ovirt.local Local maintenance : False stopped : False crc32 : a1c1f3b9 conf_on_shared_storage : True local_conf_timestamp : 10187 Status up-to-date : True Extra metadata (valid at timestamp): metadata_parse_version=1 metadata_feature_version=1 timestamp=10187 (Tue Nov 30 08:55:06 2021) host-id=1 score=3400 vm_conf_refresh_time=10187 (Tue Nov 30 08:55:06 2021) conf_on_shared_storage=True maintenance=False state=EngineUp stopped=False Tips Selagi masih dalam shell host1.ovirt.local coba untuk SSH ke hosted-engine.ovirt.local dan lakukan konfigurasi file /etc/hosts sesuai dengan yang sebelumnya telah kita bahas di bagian Network. Login SSH menggunakan user root dan kata sandi yang telah dibuat sebelumnya. ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:3:4","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"oVirt Webmanager Jika VM Self-hosted Engine dalam keadaan baik, kita dapat membuka Web Manager untuk mengelola oVirt lewat web browser dengan alamat https://hosted-engine.ovirt.local menggunakan username admin dan kata sandi yang telah kita buat sebelumnya pada saat melakukan konfigurasi VM Settings. oVirt Manager Web Portal ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:3:5","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Add Host Tambahkan host2.ovirt.local ke datacenter oVirt yang berhasil kita deploy. Caranya adalah dengan masuk ke menu Hosts pada oVirt Webmanager Web Portal. Lalu pilih New dan masukkan hostname serta kata sandi dari user root. Tunggu beberapa saat, sampai host baru reboot dan berhasil join ke datacenter oVirt. Add Host Bila berhasil, nantinya host2.ovirt.local akan muncul di oVirt Webmanager, total jumlah Host akan bertambah, dan ada alert seperti berikut. Add Host Success Tasks Success ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:4:0","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Upload ISO Sayangnya untuk mengunggah file installer ISO ke oVirt tidak terasa begitu ramah pengguna, kita perlu melakukannya secara manual seperti berikut. ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:5:0","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Mountpoint ISO Buat sebuah direktori baru bernama nfs-iso dalam mountpoint NFS untuk Storage Domain khusus bagi ISO. mkdir -p /mnt/storage1/nfs-iso chmod 777 /mnt/storage1/nfs-iso ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:5:1","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"New Storage Domain Pada oVirt Webmanager pilih masuk ke bagian Storage Domains, kemudian klik New Domains. New Storage Domain New Storage Domain Successfully Created ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:5:2","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Enable User Kita ubah shell milik user vdsm dari yang sebelumnya /sbin/nologin menjadi /bin/bash lalu login ke dalam user tersebut. usermod -s /bin/bash vdsm su - vdsm ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:5:3","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Lokasi Direktori tree /rhev/data-center/mnt Setelah menjalankan perintah di atas, perhatikan output dari perintah tree dengan teliti karena kita akan membutuhkan letak full path dari sebuah direktori bernama 11111111-1111-1111-1111-111111111111. /rhev/data-center/mnt └── host1.ovirt.local:_mnt_storage1_nfs-iso └── 7818ab21-eb15-4421-bd17-68d1f3a772b4 ├── dom_md │ ├── ids │ ├── inbox │ ├── leases │ ├── metadata │ └── outbox └── images └── 11111111-1111-1111-1111-111111111111 ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:5:4","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Rsync File Masih di dalam user vdsm kita dapat menyalin file dari komputer lain dengan rsync atau scp melalui SSH. rsync -aPv pwn3r@192.168.122.1:/run/media/pwn3r/DATA/ISOs/ubuntu-18.04.6-live-server-amd64.iso /rhev/data-center/mnt/host1.ovirt.local\\:_mnt_storage1_nfs-iso/7818ab21-eb15-4421-bd17-68d1f3a772b4/images/11111111-1111-1111-1111-111111111111/ Perhatian Pemilik IP 192.168.122.1 adalah komputer saya dengan username pwn3r, sesuaikan dengan environment kalian masing - masing. Dari sini saya menyalin file ISO Ubuntu Server dari komputer saya menuju ke Storage Domain di dalam oVirt. ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:5:5","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Disable User Jika sudah, jangan lupa untuk logout dari user vdsm dan mematikan akses shell. logout usermod -s /sbin/nologin vdsm ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:5:6","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Check ISO File Coba lihat dari sisi oVirt Webmanager apakah file ISO sudah muncul seberti berikut ini. Uploaded ISO ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:5:7","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Create VM ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:6:0","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"New VM Buka menu Virtual Machines pada oVirt Webmanager lalu pilih New. Create New VM Silahkan buat disk baru yang akan digunakan oleh VM baru. Create Disk for New VM Sesuaikan resource memori dan CPU yang akan dialokasikan untuk VM. Resource Limit for New VM ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:6:1","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Install OS on VM with ISO Saat pertamakali membuat, VM akan dalam keadaan Powered Off, pilih Run Once dan attach file ISO yang telah kita upload sebelumnya. Run Once For OS Installation Untuk melakukan remote menggunakan protokol SPICE, klik VM yang kita nyalakan dan pilih Console. Web Browser akan mengunduh sebuah file bernama console.vv yang dapat kita buka menggunakan tool bernama virt-viewer. Jika belum ada, silahkan install terlebih dahulu pada komputer kalian. sudo pacman -Sy virt-viewer Info Komputer saya menjalankan distro Artix Linux sehingga menggunakan package manager pacman. Silahkan sesuaikan dengan distro yang kalian gunakan. Berikut ini adalah tampilan dari VM yang berjalan di atas oVirt, sedang menjalankan instalasi Ubuntu Server menggunakan ISO yang telah kita upload ke Storage Domain lewat NFS. Installing Ubuntu Server ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:6:2","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Eject ISO Ketika proses instalasi telah selesai, Ubuntu akan meminta reboot VM. Jangan lupa untuk eject ISO terlebih dahulu agar VM booting menggunakan disk. Eject ISO ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:6:3","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Uji Coba Instalasi OS telah berhasil dilakukan pada VM di atas, jika dilihat pada sisi oVirt Webmanager akan terlihat statusnya Up yang menandakan VM telah berjalan. VM juga sudah dapat mengakses internet VM Running Sementara berikut ini adalah Overview dari oVirt Webmanager, terlihat bahwa dua VM sedang berjalan dan resource berkurang karena digunakan oleh VM baru. oVirt Overview ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:6:4","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Kesimpulan Tentunya di production grade RHV lebih banyak diminati karena tersedianya support, dan oVirt menjadi alternatif jika ingin merasakan teknologi virtualisasi ini tanpa perlu biaya subscription. Harap dicatat bahwa dibutuhkan effort lebih untuk produk community yang dapat dipakai secara bebas tanpa biaya langganan jika misalnya kita mendapati masalah atau issue. Selain RHV dan oVirt, masih ada banyak teknologi di level hypervisor yang dapat kita jadikan referensi seperti misalnya vSphere, Proxmox, ESXi, hingga OpenStack. Dari segi fitur, lumayan banyak yang bisa kita manfaatkan di oVirt dan RHV. Namun untuk Web Interface saya rasa masih kurang user friendly jika dibandingkan kompetitornya. ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:7:0","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Platform"],"content":"Referensi ovirt.org/documentation/installing_ovirt_as_a_self-hosted_engine_using_the_command_line/index.html ovirt.org/develop/architecture/architecture.html www.linux-kvm.org/page/FAQ wiki.archlinux.org/title/libvirt wiki.archlinux.org/title/QEMU wiki.archlinux.org/title/KVM www.desktop-virtualization.com/2008/05/01/qumranet-solid-ice www.desktop-virtualization.com/2008/09/09/redhat-acquires-qumranet-for-107m access.redhat.com/documentation/en-us/red_hat_virtualization/4.4/html-single/administration_guide/index#Copy_ISO_to_ISO_domain-storage_tasks access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/deploying_different_types_of_servers/exporting-nfs-shares_deploying-different-types-of-servers ubuntu.com/tutorials/install-ubuntu-server ","date":"2021-11-30","objectID":"/virtualisasi-infrastruktur-dengan-ovirt/:8:0","tags":["Virtualization","oVirt","RHEV","RHV","Hypervisor","Infrastructure"],"title":"Virtualisasi Infrastruktur dengan oVirt","uri":"/virtualisasi-infrastruktur-dengan-ovirt/"},{"categories":["Tools"],"content":"Memanfaatkan InfluxDB v2 untuk resource usage monitoring cluster Kubernetes","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"InfluxDB merupakan time-series database yang dibangun menggunakan bahasa pemrograman Go, dan dikembangkan oleh InfluxData. InfluxDB dioptimasi agar mampu berjalan dengan cepat dan mendukung konsep high-availability untuk menerima time-series data yang dipakai dalam hal monitoring, application metrics, data Internet of Things, hingga analisa secara real-time. ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:0:0","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"InfluxDB InfluxData memiliki beberapa macam produk, salah satunya yang akan kita gunakan adalah InfluxDB OSS (Open Source Software). Selain InfluxDB OSS, sebenarnya terdapat produk lain yang berbayar seperti InfluxDB Cloud dengan model SaaS (Software as a Service) dan InfluxDB Enterprise. Sedangkan untuk versi, saat artikel ini dibuat InfluxDB v2 adalah yang paling baru dan sudah diklaim sebagai versi stabil. InfluxDB Enterprise dapat mendukung high-availability sehingga kita dapat membangunnya menjadi seperti sebuah cluster, sedangkan InfluxDB OSS tidak mendukung fitur tersebut. Monitor Kubernetes with InfluxDB ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:1:0","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"TICK Stack Bagi pemula atau orang awam, perbedaan dari InfluxDB v1 dan InfluxDB v2 adalah dalam hal modulnya. InfluxDB v1 lebih modular, dalam artian masing-masing komponen perlu dipasang untuk dapat berjalan menjadi satu tumpukan teknologi yang dalam sering disebut sebagai TICK Stack. TICK merupakan singkatan dari Telegraf InfluxDB Chronograf Kapacitor, keempat komponen tersebut memiliki tugas masing-masing. Telegraf akan melakukan mengumpulkan data, InfluxDB untuk menampung data yang telah dikumpulkan, Chronograf dipakai untuk visualisasi dan pengelolaan data, lalu Kapacitor digunakan untuk melakukan alerting. Untuk InfluxDB v2 beberapa komponen sebelumnya di-bundle menjadi single-binary yang disebut sebagai InfluxDB saja. Beberapa komponen tersebut adalah InfluxDB, Chronograf, dan Kapacitor. Sedangkan untuk Telegraf masih terpisah, karena Telegraf bisa saja dijalankan di perangkat terpisah dan berfungsi untuk mengumpulkan data yang bisa saja lebih dari satu perangkat. Arsitektur InfluxDB v2 ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:1:1","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Planning Dalam artikel ini InfluxDB akan saya jalankan di atas cluster Kubernetes menggunakan objek StatefulSet sehingga persistent volume diperlukan supaya database tidak akan terhapus ketika pod mengalami restart atau terhapus. Lalu Telegraf akan saya jalankan sebagai objek DaemonSet supaya dapat mengambil data dari semua Nodes yang bergabung pada cluster. Untuk mempermudah proses deploy InfluxDB, sudah ada Helm chart yang disediakan. Namun karena saat artikel ini dibuat, Helm bagi InfluxDB masih belum stable saya lebih memilih menulis dalam bentuk YAML, dan hanya menggunakan Helm untuk men-deploy Telegraf saja. ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:1:2","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Deploy InfluxDB Sebelum lebih lanjut, saya membuat sebuah namespace khusus bernama monitoring yang akan berisi seluruh objek terkait InfluxDB. ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:2:0","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Membuat Namespace kubectl create namespace monitoring ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:2:1","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Deploy InfluxDB Silahkan sesuaikan script YAML berikut ini dengan environment yang ada. --- apiVersion: v1 kind: Secret metadata: labels: app: influxdb name: influxdb-auth namespace: monitoring type: Opaque data: # Random alphanumeric 32 karakter dengan base64 # Contoh: # cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1 # g71Kv9SUBnk7yqUQLw8UJV08jq3i4Vcl # echo -n 'g71Kv9SUBnk7yqUQLw8UJV08jq3i4Vcl' | base64 # ZzcxS3Y5U1VCbms3eXFVUUx3OFVKVjA4anEzaTRWY2w= admin-token: ZzcxS3Y5U1VCbms3eXFVUUx3OFVKVjA4anEzaTRWY2w= # Ubah plaintext password ke bae64 # Contoh: # echo -n 'administrator' | base64 # YWRtaW5pc3RyYXRvcg== admin-password: YWRtaW5pc3RyYXRvcg== --- # PDB Untuk menjaga jumlah replikasi # https://kubernetes.io/docs/concepts/workloads/pods/disruptions/#pod-disruption-budgets apiVersion: policy/v1beta1 kind: PodDisruptionBudget metadata: name: influxdb labels: app: influxdb namespace: monitoring spec: minAvailable: 1 # maxAvailable: 1 selector: matchLabels: app: influxdb --- apiVersion: apps/v1 kind: StatefulSet metadata: labels: app: influxdb name: influxdb namespace: monitoring spec: replicas: 1 selector: matchLabels: app: influxdb serviceName: influxdb template: metadata: labels: app: influxdb spec: containers: - image: influxdb:2.0.6 name: influxdb ports: - containerPort: 8086 name: influxdb volumeMounts: - mountPath: /var/lib/influxdb2 name: data env: - name: DOCKER_INFLUXDB_INIT_MODE value: setup - name: DOCKER_INFLUXDB_INIT_ORG value: influxdata - name: DOCKER_INFLUXDB_INIT_BUCKET value: demo - name: DOCKER_INFLUXDB_INIT_RETENTION value: 12h - name: DOCKER_INFLUXDB_INIT_USERNAME value: admin - name: DOCKER_INFLUXDB_INIT_PASSWORD valueFrom: secretKeyRef: name: influxdb-auth key: admin-password - name: DOCKER_INFLUXDB_INIT_ADMIN_TOKEN valueFrom: secretKeyRef: name: influxdb-auth key: admin-token volumeClaimTemplates: - metadata: name: data namespace: monitoring spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi --- apiVersion: v1 kind: Service metadata: name: influxdb namespace: monitoring spec: type: ClusterIP ports: - name: influxdb port: 8086 targetPort: 8086 selector: app: influxdb --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: influxdb namespace: monitoring labels: name: influxdb spec: rules: - host: tick.k8s.local http: paths: - path: / pathType: Prefix backend: service: name: influxdb port: number: 8086 Simpan script tersebut, misalnya dengan nama influxdb.yaml dan jalankan perintah declarative berikut. kubectl apply -f influxdb.yaml ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:2:2","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Memeriksa Objek InfluxDB Silahkan periksa apakah semua objek telah berhasil dibuat. kubectl -n monitoring get all; kubectl -n monitoring get pvc; kubectl -n monitoring get ingress Jika StatefulSet telah membuat sebuah Pod, Service, PersistentVolumeClaim, dan Ingress telah terbuat maka kurang lebih akan muncul tampilan seperti berikut. NAME READY STATUS RESTARTS AGE pod/influxdb-0 1/1 Running 0 49s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/influxdb ClusterIP 10.104.71.97 \u003cnone\u003e 8086/TCP 49s NAME READY AGE statefulset.apps/influxdb 1/1 49s NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE data-influxdb-0 Bound pvc-8b746bbc-2bf8-4d3a-9358-a66442bb6c88 1Gi RWO standard 49s NAME CLASS HOSTS ADDRESS PORTS AGE influxdb \u003cnone\u003e tick.k8s.local 192.168.39.26 80 49s Perhatian Saya menggunakan NGINX Ingress Controller untuk mengekspos Service dengan objek Ingress, serta PersistentVolume berjenis hostPath, silahkan sesuaikan dengan kebutuhan di environment. ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:2:3","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"InfluxDB Secret File YAML tersebut juga akan membuat sebuah objek Secret bernama influxdb-auth untuk menyimpan admin-password dan admin-token. Nantinya token akan dipakai oleh agent Telegraf untuk melakukan store data ke InfluxDB, sedangkan password akan kita pakai untuk masuk ke dalam UI InfluxDB. Jalankan perintah berikut untuk menampilkan admin-password dalam bentuk plain-text. echo $(kubectl get secret influxdb-auth -o \"jsonpath={.data['admin-password']}\" \\ --namespace monitoring | base64 --decode) Jalankan perintah berikut untuk menampilkan admin-token dalam bentuk plain-text. echo $(kubectl get secret influxdb-auth -o \"jsonpath={.data['admin-token']}\" \\ --namespace monitoring | base64 --decode) ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:2:4","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Deploy Telegraf Entah saya belum terlalu memahami atau apa, Telegraf membutuhkan dua macam Helm chart supaya dapat berjalan di kubernetes yang akan membuat dua macam objek (DaemonSet dan Deployment). ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:3:0","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Add Repo Helm Karena kita akan men-deploy Telegraf menggunakan Helm chart, mari kita siapkan terlebih repository influxdata terlebih dahulu. helm repo add influxdata https://helm.influxdata.com/ ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:3:1","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Values Kita perlu mempersiapkan value untuk menampung beberapa argumen. Pertama mari membuat file values-ds.yaml berisi script seperti berikut. config: outputs: - influxdb_v2: urls: - \"http://influxdb.monitoring.svc.cluster.local:8086\" bucket: \"demo\" token: \"g71Kv9SUBnk7yqUQLw8UJV08jq3i4Vcl\" organization: \"influxdata\" monitor_self: true Kemudian kita buat lagi file lain bernama values-inventory.yaml berisi script berikut. service: enabled: true type: ClusterIP metrics: health: enabled: true rbac: create: true clusterWide: true rules: - apiGroups: - \"*\" resources: - \"*\" verbs: - \"*\" - nonResourceURLs: - \"*\" verbs: - \"get\" - \"list\" - \"watch\" config: outputs: - influxdb_v2: urls: - \"http://influxdb.monitoring.svc.cluster.local:8086\" bucket: \"demo\" token: \"g71Kv9SUBnk7yqUQLw8UJV08jq3i4Vcl\" organization: \"influxdata\" inputs: - kube_inventory: url: \"https://kubernetes.default\" bearer_token: \"/run/secrets/kubernetes.io/serviceaccount/token\" insecure_skip_verify: true namespace: \"\" monitor_self: true Sesuaikan config pada bagian bucket, token, dan organization seperti yang kita definisikan pada file influxdb.yaml. Sedangkan untuk urls dilihat berdasarkan URL dari objek Service yang telah kita buat, gunakan perintah berikut untuk mencari tahu. kubectl -n monitoring describe services influxdb Tips Biasanya URL dari service akan berbentuk seperti berikut: \u003cservice-name\u003e.\u003cnamespace\u003e.svc.cluster.local:\u003cservice-port\u003e Jika semua file value sudah terbuat, sekarang saatnya kita jalankan Helm chart. helm upgrade -n monitoring --install telegraf-ds -f telegraf/values-ds.yaml influxdata/telegraf-ds helm upgrade -n monitoring --install telegraf-inventory -f telegraf/values-inventory.yaml influxdata/telegraf ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:3:2","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Memeriksa Objek Telegraf Kita dapat memeriksa apakah semua objek Telegraf telah berjalan dengan perintah berikut. kubectl -n monitoring get all Jika sudah berjalan maka kurang lebih akan muncul tampilan seperti berikut. NAME READY STATUS RESTARTS AGE pod/influxdb-0 1/1 Running 0 49m pod/telegraf-ds-8rzbh 1/1 Running 0 4m17s pod/telegraf-inventory-56d799f599-k74zg 1/1 Running 0 2m59s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/influxdb ClusterIP 10.104.71.97 \u003cnone\u003e 8086/TCP 49m service/telegraf-inventory ClusterIP 10.100.248.149 \u003cnone\u003e 8888/TCP 2m59s NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE daemonset.apps/telegraf-ds 1 1 1 1 1 \u003cnone\u003e 4m17s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/telegraf-inventory 1/1 1 1 2m59s NAME DESIRED CURRENT READY AGE replicaset.apps/telegraf-inventory-56d799f599 1 1 1 2m59s NAME READY AGE statefulset.apps/influxdb 1/1 49m Apabila kurang yakin silahkan periksa log dari kedua Pod Telegraf diatas. ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:3:3","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"InfluxDB UI URL dari InfluxDB dapat kita lihat dari objek Ingress. kubectl -n monitoring get ingress Di sini misalnya akan muncul output seperti berikut. NAME CLASS HOSTS ADDRESS PORTS AGE influxdb \u003cnone\u003e tick.k8s.local 192.168.39.26 80 55m Kita dapat mengakses http://tick.k8s.local menggunakan web browser dan login menggunakan username dan password yang telah kita definisikan sesuai file influxdb.yaml sebelumnya. InfluxDB UI ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:4:0","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Template Boards Kubernetes Tersedia template boards untuk Kubernetes yang bisa kita dapatkan tanpa biaya. Pada InfluxDB UI buka menu Settings \u003e Templates \u003e Browse Community Templates, maka kita akan diarahkan menuju GitHub Repository. Di sana kita dapat mencari sebuah template bernama Kubernetes Dashboards yang dikembangkan oleh bonitoo.io. Ikuti saja alur petunjuk pemasangan template, jika berhasil akan muncul tampilan seperti berikut. Kubernetes Template InfluxDB Installed Kubernetes Template InfluxDB Selanjutnya jika kita buka menu Boards akan muncul dua Dashboard seperti berikut. Kubernetes Dashboard InfluxDB Silahkan coba buka kedua Dashboard tersebut, namun jangan lupa untuk merubah Variables dari _monitoring menjadi demo seperti nama bucket yang telah kita buat pada file influxdb.yaml sebelumnya. Variable Dashboard Jika sudah benar, seharusnya akan muncul tampilan dari kedua Dashboard seperti berikut. Monitor Kubernetes Inventory Monitor Kubernetes Node Metrics ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:4:1","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Uninstall Jika ingin menghapus objek yang telah kita buat, kita dapat menghapusnya secara bertahap seperti berikut. helm uninstall -n monitoring telegraf-inventory helm uninstall -n monitoring telegraf-ds kubectl delete -f influxdb.yaml Karena InfluxDB di-deploy sebagai StatefulSet maka PVC tidak akan terhapus secara otomatis, apabila kita ingin menghapusnya kita harus melakukannya secara manual. kubectl -n monitoring delete pvc data-influxdb-0 Selanjutnya kita hapus bagian terakhir, yaitu namespace. kubectl delete namespace monitoring ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:5:0","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Kesimpulan InfluxDB dapat kita gunakan sebagai alternatif monitoring dan logging cluster Kubernetes, namun menggunakan versi OSS (Open Source Software) atau Community tidaklah bijak bagi production environment, terutama kita akan kekurangan layanan customer support secara langsung dari InfluxData. Dalam file influxdb.yaml kita perlu melakukan beberapa penyesuaian, misalnya adalah peningkatan kapasitas storage karena saya hanya menulisnya sebanyak 1Gi dan retention hanya 12h. Masih ada banyak hal yang perlu saya explore terkait InfluxDB, terutama dalam melakukan query terhadap data yang ada dalam bucket. ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:6:0","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Referensi docs.influxdata.com/influxdb/v2.0/install/?t=Kubernetes github.com/influxdata/helm-charts github.com/influxdata/telegraf/tree/master/plugins/inputs/kube_inventory kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumes-typed-hostpath github.com/influxdata/community-templates/tree/master/k8s kubernetes.github.io/ingress-nginx/deploy helm.sh/docs/intro/using_helm www.gojek.io/blog/diy-set-up-telegraf-influxdb-grafana-on-kubernetes www.influxdata.com/blog/introducing-the-next-generation-influxdb-2-0-platform ","date":"2021-06-18","objectID":"/monitoring-kubernetes-dengan-influxdb-v2/:7:0","tags":["InfluxDB","TICK","Monitoring","Kubernetes"],"title":"Monitoring Kubernetes dengan InfluxDB v2","uri":"/monitoring-kubernetes-dengan-influxdb-v2/"},{"categories":["Tools"],"content":"Nexus Repository Manager Sebagai Private Image Registry","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"NXRM atau Nexus Repository Manager merupakan open source tool yang digunakan untuk mengelola repository multi-guna, meliputi Docker Image Registry, Java Maven, NPM, Rubygems, YUM, hingga APT. Private Repository sangat berguna bagi environment lokal yang tidak terhubung ke internet secara langsung, selain itu juga dapat digunakan untuk mengurangi penggunaan bandwidth internet, atau meningkatkan kecepatan push and pull image bagi container. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:0:0","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Sonatype NXRM NXRM Sonatype merilis NXRM menjadi dua macam, yaitu OSS (Open Source Software) yang dapat digunakan tanpa biaya, dan Pro yang memiliki beberapa fitur unggulan tambahan. Terkait komparasi antara kedua versi tersebut dapat dilihat pada link berikut atau ini. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:1:0","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Prerequisites Nexus memerlukan beberapa prasyarat yang harus dipenuhi sebelum instalasi seperti berikut. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:2:0","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Hardware Specifications Pada saat artikel ini ditulis, saya akan menggunakan Nexus Repository Manager 3. NXRM membutuhkan spesifikasi hardware minimum seperti berikut: 8GB RAM 4 CPUs 500GB disk space Terdengar lumayan besar, namun hal ini adalah hal yang wajar dalam membangun sebuah repository server. Image Registry akan membutuhkan storage yang besar, dan disk space yang kurang besar akan dengan mudah menjadi penuh nantinya. Tetapi karena dalam artikel ini saya hanya ingin melakukan percobaan saja, maka saya cukup menggunakan 20GB storage saja. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:2:1","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"System Requirements Nexus dapat dipasang langsung diatas VM/OS atau bisa juga dijalankan di dalam container, dalam artikel ini saya akan langsung memasangnya diatas VM yang menggunakan distro RHEL 8. Sebelum lebih lanjut, kita perlu melakukan beberapa hal berikut agar NXRM dapat berjalan. Dedicated User Buat sebuah user, misalnya bernama nexus dengan perintah berikut. sudo useradd nexus Kemudian berikan password pada user tersebut. sudo passwd nexus Kita hendaknya tidak pernah menjalankan Nexus menggunakan user root. Nantinya user nexus inilah yang akan kita pakai untuk menjalankan Nexus. File Handle Limits Tambahkan batasan file handle pada file /etc/security/limits.conf bagi user yang telah kita buat. nexus - nofile 65536 Instal Java Runtime Environment NXRM membutuhkan setidaknya JRE 8 untuk berjalan, jika belum ada maka pasang terlebih dahulu. sudo dnf install -y java-1.8.0-openjdk Di artikel ini saya menggunakan OpenJDK 1.8.0 sebagai Java Runtime Environment. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:2:2","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Instalasi Berikut ini adalah langkah-langkah yang dilakukan untuk memasang dan menjalankan NXRM pada RHEL 8. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:0","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Download NXRM Jalankan perintah berikut untuk mengunduh NXRM. Kemudian extract ke direktori /opt seperti berikut. wget https://download.sonatype.com/nexus/3/latest-unix.tar.gz sudo tar xvf latest-unix.tar.gz -C /opt/ ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:1","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Edit Konfigurasi NXRM Ubah beberapa konfigurasi yang diperlukan pada /opt/nexus*/bin/nexus.rc untuk memasukkan user yang akan digunakan untuk menjalankan proses. run_as_user=\"nexus\" Sedangkan /opt/nexus*/bin/nexus.vmoptions akan digunakan untuk konfigurasi yang berkaitan dengan Runtime Environment. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:2","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"SELinux Label dan File Permission Ubah user dan group owner pada direktori nexus. sudo chown -R nexus:nexus /opt/nexus* sudo chown -R nexus:nexus /opt/sonatype-work Tambahkan SELinux label yang sesuai pada direktori nexus tersebut. sudo semanage fcontext -a -t initrc_t \"/opt/nexus*(/.*)?\" sudo semanage fcontext -a -t initrc_exec_t \"/opt/nexus*(/.*)?\" sudo restorecon -Rv /opt/nexus* ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:3","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Membuat Service Systemd Jika kita memakai Systemd sebagai init system, maka kita perlu membuat sebuah file service baru. sudo vi /etc/systemd/system/nexus.service Di dalamnya bisa diisi konfigurasi seperti berikut. [Unit] Description=Nexus Service After=network.target [Service] Type=forking LimitNOFILE=65536 ExecStart=/opt/nexus-3.30.1-01/bin/nexus start ExecStop=/opt/nexus-3.30.1-01/bin/nexus stop User=nexus Group=nexus Restart=on-abort TimeoutSec=600 [Install] WantedBy=multi-user.target Perhatian 3.30.1-01 merupakan versi dari Nexus Repository Manager yang saya gunakan saat artikel ini dibuat, sesuaikan dengan versi yang akan kalian gunakan. Dengan menjadikan NXRM sebagai Service, maka NXRM dapat berjalan secara otomatis apabila OS mengalami reboot. Pastikan juga file systemd service tersebut mempunyai permission yang benar. sudo chmod 644 /etc/systemd/system/nexus.service ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:4","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"chkconfig Jalankan perintah chkconfig seperti berikut. sudo chkconfig nexus on ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:5","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Buka Port untuk NXRM Karena by-default firewalld tidak memperbolehkan akses port dari luar, maka kita perlu membukanya. sudo firewall-cmd --permanent --add-port=8081/tcp sudo firewall-cmd --reload NXRM akan listening pada port 8081 supaya dapat diakses melalui web browser. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:6","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Enable Service NXRM Enable service NXRM supaya ikut berjalan otomatis bersama OS saat pertamakali dihidupkan. sudo systemctl daemon-reload sudo systemctl enable --now nexus.service ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:7","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Mengganti Password Admin Dapatkan password bawaan dari NXRM untuk login melalui web browser yang disimpan pada /opt/sonatype-work/nexus3/admin.password seperti berikut. sudo cat /opt/sonatype-work/nexus3/admin.password Lalu buka alamat IP port 8081 pada web browser, dan login menggunakan user admin dan password diatas. Ganti Password Perhatian 192.168.122.3 merupakan IP dari VM yang saya jalankan untuk memasang NXRM, sesuaikan dengan environment kalian masing-masing. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:8","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Create Repository Buat repository baru yang akan kita gunakan sebagai image registry. Silahkan centang sesuai gambar berikut. Membuat Repository Pada artikel ini, saya akan menggunakan port 5000 untuk Image Registry. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:9","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Realm Aktifkan Docker Bearer Token Realm. Mengaktifkan Realm ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:10","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Buka Port Image Registry Kita perlu membuka port 5000 supaya dapat diakses dari luar. sudo firewall-cmd --permanent --add-port=5000/tcp sudo firewall-cmd --reload ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:3:11","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Pengujian Dari sini saja harusnya kita sudah dapat menggunakan Image Registry di dalam NXRM yang sudah kita buat. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:4:0","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Insecure Registry Karena kita tidak mengaktifkan SSL yang sah pada repository Image Registry maka kita perlu menambahkan address Registry tersebut ke dalam Insecure Registry. Jika memakai Docker sebagai Container Runtime, maka buat file /etc/docker/daemon.json dan isi seperti berikut. { \"insecure-registries\": [ \"192.168.122.3:5000\" ] } Lalu restart Docker Service jika menggunakan Systemd. sudo systemctl restart docker.service Jika menggunakan Podman sebagai Container Runtime, maka buka file /etc/containers/registries.conf kemudian edit isinya pada bagian berikut. [registries.insecure] registries = ['192.168.122.3:5000'] Karena Podman merupakan daemonless maka kita tidak perlu melakukan restart service apapun. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:4:1","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Login Image Registry Sekarang coba login ke dalam Image Registry menggunakan user admin dan password yang sudah kita buat. docker login -u admin 192.168.122.3:5000 Jika berhasil maka akan muncul tampilan seperti berikut. Docker Login Sedangkan jika menggunakan Podman adalah seperti berikut. Podman Login ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:4:2","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Push Container Image Sebelumnya saya telah memiliki sebuah Container Image bernama localhost/mycompany dan akan coba saya push ke Image Registry. Container Image Pertama saya akan merubah tag Image tersebut. podman tag localhost/mycompany 192.168.122.3:5000/mycompany podman images Kemudian kita push container image tersebut menuju Image Registry. podman push 192.168.122.3:5000/mycompany Jika berhasil, maka kira-kira akan muncul tampilan seperti berikut. Push Image ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:4:3","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Search Container Image Kita dapat mencari container image yang tersedia pada NXRM langsung melalui Docker atau Podman. podman search 192.168.122.3:5000/ Akan terlihat container image yang tersedia di dalam image registry pada NXRM. Search Image ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:4:4","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Kesimpulan Sebenarnya masih banyak yang fitur yang tersedia dan perlu saya coba pada NXRM, namun saya rasa artikel kali ini sudah cukup panjang dan membosankan. Salah satu yang menarik adalah kita dapat menerapkan konsep High Availability dengan membangun sebuah Nexus Cluster menggunakan beberapa server sekaligus, sayangnya saya belum dapat mencobanya karena keterbatasan resource. Dari pengalaman saya di tempat kerja, Nexus dari Sonatype memang sangat sering digunakan oleh perusahan baik Telco maupun Banking untuk membangun sebuah Private Repository Manager, tidak cuma meng-handle Image Registry namun juga YUM Repository bagi distro RHEL yang berjalan sebagai node pada cluster container oschestration seperti Kubernetes. ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:5:0","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Tools"],"content":"Referensi https://help.sonatype.com/repomanager3/installation/system-requirements https://help.sonatype.com/repomanager3/installation/run-as-a-service https://help.sonatype.com/repomanager3/formats/docker-registry/pushing-images https://help.sonatype.com/repomanager3/installation/configuring-the-runtime-environment https://www.redhat.com/sysadmin/manage-container-registries http://docs.podman.io/en/latest/markdown/podman-pull.1.html ","date":"2021-05-24","objectID":"/nxrm-untuk-private-image-registry/:6:0","tags":["Nexus","Container","Registry","Repository"],"title":"NXRM untuk Private Image Registry","uri":"/nxrm-untuk-private-image-registry/"},{"categories":["Platform"],"content":"Source to Image untuk Deployment di Red Hat OpenShift Container Platform","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"S2I atau Source to Image adalah sebuah tool untuk mempermudah membangun container images dari source code. Tool ini mengambil source code aplikasi dari repositori Git, melakukan injeksi source code ke dalam base container berdasarkan bahasa pemrograman dan framework tertentu, kemudian memproduksi sebuah container image baru, lalu container image tersebut akan dipakai untuk menjalankan aplikasi yang telah dirakit. S2I pada OpenShift ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:0:0","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Image Stream OpenShift mendeploy aplikasi versi baru ke dalam pod secara cepat. Base Image (S2I buider image) dibutuhkan untuk membuat aplikasi dengan update terbaru, jika ada perubahan pada source code. Ketika komponen source code aplikasi mengalami perubahan, OpenShift akan menciptakan container image baru. Pod yang telah dibuat dengan container image lama akan digantikan dengan pod yang menggunakan image baru. Resource Image Stream merupakan konfigurasi yang menamai container image secara spesifik yang berkaitan dengan tag image stream. OpenShift membangun aplikasi berdasarkan image stream. OpenShift installer telah menyediakan beberapa image stream secara default sejak awal. Untuk menemukan image stream yang tersedia, gunakan perintah oc get seperti berikut. $ oc get is -n openshift NAME IMAGE REPOSITORY TAGS dotnet ...svc:5000/openshift/dotnet 2.0,2.1,latest nodejs ...svc:5000/openshift/nodejs 0.10,10,11,4,6,8,latest perl ...svc:5000/openshift/perl 5.16,5.20,5.24,5.26,latest php ...svc:5000/openshift/php 5.5,5.6,7.0,7.1,latest python ...svc:5000/openshift/python 2.7,3.3,3.4,3.5,3.6,latest ruby ...svc:5000/openshift/ruby 2.0,2.2,2.3,2.4,2.5,latest OpenShift juga mendeteksi jika image stream berubah dan akan melakukan reaksi berdasarkan perubahan tersebut. Jika sebuah security issue muncul, misalnya (CVE) pada image bernama nodejs-010-rhel7, maka OpenShift akan melakukan update secara otomatis. ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:1:0","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Build S2I Membangun sebuah aplikasi menggunakan S2I dapat dilakukan melalui OpenShift CLI maupun OpenShift Web Console. Dalam artikel ini, saya ingin melakukannya melalui CLI. S2I Process ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:2:0","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Via CLI Untuk membuat application di dalam project dengan proses S2I kita memakai perintah oc new-app sseperti berikut. oc new-app --as-deployment-config php~http://my.git.server.com/my-app --name=myapp Argumen php di atas dipakai untuk mendefinisikan image stream mana yang akan digunakan, diikuti oleh karakter ~. Lalu diteruskan dengan lokasi repositori Git my.git.server.com/my-app. Selain menggunakan karakter ~ kita dapat menuliskannya menggunakan opsi -i seperti berikut. oc new-app --as-deployment-config -i php http://services.lab.example.com/app --name=myapp ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:2:1","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Repositori Lokal Jika kita tidak mendefinisikan image stream, maka OpenShift akan mencoba untuk melakukan identifikasi otomatis terhadap source code guna menemukan image stream yang tepat. Command oc new-app juga dapat dilakukan ketika kita menggunakan repositori Git lokal. Misalnya jika kita sudah berapa di direktori repositori Git lokal, maka dapat kita jalankan perintah berikut. oc new-app --as-deployment-config . Perhatian Jika menggunakan repositori Git lokal, maka repositori tersebut harus memiliki konfigurasi remote origin yang mengarah ke sebuah URL. Dan URL tersebut harus dapat diakses dari klaster OpenShift. ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:2:2","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Subdirektori Kita juga dapat menjalankan aplikasi menggunakan subdirektori pada repositori Git seperti berikut. oc new-app --as-deployment-config \\ https://github.com/openshift/sti-ruby.git \\ --context-dir=2.0/test/puma-test-app ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:2:3","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Branch Dan tentu saja S2I dapat kita lakukan pada branch atau cabang tertentu dari repositori Git, seperti berikut. oc new-app --as-deployment-config \\ https://github.com/openshift/ruby-hello-world.git#beta4 ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:2:4","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Deteksi Otomatis Seperti yang sebelumnya saya tulis di atas, jika kita tidak mendefinisikan image stream maka OpenShift akan secara otomatis melakukan deteksi secara otomatis. Deteksi tersebut dilakukan berdasarkan beberapa file yang terdapat dalam repositori. Bahasa Pemrograman File Ruby Rakefile Gemfile, config.ru Java EE pom.xml Node.js app.json package.json PHP index.php composer.json Python requirements.txt config.py Perl index.pl cpanfile Setelah bahasa pemrograman terdeteksi, OpenShift akan mencari tag image stream yang mendukung, atau yang sesuai dengan nama dari bahasa pemrograman tersebut. ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:3:0","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Generate Resource Definition File Untuk membuat sebuah file definisi resource (jika dibutuhkan) kita dapat menggunakan parameter -o kemudian diikuti dengan format yang diinginkan, misalnya yaml atau json. oc -o json new-app --as-deployment-config \\ php~http://services.lab.example.com/app \\ --name=myapp \u003e s2i.json Dan kita akan mendapatkan file bernama s2i.json berisi seperti berikut. ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:4:0","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Image Stream Definition ... { \"kind\": \"ImageStream\", \"apiVersion\": \"image.openshift.io/v1\", \"metadata\": { \"name\": \"myapp\", \"creationTimestamp\": null \"labels\": { \"app\": \"myapp\" }, \"annotations\": { \"openshift.io/generated-by\": \"OpenShiftNewApp\" } }, \"spec\": { \"lookupPolicy\": { \"local\": false } }, \"status\": { \"dockerImageRepository\": \"\" } }, ... Dapat kita lihat bahwa terdapat pendefinisian resource \"kind\": \"ImageStream\" dan resource tersebut akan memakai nama yang sama dengan parameter --name. ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:4:1","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Build Configuration Definition ... { \"kind\": \"BuildConfig\", \"apiVersion\": \"build.openshift.io/v1\", \"metadata\": { \"name\": \"myapp\", \"creationTimestamp\": null, \"labels\": { \"app\": \"myapp\" }, \"annotations\": { \"openshift.io/generated-by\": \"OpenShiftNewApp\" } }, \"spec\": { \"triggers\": [ { \"type\": \"GitHub\", \"github\": { \"secret\": \"S5_4BZpPabM6KrIuPBvI\" } }, { \"type\": \"Generic\", \"generic\": { \"secret\": \"3q8K8JNDoRzhjoz1KgMz\" } }, { \"type\": \"ConfigChange\" }, { \"type\": \"ImageChange\", \"imageChange\": {} } ], \"source\": { \"type\": \"Git\", \"git\": { \"uri\": \"http://services.lab.example.com/app\" } }, \"strategy\": { \"type\": \"Source\", \"sourceStrategy\": { \"from\": { \"kind\": \"ImageStreamTag\", \"namespace\": \"openshift\", \"name\": \"php:7.3\" } } }, \"output\": { \"to\": { \"kind\": \"ImageStreamTag\", \"name\": \"myapp:latest\" } }, \"resources\": {}, \"postCommit\": {}, \"nodeSelector\": null }, \"status\": { \"lastVersion\": 0 } }, ... Di dalam file tersebut kita juga akan mendapati resource \"kind\": \"BuildConfig\". Build config atau bc bertanggung jawab untuk mendefinisikan parameter input dan trigger yang akan dieksekusi untuk merubah source code menjadi container image. ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:4:2","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Deployment Configuration Definition ... { \"kind\": \"DeploymentConfig\", \"apiVersion\": \"apps.openshift.io/v1\", \"metadata\": { \"name\": \"myapp\", \"creationTimestamp\": null, \"labels\": { \"app\": \"myapp\" }, \"annotations\": { \"openshift.io/generated-by\": \"OpenShiftNewApp\" } }, \"spec\": { \"strategy\": { \"resources\": {} }, \"triggers\": [ { \"type\": \"ConfigChange\" }, { \"type\": \"ImageChange\", \"imageChangeParams\": { \"automatic\": true, \"containerNames\": [ \"myapp\" ], \"from\": { \"kind\": \"ImageStreamTag\", \"name\": \"myapp:latest\" } } } ], \"replicas\": 1, \"test\": false, \"selector\": { \"app\": \"myapp\", \"deploymentconfig\": \"myapp\" }, \"template\": { \"metadata\": { \"creationTimestamp\": null, \"labels\": { \"app\": \"myapp\", \"deploymentconfig\": \"myapp\" }, \"annotations\": { \"openshift.io/generated-by\": \"OpenShiftNewApp\" } }, \"spec\": { \"containers\": [ { \"name\": \"myapp\", \"image\": \"myapp:latest\", \"ports\": [ { \"containerPort\": 8080, \"protocol\": \"TCP\" }, { \"containerPort\": 8443, \"protocol\": \"TCP\" } ], \"resources\": {} } ] } } }, \"status\": { \"latestVersion\": 0, \"observedGeneration\": 0, \"replicas\": 0, \"updatedReplicas\": 0, \"availableReplicas\": 0, \"unavailableReplicas\": 0 } }, ... Resource selanjutnya adalah Deployment Configuration atau dc yang bertanggung jawab untuk melakukan preferensi proses deployment di OpenShift. Di dalamnya dapat berisi parameter dan trigger yang diperlukan untuk membuat container, dan diterjemahkan menjadi replication controller. Beberapa manfaat yang disediakan oleh objek DeploymentConfig adalah sebagai berikut. Dapat dilakukannya kustomisasi strategi terhadap deployment. Dapat digunakan untuk Rollback ke deployment sebelumnya. Dapat dipakai untuk scaling replikasi secara manual. ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:4:3","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Service Definition ... { \"kind\": \"Service\", \"apiVersion\": \"v1\", \"metadata\": { \"name\": \"myapp\", \"creationTimestamp\": null, \"labels\": { \"app\": \"myapp\" }, \"annotations\": { \"openshift.io/generated-by\": \"OpenShiftNewApp\" } }, \"spec\": { \"ports\": [ { \"name\": \"8080-tcp\", \"protocol\": \"TCP\", \"port\": 8080, \"targetPort\": 8080 }, { \"name\": \"8443-tcp\", \"protocol\": \"TCP\", \"port\": 8443, \"targetPort\": 8443 } ], \"selector\": { \"app\": \"myapp\", \"deploymentconfig\": \"myapp\" } }, \"status\": { \"loadBalancer\": {} } } Terakhir kita akan mendapati resource Service atau svc yang berfungsi untuk menghubungkan setiap container yang ada di dalam klaster. Perhatian Command oc new-app secara default tidak akan membuat resource route. Route berfungsi untuk melakukan ingress traffic dari luar klaster supaya dapat mengakses aplikasi. Jika kita menggunakan OpenShift Web Console, maka route akan dibuat secara otomatis menggunakan template yang telah tersedia. ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:4:4","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Memeriksa Deployment Setelah membuat application seperti di atas, proses build akan dijalankan. Gunakan command oc get builds untuk melihat daftar build aplikasi. $ oc get builds NAME TYPE FROM STATUS STARTED DURATION php-helloworld-1 Source Git@9e17db8 Running 13 seconds ago Kita dapat melihat log dari build menggunakan perintah berikut. oc logs build/myapp-1 Perhatian Jika status build belum menampilkan Running, atau OpenShift belum mendeploy pod s2i-build maka output berupa error akan muncul dari log. ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:5:0","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Trigger Build Kita dapat me-trigger build baru berdasarkan bc (Build Config) yang tersedia dengan perintah berikut. ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:6:0","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Melihat BuildConfig $ oc get buildconfig NAME TYPE FROM LATEST myapp Source Git 1 ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:6:1","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Menjalankan Build $ oc start-build myapp build \"myapp-2\" started ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:6:2","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Kesimpulan Alur S2I Pod BuildConfig dipakai untuk membuat image dalam OpenShift dan melakukan push ke container registry internal. Setiap konten atau source code yang mengalami perubahan biasanya membutuhkan build baru untuk menjamin supaya image terupdate. Pod DeploymentConfig digunakan untuk mendeploy pod dalam OpenShift. Hasilnya adalah deployment pod dengan image dari container registry internal. Setiap pod yang sebelumnya telah ada akan di-destroy, tergantung dari bagaimana resource DeploymentConfig dibuat. BuildConfig dan DeploymentConfig tidak berinteraksi secara langsung. BuildConfig membuat atau mengupdate container image, sedangkan DeploymentConfig akan bereaksi kepada image baru tersebut dan kemudian membuat pod baru darinya. ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:7:0","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["Platform"],"content":"Referensi access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html-single/builds/build-strategies#build-strategy-s2i_build-strategies github.com/openshift/source-to-image www.youtube.com/watch?v=flI6zx9wH6M ","date":"2021-04-02","objectID":"/deployment-dengan-s2i-process-openshift/:8:0","tags":["OpenShift","PaaS","S2I","Deployment"],"title":"Deployment dengan S2I Process OpenShift","uri":"/deployment-dengan-s2i-process-openshift/"},{"categories":["GNU/Linux"],"content":"Bagaimana kombinasi mounting filesystem bekerja dan penerapannya pada teknologi container.","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"Adalah tidak mungkin untuk menggunakan container tanpa container image. Artikel ini akan mengulas bagaimana kombinasi mounting filesystem dan penerapannya pada teknologi container dalam membangun container image. ","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/:0:0","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"Overlay Filesystem Overlay filesystem juga sering disebut sebagai union filesystem memungkinkan pembuatan kombinasi dua atau lebih direktori, yang akan menjadi list dari yang biasa dijuluki sebagai direktori lower dan direktori upper. Direktori lower biasanya memiliki permission read only, sedangkan direktori upper dapat diberikan permission read-write. Saya teringat, salah satu use case Overlay filesystem yang pernah saya lakukan adalah memakainya untuk membuat extroot atau external root pada OpenWrt guna memperluas filesystem sebuah wireless router dengan cara menaruh penyimpanannya ke media eksternal seperti USB storage. Untuk memahami Overlay filesystem kita dapat mempraktekannya dengan bantuan perintah mount pada sistem operasi GNU/Linux. Mari melihat apa yang dimaksud dengan pernyataan sebelumnya dengan mencobanya. ","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/:1:0","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"Membuat Overlay Filesystem Saya akan membuat beberapa folder dan mengkombinasikannya. Pertama saya ingin membuat sebuah folder bernama mount dimana nantinya akan berisikan gabungan dari keseluruhan folder lainnya. Kemudian saya membuat sebuah sekelompok folder bernama 1-lower-layer, 2-lower-layer, dan 3-upper-layer. Dan akhirnya saya membuat sebuah folder bernama workdir yang diperlukan oleh overay filesystem untuk dapat bekerja dengan benar. cd /tmp \u0026\u0026 mkdir overlay-example \u0026\u0026 cd overlay-example mkdir -v mount 1-lower-layer 2-lower-layer 3-upper-layer workdir ls -l Membuat Folder Sekarang mari membuat beberapa file dalam folder 1-lower-layer 2-lower-layer memakai perintah echo. Untuk folder 3-upper-layer akan kita biarkan kosong sebagai contoh dari direktori upper saja. Kita akan melihat bagaimana nantinya mereka akan bekerja. echo \"ini layer 1\" \u003e ./1-lower-layer/file1 echo \"ini layer 2\" \u003e ./2-lower-layer/file2 tree Membuat file pada direktori _lower_ Pada akhirnya, mari kita jalankan perintah mount pada mereka. sudo mount -vt overlay overay-example -o \\ lowerdir=/tmp/overlay-example/1-lower-layer:/tmp/overlay-example/2-lower-layer,upperdir=/tmp/overlay-example/3-upper-layer,workdir=/tmp/overlay-example/workdir \\ /tmp/overlay-example/mount df -h | grep overlay tree Jika berhasil kita dapat melihatnya seperti output berikut ini. Mounting Overlay Sebagaimana kita mengharapkannya, seluruh konten dari folder 1-lower-layer dan 2-lower-layer dapat dikombinasikan dan dimuat ke dalam folder mount. Mari kita periksa konten dari file tersebut yang sebelumnya telah kita tuliskan sebuah string menggunakan perintah echo. cat mount/file2 Sudah dipastikan bahwa memang file tersebut identik dengan apa yang sudah kita ciptakan sebelumnya. Memeriksa isi konten Lalu bagaimana jika kita membuat sebuah file baru pada folder mount? mari kita coba. echo \"Ini adalah file baru\" \u003e ./mount/file-baru tree Membuat file baru Terlihat bahwa file baru yang kita ciptakan di folder mount akan tersimpan pada upper layer atau di sini kita menamai foldernya dengan nama 3-upper-layer. Lalu bagaimana jika kita menghapus salah satu file milik lower layer, misalnya adalah file2. rm mount/file2 tree Menghapus file File tersebut berhasil dihapus dari folder mount, tapi ternyata file2 masih utuh dan baik-baik saja di dalam folder 2-lower-layer. Kemudian jika diperhatikan, akan muncul sebuah file baru pada folder 3-upper-layer bernama file2 sesuai dengan yang baru saja kita hapus. Mari kita periksa file tersebut. ls -lhtra 3-upper-layer Memeriksa upper layer File baru di dalam folder 3-upper-layer ternyata adalah sebuah character file. File semacam ini seringkali disebut sebagai file whiteout dan begitulah overlay filesystem menampilkan berkas yang akan dihapus. ","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/:1:1","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"Menarik Kesimpulan Sebagaimana yang saya bicarakan pada awal tadi, overlay filesystem memungkinkan kita untuk membuat sebauh union atau kesatuan beberapa direktori. Dalam kasus kita saat ini union dibuat pada folder mount dan di dalamnya akan berisi konten kolaborasi dari direktori layer yaitu folder 1-lower-layer dan 2-lower-layer sebagai lapisan direktori lower, serta folder 3-upper-layer sebagai lapisan direktori upper. Setiap perubahan yang kita lakukan pada union (membuat, menghapus, atau mengedit konten) akan dicatat pada upper layer. Ini adalah alasan kenapa lapisan upper juga sering disebut sebagai lapisan diff. Fakta lainnya adalah, berkas-berkas dari union merupakan bayangan dari lower layer namun upper layer memiliki tingkatan lebih tinggi untuk ditampilkan ke panggung, contohnya ketika kita membuat file atau folder pada 3-upper-layer dengan nama yang sama seperti dalam 1-lower-layer dan 2-lower-layer maka justru konten dari 3-upper-layer yang akan ditampilkan pada union atau dalam kasus ini yaitu folder mount. Upper Layer override ","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/:1:2","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"Container Image Container Image sebenarnya adalah sebuah tarfile dengan root filesystem dan beberapa metadata. Kita mungkin pernah mendengar tentang karakteristik image layer dan setiap baris dari Dockerfile (sebuah textfile yang berisi baris perintah untuk membangun container image) akan membuat layer baru. Contohnya seperti berikut, dimana dia akan membuat tiga layer untuk setiap baris perintahnya. FROM scratch ADD my-files /doc ADD hello / CMD [\"/hello\"] Jadi apa yang sebenarnya terjadi saat kita menjalankan perintah docker run. Banyak hal yang sebenarnya terjadi, tapi untuk kepentingan artikel kali ini kita akan meluruskan ketertarikan kita pada container image. Container Image Construct Secara pandangan high level, docker akan mengunduh tarball untuk image, kemudian melakukan unpack pada setiap layer menjadi beberapa direktori terpisah dan kemudian menggunakan overlay filesystem untuk mengkombinasinya menjadi sebuah kesatuan direktori upper kosong yang akan digunakan oleh container untuk menuliskan segala perubahan ketika tengah berjalan. Ketika kita melakukan suatu perubahan, seperti membuat atau menghapus file di dalam container, perubahan tersebut akan disimpan pada direktori kosong di upper layer. Ketika container dihentikan, docker akan membersihkan folder tersebut. Itulah alasannya kenapa setiap perubahan yang kita lakukan di dalam container by default tidak disimpan permanen. ","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/:2:0","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"Layer Cache Layer Cache Ini adalah metode yang digunakan oleh overlay filesystem untuk memungkinkan host melakukan caching container image secara efektif. Sebagai contoh, jika kita mendefinisikan dua container image, mereka berdua dapat menggunakan beberapa layer yang sama. Sehingga host tidak perlu mengunduh kembali atau menyimpan salinannya berkali-kali pada disk. ","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/:2:1","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"OCI format Menjalankan sebuah container dapat dianalogikan menjadi dua langkah proses: membangun image dan menjalankan container dari image tersebut. Popularitas container telah meyakinkan orang-orang untuk melakukan standarisasi kedua langkah proses tersebut. Karena open source, kedua langkah proses tersebut dapat dikembangkan secara terpisah. Open Container Initiative (OCI) merupakan sebuah project dari Linux Foundation yang mengelola standarisasi container supaya dapat disesuaikan dengan lingkungan industri. Saat artikel ini dibuat, OCI memiki dua macam spesifikasi: Runtime Specification (runtime-spec) dan Image Specification (image-spec). Runtime Specification menguraikan cara untuk menjalankan “filesystem bundle” yang dapat dibongkar pada disk. Penerapan OCI seperti mengunduh OCI Image kemudian melakukan unpack image tersebut ke dalam OCI Runtime filesystem bundle. Pada titik ini OCI Runtime Bundle akan dijalankan oleh sebuah OCI Runtime. Standarisasi tersebut memperbolehkan setiap orang untuk mengembangkan custom container builder dan custom runtime. Sebagai contoh, ada jessfraz/img, buildah, hingga Skopeo yang mampu kita pakai untuk membangun container image tanpa perlu bergantung pada Docker. Banyak tool lain yang juga bisa kita gunakan untuk menjalankan container (disebut container runtime) seperti runC (yang dipakai oleh Docker) dan rkt. ","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/:2:2","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"Overlay Filesystem Lainnya OverlayFS lain Docker tidak cuma mampu menggunakan Overlay untuk melakukan kombinasi filesystem. Ada beberapa lainnya yang memiliki potensi untuk dapat digunakan seperti AuFS, Btrfs, ZFS, hingga Device mapper. ","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/:3:0","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"Build Container Image Container Image Layer Misalkan kita memiliki sebuah Dockerfile seperti berikut untuk membangun image. Apa yang sebenarnya terjadi? FROM centos:7 RUN yum install -y wget ... Pada pandangan high level, inilah yang akan terjadi dari Dockerfile tersebut. Docker mengunduh tarball untuk image karena perintah FROM dan membongkarnya. Ini akan menjadi layer paling bawah dari container image. Memuat union filesystem. Berkas yang sebelumnya telah terunduh pada langkah pertama akan dipakai sebagai lower layer. Menjalankan shell command di dalam environment chroot karena perintah RUN. Perintah tersebut adalah /bin/sh -c \"yum install -y wget. Ketika baris perintah terakhir telah dijalankan, container runtime akan membuat upper layer. Ini adalah lapisan baru dari image yang kita bangun. Jika Dockerfile mengandung perintah lainnya, maka proses pada langkah kedua akan diulangi sebagai lower layer dan berikutnya hingga selesai. Tentu anggapan ini cenderung terlalu menyederhanakan workflow dimana saya tidak menyinggung perintah lain seperti ENV hingga ENTRYPOINT. Perintah tersebut akan disimpan di dalam metadata dan kemudian dikemas bersama ke dalam layer. ","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/:4:0","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"Kesimpulan Gagasan untuk merangkum keseluruhan root filesystem menjadi sebuah tarfile dan memisahkan setiap layer menjadi begitu powerful. Ini tidak hanya dipakai pada teknologi container, tapi konsep ini juga dapat digunakan pada konteks lainnya. Saya kira, di masa mendatang akan semakin banyak tools yang memanfaatkan hal serupa. ","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/:5:0","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"Referensi git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/filesystems/overlayfs.rst linux.die.net/man/8/mount openwrt.org/docs/guide-user/additional-software/extroot_configuration docs.docker.com/develop/develop-images/dockerfile_best-practices opencontainers.org/faq github.com/opencontainers/runtime-spec/blob/master/spec.md github.com/opencontainers/image-spec/blob/master/layer.md ","date":"2021-03-26","objectID":"/penerapan-linux-overlayfs-pada-container-image/:6:0","tags":["Container","OverlayFS","Mount","Review"],"title":"Penerapan Linux OverlayFS pada Container Image","uri":"/penerapan-linux-overlayfs-pada-container-image/"},{"categories":["GNU/Linux"],"content":"Keterkaitan dan validasi pengguna GNU/Linux dengan sikap Elitisme","date":"2021-03-23","objectID":"/linux-dan-elitisme/","tags":["General","Environment"],"title":"Linux dan Elitisme","uri":"/linux-dan-elitisme/"},{"categories":["GNU/Linux"],"content":"Ada sebuah anggapan di lingkup pengguna komputer bahwa GNU/Linux user mempunyai sikap elitis dan berpikir bahwa mereka lebih baik daripada orang lain yang tidak menggunakan distro GNU/Linux. Untuk mengetahui apakah seseorang itu elitis atau tidak, ada kriteria yang perlu kita perhatikan tentang bagaimana user ini beropini tentang dirinya sendiri dan user lainnya. ","date":"2021-03-23","objectID":"/linux-dan-elitisme/:0:0","tags":["General","Environment"],"title":"Linux dan Elitisme","uri":"/linux-dan-elitisme/"},{"categories":["GNU/Linux"],"content":"Prolog Mungkin dari kita semua pernah merasa seperti dipaksa lalu merasa bingung atau tidak mengerti mengenai apa yang diucapkan seseorang, entah itu dari internet maupun secara langsung. Meskipun begitu, ada juga orang yang tidak peduli terhadap ucapan tersebut. Misalnya, Si A pernah berkata “Udahlah, objek X bloated, insecure, dan non-FLOSS. Pakai Y saja.” dan sebagainya. Apakah itu dapat dianggap suatu perilaku pemaksaan? Belum tentu, itu bisa kita anggap sebagai tindakan persuasif yang harus kita olah sebijak mungkin dengan mencari tahu sumber referensi yang jelas dan tentunya sesuai kebutuhan setiap individu melalui berbagai riset. Informasi Sebelum lebih lanjut, saya tegaskan bahwa di bawah ini yang dimaksud sebuah sistem operasi GNU/Linux (atau sering disebut Linux) sebenarnya dikemas sebagai distribusi Linux. Lihat juga kernel Linux. ","date":"2021-03-23","objectID":"/linux-dan-elitisme/:1:0","tags":["General","Environment"],"title":"Linux dan Elitisme","uri":"/linux-dan-elitisme/"},{"categories":["GNU/Linux"],"content":"Linux dan Elitisme “Linux dan Elitisme”. Apakah keduanya memiliki keterkaitan satu sama-lain? Mengapa begitu banyak pengguna sistem operasi Linux mempunyai sikap elitis? Memang, pada beberapa aspek pengguna sistem operasi Linux dapat disebut sebagai elit. Berdasarkan data statistik dari gs.statcounter.com, kurang dari 2% di dunia yang menggunakan sistem operasi Linux di platform desktop, sedangkan jika disaring dalam semua platform mereka hanya kurang dari 1%. Itu adalah fakta bukan sekedar sebuah sikap saja. Android juga menggunakan mainstream kernel Linux, tetapi ditambahkan driver maupun fitur untuk perangkat spesifik sehingga dibedakan kategorinya. Biasanya driver/fitur tambahan tersebut akan diterapkan ke kernel Linux jika komunitas menyetujuinya dan memang mungkin untuk memodifikasinya. Rata-rata mereka lebih terampil, menguasai dan memiliki pengetahuan mendalam mengenai komputer daripada pengguna sistem operasi lain karena seringnya mencari dan membaca serta mengolah informasi. Mayoritas dari mereka sadar akan seluk-beluk dalam sistem operasi yang jarang terdengar. Contohnya HFS (Hierarchical File System), init system, user-group permission, kernel, bootloader, package manager, process scheduling, desktop environment, dan masih banyak lagi. Pada awalnya sistem operasi Linux banyak digunakan untuk keutamaan seperti kegiatan ilmiah eksperimen DØ yang menggunakan Scientific Linux, server produksi, seorang penghobi, programmer/developer, engineer, pentester. Bahwa berarti pada awalnya Linux bukanlah untuk mayoritas konsumsi rumahan. Namun, sekarang sistem operasi Linux sudah berusaha dikembangkan secara pesat (karena open-source) untuk konsumsi publik yang lebih ramah pengguna. Pengguna sistem operasi linux yang AVID biasanya tidak melihat pragmatisme dari kebanyakan pengguna biasa. Mereka sangat terpesona dan penasaran sehingga ingin untuk mampu memodifikasi setiap hal kecil di sistem operasi yang mereka gunakan setiap harinya. Tidak semua pengguna komputer memenuhi beberapa aspek di atas. Dengan demikian, pengguna sistem operasi Linux dapat dianggap sebagai Elit dan memiliki hak untuk membedakan diri dari mayoritas pengguna komputer meskipun tidak dengan sombong. Namun, pada kenyataannya sikap elitisme adalah suatu kesalahpahaman yang besar. Itu sama sekali tidak memiliki keterkaitan dengan penggunaan sistem operasi Linux sama sekali, tetapi berasal dari ketidaksepakatan mendasar dengan pola pikir dan cara komputasi terhadap komputer modern. ","date":"2021-03-23","objectID":"/linux-dan-elitisme/:2:0","tags":["General","Environment"],"title":"Linux dan Elitisme","uri":"/linux-dan-elitisme/"},{"categories":["GNU/Linux"],"content":"Opini Jadi bagaimana pendapat saya tentang user sistem operasi lain? Ini sedikit mengejutkan, sebetulnya saya tidak berpikir bahwa pengguna sistem operasi lain benar-benar bodoh atau IQ-nya lebih rendah daripada pengguna sistem operasi Linux. Saya juga tidak berpikir bahwa pengguna sistem operasi Linux adalah seorang jenius yang hidup diantara orang-orang bodoh, walaupun terkadang kenyataannya begitu. Jika kita mau melihat pada data perkembangan IQ di masa lampau hingga masa kini, kita dapat memperhatikan bahwa rata-rata IQ meningkat pada setiap populasi manusia. Kita melihat bahwa literasi semakin meningkat, matematika yang kompleks menjadi lebih “biasa”, setiap orang memiliki smartphone dan punya akses ke hampir seluruh teknologi hanya dengan menggerakkan jari mereka. Fakta-fakta ini membuat saya ragu, bahwa apakah semua orang di luar pengguna sistem operasi Linux itu bodoh atau mempunyai IQ rendah. Jadi apa yang menyebabkan mereka tidak elit? Apatis, apatisme menjadi sangat biasa dan dinormalisir jika dibandingkan pada masa lalu, ini disebabkan oleh semua kemudahan yang bisa diakses oleh orang-orang sampai mereka tidak peduli tentang apapun, mereka tidak mau berusaha, mereka lebih memilih mencari dopamine, seperti film porno, sosial media, menggemari idola, video game, hingga sumber-sumber dopamine lainnya untuk menjadi santapan otak sehari-hari. Otak mereka sudah terlalu penuh untuk melakukan hal lainnya yang sedikit lebih sulit. ","date":"2021-03-23","objectID":"/linux-dan-elitisme/:3:0","tags":["General","Environment"],"title":"Linux dan Elitisme","uri":"/linux-dan-elitisme/"},{"categories":["GNU/Linux"],"content":"It Just Werks It Just Werks Saya menolak semua pernyataan “yang penting bisa digunakan” dan menganggapnya sebagai kata-kata yang bodoh, yang diberikan seseorang ketika tidak mau repot-repot menggerakkan tubuh dan akal sehatnya. Bukan karena suka dengan sesuatu yang rumit, tetapi saya menginginkan agar sesuatu bekerja seperti apa yang saya harapkan. Sejujurnya, saya juga tidak ingin mereka menggunakan objek Y karena dipaksakan. Berusaha sekuat tenaga sebagai orang-orang yang hidup di realitas alternatif dari apa yang disebut software piracy, dan berusaha tidak peduli terhadap apapun selama itu disebut “yang penting bisa dipakai”. Ketika manusia telah memiliki basic needs, seperti tempat tinggal, air, dan makanan di perut mereka, mereka tidak lagi memikirkan cara bertahan hidup dan eksistensinya. Ketika mereka telah mencapai kenyamanan itu, tanpa deeper meaning atau goal untuk memicu mereka, mereka akan menjadi apatis. Apatisme inilah yang menyebabkan orang-orang berkata bahwa instalasi Linux itu sulit, padahal belum tentu sesulit itu. Tapi karena sekarang kita hidup di masa mesin-mesin OEM, dimana Cortana melakukan semuanya untuk pengguna setelah membelinya dari toko. Tapi yah memang benar bahwa sistem operasi Linux sedikit banyak lebih sulit dibandingkan dengan itu. ","date":"2021-03-23","objectID":"/linux-dan-elitisme/:3:1","tags":["General","Environment"],"title":"Linux dan Elitisme","uri":"/linux-dan-elitisme/"},{"categories":["GNU/Linux"],"content":"Analogi Apakah pengguna Linux adalah Elit? Mari coba membayangkan, seumpama sistem operasi adalah mobil. Ada dua macam orang yang membeli mobil yang berbeda. Ayo sejenak berasumsi performance mobilnya sama (iya saya tahu bahwa Linux jauh memiliki performance yang lebih bagus daripada sistem operasi W, tapi mari anggap saja begitu dulu). Yang satu terus-terusan merekam obrolan pengguna, musik, makanan favorit, tujuan pergi dan semua datanya dikirim ke dealer untuk kepentingan penjualan (misalnya iklan). Dan juga, user tersebut tidak diperbolehkan mengganti komponen mobilnya, user tidak dapat memodifikasi mobil tersebut untuk memaksimalkan potensinya, jika ingin lebih maka harus membeli mobil baru. Sedangkan lawannya adalah sebuah mobil DIY (iya saya mengerti jika Linux belum tentu serumit itu, tapi mari anggap saja begitu terlebih dahulu), mobil tersebut bebas dimodifikasi, tanpa ada proses-proses yang membuat mobil tersebut menjadi lebih payah performance-nya. Jadi dari analogi diatas, sepertinya memang semakin memvalidasi elitisme pengguna sistem operasi Linux, mereka menggunakan OS yang elit, mereka berjam-jam melakukan konfigurasi OS. Dan yang terpenting, mereka took action dengan melalui itu semua. Tidak seperti pengguna sistem operasi lain yang terus-menerus hanya bisa disuapi. Tidak semua orang mempunyai skill-set itu, beberapa orang terbukti lebih superior daripada orang lain dan tidak semua orang adalah equal walapun mayoritas media hingga masyarakat kita mengatakan itu. Paham bahwa semua orang itu setara hanyalah opini juga, karena beberapa orang terbukti lebih baik dalam suatu hal tertentu atau bahkan dalam banyak hal sekaligus daripada orang lain. ","date":"2021-03-23","objectID":"/linux-dan-elitisme/:3:2","tags":["General","Environment"],"title":"Linux dan Elitisme","uri":"/linux-dan-elitisme/"},{"categories":["GNU/Linux"],"content":"Epilog Apapun yang kita lakukan, jika hanya untuk menjadi “keren” atau “ikut-ikutan” tetapi sulit dalam menyesuaikan lingkungan. Sesungguhnya itu tidaklah keren, melainkan menyakiti diri sendiri. Marilah mencoba berbagai hal yang kita temui jika itu bermanfaat bagi individu masing-masing. Permasalahannya adalah seberapa banyak orang dapat meluangkan waktu mereka untuk melakukan hal-hal seperti itu dengan tepat dan cepat. ","date":"2021-03-23","objectID":"/linux-dan-elitisme/:4:0","tags":["General","Environment"],"title":"Linux dan Elitisme","uri":"/linux-dan-elitisme/"},{"categories":["GNU/Linux"],"content":"Referensi www.linuxsec.org/2021/03/linux-dan-elitisme.html www.distrotube.com/blog/why-linux-users-have-elitist-attitude www.youtube.com/watch?v=TxDFjGPqYog ","date":"2021-03-23","objectID":"/linux-dan-elitisme/:5:0","tags":["General","Environment"],"title":"Linux dan Elitisme","uri":"/linux-dan-elitisme/"},{"categories":["Tools"],"content":"Deploy Ansible AWS di CentOS 8 sebagai alternatif Ansible Tower","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"AWX adalah perangkat lunak berbasis web yang digunakan sebagai user interface dan penyedia REST API untuk engine Ansible. AWX merupakan versi upstream dari Ansible Tower, sama seperti biasanya Red Hat selalu mewujudkan representatif layanan berbayarnya dengan project - project open source sebagai development version. Jika Ansible Tower membutuhkan biaya untuk subscription, maka AWX sama sekali tidak dipungut biaya. ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:0:0","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Ansible Ansible Ansible adalah perangkat lunak open source yang digunakan untuk melakukan software provisioning, configuration management, dan application deployment terhadap infrastruktur. Sederhananya, Ansible merupakan bentuk dari Infrastructure as Code, yang pakai untuk melakukan konfigurasi infrastruktur secara otomatis. Dalam pengoperasiannya, sering kali digunakan sebuah markup script YAML yang disebut sebagai Playbook atau dapat juga langsung dieksekusi sebagai Ad-Hoc saja. Semua hal tersebut pada umumnya dilakukan dalam perintah berbasis teks (CLI). Ansible juga terkenal karena agentless, artinya kita tidak perlu melakukan instalasi agent atau program apapun di perangkat infrastruktur yang akan dikelola. Untuk informasi lebih lanjut terkait Ansible silahkan baca di docs.ansible.com. ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:1:0","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Contoh Kasus Sebagai contoh misalkan kita memiliki tugas untuk mengganti nameserver menjadi 8.8.8.8 pada puluhan hingga ratusan server. Pada proses tradisional, kita akan melakukan login (misalnya melalui SSH) kemudian memanipulasi file /etc/resolv.conf pada masing - masing server, tentu saja mengulang-ulang tugas yang sama adalah hal membosankan. Mungkin kita bisa berusaha membuat sebuah shell script (misalnya bash) yang dijalankan sebagai program untuk melakukan itu semua, tapi tidak semua orang mau melakukan effort tersebut. Maka kita dapat menggunakan Ansible sebagai solusi, cukup install Ansible pada Control Node yang dapat terkoneksi dengan list server. Kemudian memasukkan seluruh list hostname atau alamat IP server ke dalam file inventory, dan menjalankan Ansible Ad-Hoc berisi instruksi perintah untuk mengganti isi file /etc/resolv.conf lalu masalah terselesaikan. Sedangkan untuk tugas yang lebih rumit kita dapat menulisnya ke dalam script YAML untuk kemudian dieksekusi dengan Ansible Playbook. Ansible Playbook ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:1:1","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Prerequisites Sebelum melanjutkan lebih jauh, pastikan sudah memenuhi beberapa prasyarat berikut. ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:2:0","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"System Requirements Untuk mendapatkan performa yang baik saat pertama kali melakukan deployment, setidaknya dibutuhkan spesifikasi seperti berikut. 4 GB Memory 2 Core CPU 20 GB Storage Saya akan menggunakan VM Guest CentOS 8 sebagai Control Node. Namun jika ingin menggunakan CentOS 7 setidaknya gunakan CentOS 7.7 atau versi lebih baru. Perhatian Dalam artikel ini saya akan mengeksekusi seluruh perintah dengan menggunakan user root. ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:2:1","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Disable SELinux Untuk sementara saya merubah SELinux menjadi permissive agar proses deployment berjalan lancar. sed -i 's/^SELINUX=.*/SELINUX=permissive/g' /etc/selinux/config setenforce permissive ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:2:2","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"EPEL dan Extra Packages Jalankan perintah berikut ini. dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:2:3","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Instalasi Ansible Kita membutuhkan Ansible Engine versi 2.8 atau lebih baru. Jalankan perintah berikut ini. dnf install ansible ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:2:4","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Paket Tambahan Jalankan perintah berikut ini untuk memasang beberapa paket tambahan. dnf install git python3-pip curl \\ wget nodejs gettext lvm2 \\ device-mapper-persistent-data bzip2 ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:2:5","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Development Tools AWX membutuhkan beberapa paket lain dari group Development Tools untuk GNU Make. dnf group install \"Development Tools\" ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:2:6","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Docker dan Docker Compose Karena AWX akan dijalankan di container, by-default AWX menyarankan untuk memakai Docker CE. dnf config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo dnf install docker-ce docker-ce-cli containerd.io systemctl enable --now docker Lalu pasang docker-compose menggunakan pip3. pip3 install docker-compose Perhatian Jika tidak menggunakan user root maka tambahkan user tersebut ke dalam group docker kemudian logout dan login kembali. Menambahkan user ke dalam suatu grup dapat dilakukan dengan perintah sudo usermod -aG docker user ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:2:7","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Deploy AWX ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:3:0","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Clone Repository Periksa terlebih dahulu release yang tersedia dari remote repository AWX pada halaman releases. Kemudian jalankan clone dengan perintah berikut. git clone -b x.y.z https://github.com/ansible/awx.git Perhatian Untuk x.y.z adalah versi yang akan digunakan, misalnya pada halaman release terdapat versi 17.0.1. Melakukan clone tanpa definisi versi branch akan diarahkan langsung menuju branch HEAD yang berisi versi development, hal tersebut tidak disarankan karena sangat tidak stabil. ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:3:1","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Generate Secret Key Biasanya AWX membutuhkan Secret Key, kita dapat membuatnya menggunakan openssl yang sudah tersedia di CentOS 8. openssl rand -hex 32 Catat output yang dihasilkan dari perintah diatas. ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:3:2","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Edit Inventory Buka file inventory yang terdapat dalam direktori instaler AWX misalnya menggunakan vi. cd awx/installer vi inventory Cari dan edit beberapa baris yang ada seperti berikut. secret_key=\u003cSECRET_KEY\u003e admin_password=\u003cPASSWORD_AWX\u003e project_data_dir=/var/lib/awx/projects awx_official=true awx_alternate_dns_servers=\"8.8.8.8,8.8.4.4\" Perhatian Ganti SECRET_KEY dengan output yang tadi dihasilkan oleh openssl, dan ganti PASSWORD_AWX dengan password untuk login ke dalam user interface. ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:3:3","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Membuat Direktori Project Karena kita mengaktifkan variabel project_data_dir maka kita perlu membuat direktorinya juga. mkdir -p /var/lib/awx/projects Direktori tersebut nantinya akan berisi project yang akan kita gunakan dalam AWX. ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:3:4","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Konfigurasi Firewall Supaya AWX dapat diakses dari luar VM maka kita perlu melakukan beberapa konfigurasi firewall. firewall-cmd --zone=public --add-masquerade --permanent firewall-cmd --add-service=http --add-service=https --permanent firewall-cmd --reload ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:3:5","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Deployment Eksekusi file YAML bernama install.yml menggunakan ansible-playbook. ansible-playbook -i inventory install.yml Proses akan memakan waktu cukup lama hingga akhirnya selesai. Apabila tidak ada kendala maka akan muncul tampilan seperti berikut. PLAY RECAP **************************************************************************************** localhost : ok=21 changed=8 unreachable=0 failed=0 skipped=73 rescued=0 ignored=1 ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:3:6","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Post-Deployment Jangan lupa untuk mengembalikan kondisi SELinux menjadi enforcing dari yang tadinya telah kita manipulasi menjadi permissive. sed -i 's/^SELINUX=.*/SELINUX=enforcing/g' /etc/selinux/config setenforce enforcing ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:3:7","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Pengujian Periksa apakah ada container yang berjalan. docker ps Jika berhasil maka akan ada 4 container yang dalam status Up. 003389b920b6 ansible/awx:17.0.1 \"/usr/bin/tini -- /u...\" 7 minutes ago Up 7 minutes 8052/tcp awx_task 42d2ff79f8e1 ansible/awx:17.0.1 \"/usr/bin/tini -- /b...\" 7 minutes ago Up 7 minutes 0.0.0.0:80-\u003e8052/tcp awx_web 3e73bd538074 postgres:12 \"docker-entrypoint.s...\" 7 minutes ago Up 7 minutes 5432/tcp awx_postgres 94ee8bb7949b redis \"docker-entrypoint.s...\" 7 minutes ago Up 7 minutes 6379/tcp awx_redis Sekarang coba buka user interface AWX di Web Browser menggunakan alamat IP milik VM. Jika berhasil kita dapat melakukan login memakai username dan password yang sebelumnya telah kita isi pada file inventory. Login AWX Dashboard AWX AWX About ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:4:0","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Kesimpulan Berdasarkan FAQ (Frequently Asked Questions) dikatakan bahwa AWX sangat tidak dianjurkan untuk dipakai di production, namun jika untuk sekedar mempelajari fitur-fitur yang ada saya rasa AWX sudah cukup. Jika sudah terbiasa mengoperasikan AWX, kita bisa saja beralih untuk berlangganan Ansible Tower di production environment. Selama saya mencoba melakukan deployment AWX, saya melihat banyak sekali issue masih dalam status Open di repositori Github milik AWX. ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:5:0","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":["Tools"],"content":"Referensi docs.ansible.com/ansible/latest/user_guide/intro_getting_started.html github.com/ansible/awx/ www.ansible.com/overview/how-ansible-works www.ansible.com/community/awx-project www.ansible.com/products/awx-project/faq www.redhat.com/en/resources/awx-and-ansible-tower-datasheet ","date":"2021-02-04","objectID":"/deploy-ansible-awx-di-centos/:6:0","tags":["Ansible","AWX","Automation","CentOS"],"title":"Deploy Ansible AWX di CentOS","uri":"/deploy-ansible-awx-di-centos/"},{"categories":null,"content":"Tentang situs init.web.id dan alasannya dibangun","date":"2020-12-12","objectID":"/about/","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":" Bonjour! Saya Anwar, seorang biasa pegiat GNU/Linux, serta jaringan komputer. Gemar mempelajari konfigurasi infrastruktur dan arsitektur yang berkaitan dengan komputasi, mendengar musik, menonton film, dan membaca. Saya menemukan hasrat pada code delivery serta pengelolaan infrastruktur yang stabil dan capable. Sebut saja SysAdmin, DevOps, atau SRE, meskipun sejujurnya saya tidak terlalu peduli dengan julukan. Saat ini saya bekerja untuk SIRCLO Group sebagai Cloud Ops Engineer. Seringkali hal yang jarang dilakukan akan mudah terlupakan, maka dibangunlah situs web ini untuk membantu merawat ingatan, bukan berbagi. Jika ternyata mampu menolong orang lain, anggap itu sebagai sebuah bonus. Perhatian Situs web yang sedang terbuka ini hanyalah arsip pribadi yang berusaha ditulis sedemikian rupa supaya terlihat lebih teknis. Perlu diketahui, bahwa penulis tidak berharap setiap orang dapat memahaminya. Penulis sepenuhnya tidak bertanggung jawab atas segala kerugian atau kerusakan yang disebabkan oleh setiap konten dalam situs ini. Pembaca hendaknya lebih waspada dalam mempraktikan hal-hal dari internet. Seluruh konten tersedia gratis dan bebas untuk dibaca, disalin, serta disebarluaskan, hingga dapat dikembangkan pada media lain. Setiap artikel memiliki source code yang dapat diakses dari repository. Jika memiliki pertanyaan, atau urusan lain silahkan hubungi penulis melalui beberapa kontak berikut ini : Contact  Twitter  Email ","date":"2020-12-12","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":["Blog"],"content":"Integrasi Github Pages dengan Cloudflare CDN untuk meningkatkan kecepatan load-time situs web.","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Github Pages biasanya digunakan sebagai hosting untuk situs web dengan konten statis, maka diperlukan caching untuk mempercepat load-time. Cloudflare dapat dimanfaatkan sebagai CDN (Content Delivery Network) yang berfungsi untuk menyimpan cache apabila belum ada perubahan yang signifikan pada situs web. ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:0:0","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"CDN CDN (Content Delivery Network) merupakan sekelompok server yang ditempatkan diberbagai lokasi untuk mendistribusikan konten situs web ke sejumlah wilayah geografis yang luas. Salah satu contohnya adalah Cloudflare, yang menyediakan beberapa layanan baik berbayar maupun bebas biaya seperti yang telah saya gunakan pada situs web ini. CDN bekerja untuk menyimpan cache dari Origin Server (misalnya server Github Pages) dan menyimpannya di berbagai CDN Server pada berbagai belahan dunia. Contohnya ketika pengguna dari benua Asia mencoba mengakses situs web yang dikenal memiliki basis server di benua Amerika, CDN Server yang terletak pada lokasi terdekat dengan penggunalah yang akan menjawab request pengguna tersebut. Bagaimana CDN Bekerja ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:1:0","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Manfaat Cloudflare Selain mempercepat load-time situs web, terdapat beberapa manfaat lain yang dapat kita peroleh dengan mengintegrasikan Cloudflare pada situs web. Dengan menggunakan Cloudflare kita dapat lebih menghemat bandwith, meningkatkan keamanan server dari serangan DDoS dari pihak tidak bertanggung jawab, hingga memperoleh layanan SSL HTTPS terpercaya. Manfaat Cloudflare ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:1:1","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Prerequisites Sebelum melaksanakan beberapa langkah lebih lanjut, pastikan sudah memenuhi beberapa prasyarat berikut ini. Saya sudah memiliki akun Cloudflare dengan paket layanan bebas biaya, apabila belum memilikinya maka sebaiknya lakukan registrasi akun terlebih dahulu pada dash.cloudflare.com/sign-up. Memiliki akses registrar dari domain yang digunakan oleh situs web. Registrar akan kita gunakan untuk melakukan pointing menuju nameserver Cloudflare. Dalam artikel ini saya telah memiliki sebuah domain yang disediakan oleh DewaBiz.com. Sebuah situs web yang menggunakan Github Pages sebagai hosting. Contohnya seperti yang telah saya tulis pada artikel Custom APEX Domain untuk Github Pages. ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:2:0","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Nameserver Cloudflare ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:3:0","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Tambahkan Situs Web Login ke dalam halaman dashboard Cloudflare menggunakan akun yang sebelumnya telah dibuat. Kemudian tambahkan situs web dengan memasukkan alamat domainnya. Tambah Situs Web Lalu pilih paket yang akan digunakan seperti berikut ini. Paket Layanan ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:3:1","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Konfigurasi Nameserver Clouflare Setelah menambahkan situs web, kita perlu melaukan konfigurasi DNS kemudian kita akan mendapatkan sepasang nameserver seperti berikut ini. Konfigurasi Nameserver IP pada A records merupakan IP miliki Github yang saya dapatkan dari docs.github.com. 185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 Yang perlu dicatat adalah nameserver yang telah kita dapatkan dari Cloudflare, seperti berikut. penny.ns.cloudflare.com sri.nds.cloudflare.com ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:3:2","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Registrar Domain Sekarang login ke dalam registrar domain kalian untuk merubah nameserver. Ubah Nameserver di Registrar Biasanya perubahan nameserver akan memakan waktu beberapa saat, sebaiknya tunggu terlebih dahulu sekitar 15 menit dan lakukan flush cache dns. ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:4:0","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Konfigurasi HTTPS Kita perlu mengaktifkannya terlebih dahulu pada menu SSL/TLS di dashboard Cloudflare. SSL/TLS Cloudflare Kemudian masuk ke Settings pada Github Pages dan centang Enforce HTTPS Enforce HTTPS ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:5:0","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Konfigurasi Cache Ini adalah salah satu fitur yang paling dicari di Cloudflare, kita dapat menemukannya pada menu Caching. Di sini saya hanya mengaktifkan Caching Level seperti berikut. Caching Level Untuk mengetahui lebih jelasnya kita dapat melihat kegunaan dari setiap properties tersebut pada dokumentasi resmi Cloudflare dari halaman support.cloudflare.com. ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:6:0","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Page Rules Selanjutnya buka Page Rules untuk membuat 3 rules baru bagi domain kita. Always Use HTTPS Forwarding URL Cache Level Page Rules Untuk menerapkan semua konfigurasi yang telah dibuat, saya menghapus semua cache yang telah tersimpan di Cloudflare dengan menggunakan Purge Everything pada menu Caching di dashboard Cloudflare. Purge Everything ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:7:0","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Pengujian Untuk melakukan pengujian saya menggunakan perintah dig dan hasilnya sebagai berikut. $ dig init.web.id Jika registrar domain telah menggunakan nameserver Cloudflare maka akan muncul tampilan seperti berikut. Name Server:penny.ns.cloudflare.com Name Server:sri.ns.cloudflare.com Lalu jika SSL Cloudflare telah berhasil diterapkan, maka pada overview registrar domain DewaBiz.com akan menampilkan informasi berikut. Overview Registrar ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:8:0","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Kesimpulan Dengan menggunakan nameserver milik Cloudflare saya merasa fitur Konfigurasi DNS yang terdapat pada registrar domain kini dapat dikelola melalui dashboard Cloudflare. Perubahan kecepatan load-time situs web memang benar-benar terasa. Kita dapat melihat analisis secara mudah lewat menu Analytics, serta menguji kecepatan situs web dengan fitur Speed pada dashboard Cloudflare. Di lain kesempatan saya ingin mencoba untuk bermigrasi ke Netlify untuk mereasakan perbandingannya. ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:9:0","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Blog"],"content":"Referensi en.wikipedia.org/wiki/Cloudflare blog.cloudflare.com/secure-and-fast-github-pages-with-cloudflare support.cloudflare.com/hc/en-us/articles/204144518-SSL-FAQ support.cloudflare.com/hc/en-us/articles/200168256-Understand-Cloudflare-Caching-Level docs.github.com/en/github/working-with-github-pages/managing-a-custom-domain-for-your-github-pages-site ","date":"2021-01-30","objectID":"/integrasi-github-pages-dengan-cloudflare-cdn/:10:0","tags":["Cloudflare","Github","CDN","Review"],"title":"Integrasi Github Pages dengan Cloudflare CDN","uri":"/integrasi-github-pages-dengan-cloudflare-cdn/"},{"categories":["Platform"],"content":"Provisioning Kubernetes dengan Terraform dan Ansible di AWS menggunakan spesifikasi instance minimal.","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Kubernetes Vanilla atau versi Kubernetes orisinil merupakan aplikasi opensource untuk Container Orchestration dengan berbagai fleksibilitas yang dapat diintegrasikan lebih lanjut bersama komponen atau tools lain dari pihak ketiga. Berbeda dengan distribusi Kubernetes (seperti OpenShift dan OKD) yang menawarkan kemudahan dalam instalasi, Kubernetes (atau sering disebut k8s) seringkali membutuhkan effort yang lebih besar dalam membangun klaster-nya jika dilakukan secara manual tanpa layanan dari vendor atau cloud provider (seperti EKS atau GKS). Namun sebenarnya kita dapat melakukannya dengan lebih effortless menggunakan tools untuk provisioning infrastruktur maupun konfigurasi, seperti Terraform dan Ansible. ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:0:0","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Struktur Klaster Pada artikel ini saya akan membangun klaster Kubernetes yang terdiri dari satu Control Plane atau Master Node, serta dua Worker Node. Untuk pengelolaan container di dalam klaster saya akan menggunakan Docker. Infrastruktur akan didirikan di cloud provider AWS (Amazon Web Service). Klaster Kubernetes ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:1:0","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Provisioning Provisioning dalam urusan cloud native sering dianggap sebagai proses menyediakan suatu layanan. Segala proses yang terjadi dalam menyediakan layanan tersebut dapat dilakukan secara manual, namun seiring berkembangnya zaman tentu saja kini banyak sekali tools yang bermunculan dan menawarkan kemampuan untuk membuat process automation. Misalnya pada artikel ini, Terraform akan digunakan untuk melakukan provisioning infrastruktur pada AWS. Sementara dalam melakukan konfigurasi atau setup setiap instance, Ansible Playbook adalah tools yang akan bertanggung jawab untuk melakukannya. Ansible Playbook akan melakukan beberapa proses mulai dari update sistem operasi, setup Docker, memasang kubelet, etcd, membuat token bagi worker node hingga berbagai keperluan setup k8s lainnya sampai selesai. ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:1:1","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Prerequisites Pastikan beberapa prasyarat berikut ini sudah terpenuhi sebelum melakukan tahap lebih lanjut. ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:2:0","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Access Key Untuk mendapatkan access key AWS, kita harus memiliki akun AWS. Access Key ini sama dengan yang biasanya digunakan sebagai credentials aws-cli, dan pada artikel ini access key tersebut akan dipakai oleh Terraform untuk mengeksekusi perintah sesuai dengan script yang kita buat. Untuk lebih lengkapnya silahkan lihat dokumentasi resmi AWS. Simpan access key tersebut ke dalam sebuah file, misalnya credentials seperti berikut ini. [default] aws_access_key_id=AKIA3ANXUSNAUATXXXXX aws_secret_access_key=+JDR1HWw4vrcFrLqbf+ewv/nJL/L6TlVAhwXXXXX ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:2:1","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"VPC Pada umumnya by-default AWS sudah memiliki VPC (Virtual Private Cloud), namun jika belum kita dapat membuatnya sendiri dengan perintah berikut. $ aws ec2 create-default-vpc --availability-zone us-east-1 Saya akan menggunakan default VPC Subnet yang sudah ada pada AWS. Namun jika belum ada maka kita dapat membuatnya sendiri seperti berikut. $ aws ec2 create-default-subnet --availability-zone us-east-1a Kita akan membutuhkan id dari Subnet VPC yang telah kita buat untuk tahap selanjutnya. $ aws ec2 describe-subnets --region us-east-1 Catat dan simpan id dari Subnet VPC yang telah kita buat. ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:2:2","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"SSH Key Buat sebuah SSH Key bagi instance AWS yang akan kita dirikan. Untuk membuatnya saya menggunakan aws-cli dengan perintah berikut. $ aws ec2 create-key-pair --region us-east-1 --key-name infra-k8s --query 'KeyMaterial' --output text \u003e infra-k8s.pem Nantinya perintah tersebut akan menghasilkan sebuah file SSH Key bernama infra-k8s.pem. Selanjutnya kita perlu merubah permissionnya supaya dapat digunakan untuk mengakses instance. $ chmod 400 infra-k8s.pem Info Dalam artikel ini saya menggunakan region us-east-1 atau North Virginia. Jika ingin menggunakan regional lain, silahkan lihat dokumentasi resmi AWS. ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:2:3","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Infrastructure Provisioning ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:3:0","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Pasang Paket Terraform Pasang paket terraform pada komputer lokal seperti berikut. $ sudo pacman -Sy terraform Info Saya menggunakan sistem operasi GNU/Linux dengan distro Arch-based yang memiliki package manager pacman. Silahkan sesuaikan dengan perintah package manager pada distro masing-masing. ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:3:1","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Script Terraform Selanjutnya silahkan buat file baru untuk menulis script terraform. Misalnya saya membuat file infra.tf yang akan berisi script Terraform seperti berikut ini. ## AWS Provider terraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"~\u003e 3.0\" } } } ## Init Credentials Profile and Region provider \"aws\" { profile = \"default\" region = \"us-east-1\" shared_credentials_file = \"credentials\" } ## Public Security Group resource \"aws_security_group\" \"public-sec\" { name = \"public\" description = \"Public Server Security Group\" ## SSH, HTTP, HTTPS Access ingress { from_port = 22 to_port = 22 protocol = \"tcp\" cidr_blocks = [\"0.0.0.0/0\"] } ingress { from_port = 80 to_port = 80 protocol = \"tcp\" cidr_blocks = [\"0.0.0.0/0\"] } ingress { from_port = 443 to_port = 443 protocol = \"tcp\" cidr_blocks = [\"0.0.0.0/0\"] } ## Kubernetes Cluster ingress { from_port = 6443 to_port = 6443 protocol = \"tcp\" cidr_blocks = [\"0.0.0.0/0\"] } ingress { from_port = 2379 to_port = 2380 protocol = \"tcp\" cidr_blocks = [\"0.0.0.0/0\"] } ingress { from_port = 10250 to_port = 10250 protocol = \"tcp\" cidr_blocks = [\"0.0.0.0/0\"] } ingress { from_port = 10251 to_port = 10251 protocol = \"tcp\" cidr_blocks = [\"0.0.0.0/0\"] } ingress { from_port = 10252 to_port = 10252 protocol = \"tcp\" cidr_blocks = [\"0.0.0.0/0\"] } egress { from_port = 0 to_port = 0 protocol = \"-1\" cidr_blocks = [\"0.0.0.0/0\"] } tags = { Name = \"public\" Description = \"Public Server Security Group\" } } ## Elastic IP for Public Instance resource \"aws_eip\" \"lb\" { instance = aws_instance.public.id } ## Create Public Instance resource \"aws_instance\" \"public\" { ami = \"ami-00ddb0e5626798373\" instance_type = \"t2.medium\" source_dest_check = false key_name = \"infra-k8s\" subnet_id = \"subnet-0f5a08d3063a6b742\" private_ip = \"172.31.16.20\" vpc_security_group_ids = aws_security_group.public-sec.*.id tags = { Name = \"public\" } ## Disk Space root_block_device { delete_on_termination = true encrypted = false iops = 100 volume_size = 10 } } ## Node Security Group resource \"aws_security_group\" \"node-sec\" { name = \"node\" description = \"Node/Worker Security Group\" ## SSH Access ingress { from_port = 22 to_port = 22 protocol = \"tcp\" ## Close all traffic IP after setup! #cidr_blocks = [\"172.31.16.20/32\"] cidr_blocks = [\"0.0.0.0/0\"] } ## Kubernetes Cluster ingress { from_port = 10250 to_port = 10250 protocol = \"tcp\" cidr_blocks = [\"172.31.16.20/32\"] } ingress { from_port = 10255 to_port = 10255 protocol = \"tcp\" cidr_blocks = [\"172.31.16.20/32\"] } ingress { from_port = 30000 to_port = 32767 protocol = \"tcp\" cidr_blocks = [\"172.31.16.20/32\"] } ingress { from_port = 3000 to_port = 3000 protocol = \"tcp\" cidr_blocks = [\"172.31.16.20/32\"] } egress { from_port = 0 to_port = 0 protocol = \"-1\" cidr_blocks = [\"0.0.0.0/0\"] } tags = { Name = \"node\" Description = \"Node/Worker Security Group\" } } ## Elastic IP for Node Server (Temporary) resource \"aws_eip\" \"lb-node\" { count = 2 instance = aws_instance.node[count.index].id } ## Create Instance Node resource \"aws_instance\" \"node\" { ami = \"ami-00ddb0e5626798373\" instance_type = \"t2.small\" associate_public_ip_address = false source_dest_check = false key_name = \"infra-k8s\" subnet_id = \"subnet-0f5a08d3063a6b742\" vpc_security_group_ids = aws_security_group.node-sec.*.id count = 2 tags = { Name = \"node-${count.index + 1}\" } ## Disk Space root_block_device { delete_on_termination = true encrypted = false iops = 100 volume_size = 10 } } Perhatian Sesuaikan variabel subnet_id dengan id Subnet VPC yang telah kita buat sebelumnya. Sedangkan variabel ami merupakan id dari Amazon Machine Image yang value nya tergantung dari distro apa yang akan kita jalankan pada setiap instance EC2 untuk informasi lebih lanjut kita dapat melihatnya dari dokumentasi resmi AWS karena setiap region dan distro hingga sistem operasi memiliki AMI ID yang berbeda-beda. Terlihat bahwa saya membuka seluruh traffic dari inbound dan outbound yang tentu saja tidaklah aman, sesuaikan dengan kebutuhan port Kubernetes p","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:3:2","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Eksekusi Terraform Sekarang jalankan provisioning menggunakan terraform sesuai dengan script yang telah dibuat sebelumnya. $ terraform apply ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:3:3","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Configuration Provisioning ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:4:0","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Pasang Paket Ansible Pasang ansible pada komputer lokal menggunakan perintah berikut. $ sudo pacman -Sy ansible ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:4:1","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Konfigurasi Ansible Kita perlu membuat sebuah file bernama ansible.cfg yang berisi konfigurasi seperti berikut. [defaults] inventory = inventory Private_key_file = infra-k8s.pem remote_user = ubuntu ansible_python_interpreter = /usr/bin/python3 host_key_checking = false remote_tmp = /tmp/.ansible-${USER}/tmp Perhatian Variabel remote_user adalah user pada instance EC2 yang akan dipakai untuk penerapan provisioning, by-default pada AWS untuk AMI Ubuntu 18 menggunakan user ubuntu. Jika menggunakan AMI lain maka kita perlu menyesuaikannya. ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:4:2","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Inventory Ansible Playbook Jalankan perintah berikut untuk mendapatkan IP Publik dari Master Node. $ aws ec2 describe-instances \\ --region us-east-1 \\ --filters \"Name=tag-value,Values=public\" Jalankan perintah berikut untuk mendapatkan IP Publik dari Worker Node pertama. $ aws ec2 describe-instances \\ --region us-east-1 \\ --filters \"Name=tag-value,Values=node-1\" Jalankan perintah berikut untuk mendapatkan IP Publik dari Worker Node pertama. $ aws ec2 describe-instances \\ --region us-east-1 \\ --filters \"Name=tag-value,Values=node-2\" Kemudian masukan ketiga IP tersebut ke dalam file bernama inventory sehingga kurang lebih isinya akan menjadi seperti berikut. [public] 18.233.242.19 [nodes] 3.224.63.65 54.198.25.43 ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:4:3","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Docker Selanjutnya saya membuat file baru bernama docker.yml yang berisi script untuk melakukan update sistem operasi dan setup Docker. - hosts: all gather_facts: false tasks: - name: Update \u0026 Upgrade become: yes apt: upgrade: dist update_cache: yes - name: Install Docker Requiremts become: yes apt: name: - ca-certificates - curl - gnupg-agent - python3-pip - software-properties-common - name: GPG Key Docker become: yes apt_key: url: https://download.docker.com/linux/ubuntu/gpg - name: Repo Docker become: yes apt_repository: repo: deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable state: present update_cache: yes - name: Install Docker become: yes apt: force: True name: - docker-ce - name: Hold Docker become: yes dpkg_selections: name: docker-ce selection: hold - name: Install Docker Py as root become: yes command: pip3 install docker-py - name: Install Docker Py as normal user command: pip3 install docker-py - name: Enable service docker, and enable persistently become: yes service: name: docker enabled: yes - name: Add the user 'ubuntu' to docker group become: yes user: name: ubuntu group: docker Terapkan script yang telah kita buat dengan Ansible Playbook seperti berikut. $ ansible docker.yml Jika berhasil maka akan muncul tampilan seperti berikut ini. PLAY RECAP ******************************************************************************************************* 18.233.242.19 : ok=10 changed=9 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 3.224.63.65 : ok=10 changed=9 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 54.198.25.43 : ok=10 changed=9 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:4:4","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Bootstraping Kubernetes Sekarang buat file baru bernama k8s.yml yang berisi script untuk melakukan setup Kubernetes. - hosts: all gather_facts: false tasks: - name: Add Google official GPG key become: yes apt_key: url: https://packages.cloud.google.com/apt/doc/apt-key.gpg state: present - name: Add Kubernetes Repository become: yes apt_repository: repo: deb http://apt.kubernetes.io/ kubernetes-xenial main state: present filename: kubernetes mode: 0600 - name: Installing Kubernetes Cluster Packages become: yes apt: force: True name: - kubeadm - kubectl - kubelet state: present - name: Hold kubeadm become: yes dpkg_selections: name: kubeadm selection: hold - name: Hold kubectl become: yes dpkg_selections: name: kubectl selection: hold - name: Hold kubelet become: yes dpkg_selections: name: kubelet selection: hold - name: Add line Net Bridge on sysctl.conf become: yes lineinfile: path: /etc/sysctl.conf line: net.bridge.bridge-nf-call-iptables=1 - name: Add line 'max_map_count' on sysctl.conf become: yes lineinfile: path: /etc/sysctl.conf line: vm.max_map_count=262144 - name: Apply change on sysctl become: yes become_method: sudo shell: sysctl -p - hosts: public gather_facts: false tasks: - name: Initialize k8s cluster become: yes become_method: sudo shell: kubeadm reset -f - name: Start k8s init become: yes become_method: sudo shell: kubeadm init --pod-network-cidr=10.244.0.0/16 register: kubeadm_result - debug: var: kubeadm_result.stdout_lines - name: Make configuration folder for k8s become: yes become_user: ubuntu file: state: directory path: /home/ubuntu/.kube mode: 0755 - name: Copy configuration k8s into home become: yes copy: src: /etc/kubernetes/admin.conf dest: /home/ubuntu/.kube/config remote_src: yes owner: ubuntu - name: apply network plugin flannel become: yes become_user: ubuntu shell: kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml - hosts: nodes gather_facts: false vars_prompt: - name: \"kubeadm\" prompt: \"kubeadm Command \" private: no tasks: - name: Reset kubeadm become: yes become_method: sudo shell: kubeadm reset -f - name: Prune docker images become: yes become_method: sudo shell: sudo docker image prune -af - name: Retriving input command kubeadm become: yes become_method: sudo shell: \"{{ kubeadm }}\" Kemudian terapkan script tersebut dengan Ansible Playbook seperti berikut. $ ansible k8s.yml ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:4:5","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Joining Cluster Di tengah proses, kita akan diberikan sebuah token yang harus dimasukkan secara manual. Token tersebut digunakan oleh Worker Node untuk bergabung ke dalam klaster. Join Token Jika berhasil maka akan muncul tampilan seperti berikut ini. PLAY RECAP ******************************************************************************************************* 18.233.242.19 : ok=15 changed=14 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 3.224.63.65 : ok=12 changed=12 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 54.198.25.43 : ok=12 changed=12 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:4:6","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Post Installation ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:5:0","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Menghapus Worker Node Elastic IP Karena Worker Node sudah tidak lagi membutuhkan IP Publik, maka kita akan menghapusnya dengan cara merubah script file infra.tf yang sebelumnya kita buat. Jadikan beberapa baris konfigurasi menjadi comment seperti berikut ini. ## Elastic IP for Node Server (Temporary) #resource \"aws_eip\" \"lb-node\" { # count = 2 # instance = aws_instance.node[count.index].id #} Dan tambahkan comment juga pada baris konfigurasi variabel associate_public_ip_address. #associate_public_ip_address = false Kemudian jalankan kembali Terraform seperti berikut. $ terraform apply Periksa dan jika sudah benar maka ketik yes dan tekan Enter. Apabila berhasil maka akan muncul tampilan seperti berikut. aws_eip.lb-node[1]: Destroying... [id=eipalloc-0adb19f75c6648130] aws_eip.lb-node[0]: Destroying... [id=eipalloc-07464709ac36cafe4] aws_eip.lb-node[0]: Destruction complete after 5s aws_eip.lb-node[1]: Destruction complete after 5s Apply complete! Resources: 0 added, 0 changed, 2 destroyed. ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:5:1","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Ubah Label Worker Node Sekarang coba akses Master Node lewat SSH menggunakan SSH Key yang sebelumnya telah kita miliki. $ ssh -i infra-k8s.pem ubuntu@18.233.242.19 Perhatian Sesuaikan dengan alamat IP Publik yang dimiliki oleh Master Node atau Control Plane. Setelah berhasil masuk, sekarang jalankan perintah berikut. $ kubectl get nodes Maka akan muncul daftar node yang terhubung pada klaster. NAME STATUS ROLES AGE VERSION ip-172-31-16-20 Ready control-plane,master 8m50s v1.20.2 ip-172-31-25-81 Ready \u003cnone\u003e 7m41s v1.20.2 ip-172-31-29-192 Ready \u003cnone\u003e 7m40s v1.20.2 Ubah ROLES Worker Node dengan menambahkan label. $ kubectl label node ip-172-31-25-81 node-role.kubernetes.io/worker=worker1 $ kubectl label node ip-172-31-29-192 node-role.kubernetes.io/worker=worker2 Perhatian Sesuaikan nama node dengan NAME seperti yang muncul dari hasil pemeriksaan daftar node. ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:5:2","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Pengujian Sekarang coba periksa lagi daftar node yang ada. $ kubectl get nodes Jika berhasil hasilnya akan menjadi seperti berikut. NAME STATUS ROLES AGE VERSION ip-172-31-16-20 Ready control-plane,master 8m50s v1.20.2 ip-172-31-25-81 Ready worker 7m41s v1.20.2 ip-172-31-29-192 Ready worker 7m40s v1.20.2 Periksa pod yang berjalan pada semua namespace. $ kubectl get pods --all-namespaces Hasilnya kurang lebih akan seperti berikut. NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-74ff55c5b-kfzvr 1/1 Running 0 4h56m kube-system coredns-74ff55c5b-qrz2j 1/1 Running 0 4h56m kube-system etcd-ip-172-31-16-20 1/1 Running 0 4h56m kube-system kube-apiserver-ip-172-31-16-20 1/1 Running 0 4h56m kube-system kube-controller-manager-ip-172-31-16-20 1/1 Running 0 4h56m kube-system kube-flannel-ds-hltkg 1/1 Running 0 4h55m kube-system kube-flannel-ds-jvvbv 1/1 Running 0 4h56m kube-system kube-flannel-ds-xfdq8 1/1 Running 0 4h55m kube-system kube-proxy-67kgp 1/1 Running 0 4h55m kube-system kube-proxy-bd7cj 1/1 Running 0 4h56m kube-system kube-proxy-gjkr6 1/1 Running 0 4h55m kube-system kube-scheduler-ip-172-31-16-20 1/1 Running 0 4h56m ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:6:0","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Kesimpulan Dengan menggunakan Terraform dan Ansible, kita dapat membangun klaster Kubernetes sendiri pada AWS. Salah satu keunggulan yang saya rasakan adalah fleksibilitas yang tinggi, dimana saya dapat menggunakan spesifikasi instance yang terbilang rendah untuk mencoba membangun klaster Kubernetes jika dibandingkan dengan menggunakan distribusi Kubernetes (seperti OKD atau OpenShift). Jika semua script telah tersedia, maka proses instalasi klaster bisa dikatakan sangat cepat. ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:7:0","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Platform"],"content":"Referensi registry.terraform.io/providers/hashicorp/aws/latest/docs docs.ansible.com/ansible/latest/reference_appendices/playbooks_keywords.html kubernetes.io/docs/setup/production-environment/container-runtimes/#docker kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/ docs.aws.amazon.com/cli/latest/reference/ec2/ docs.aws.amazon.com/cli/latest/userguide/cli-services-ec2-keypairs.html docs.aws.amazon.com/cli/latest/userguide/cli-services-ec2-instances.html docs.aws.amazon.com/cli/latest/reference/ec2/describe-vpcs.html blog.leonprasetya.my.id ","date":"2021-01-17","objectID":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/:8:0","tags":["Kubernetes","Terraform","Ansible","AWS"],"title":"Kubernetes Cluster Provisioning dengan Terraform dan Ansible","uri":"/kubernetes-cluster-provisioning-dengan-terraform-dan-ansible/"},{"categories":["Tools"],"content":"Memasang Sysdig Agent pada OpenShift untuk Monitoring Cloud Native Environment Cluster OpenShift.","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Sysdig mampu menyediakan Cloud Monitoring yang memungkinkan kita untuk memaksimalkan performa dan ketersediaan dari infrastruktur, layanan, dan aplikasi berbasis cloud. Pada artikel ini saya akan mencoba mengintegrasikan layanan Sysdig Monitor dengan klaster OpenShift Cloud Platform. ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:0:0","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Sysdig Sysdig adalah sebuah Software as a Service (SaaS) yang bertugas untuk mengambil timeseries data atau biasa disebut metric dari klaster atau cloud native environment kemudian mengolah lalu menampilkannya secara real time untuk berbagai kebutuhan, misalnya akselerasi troubleshooting, monitoring at scale, menyederhanakan visibilitas metric, membangun dashboard monitoring yang fleksibel, hingga memberikan alert dengan respon cepat. Sysdig membagi produknya menjadi beberapa jenis, yaitu Sysdig Monitor, Sysdig Secure, dan gabungan dari keduanya yang disebut dengan Sysdig Platform atau Sysdig Secure DevOps Platform. Semua produk tersebut sebenarnya adalah komersil, namun kita dapat mencobanya dengan free-trial selama satu bulan. Pada artikel ini saya hanya akan mencoba mengintegrasikan Sysdig Monitor saja. Sysdig ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:1:0","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Metrics Metric adalah nilai kuantitatif atau ukuran yang dapat dikelompokkan atau dibagi dengan label. Metric dari Sysdig Monitor dibagi menjadi dua jenis seperti berikut. Default metrics, yaitu metric yang berhubungan dengan sistem atau host, container, orchestrator, HTTP, dan infrastruktur jaringan. Custom metrics, berhubungan dengan metric yang didapat dari aplikasi pihak ketiga seperti JMX, StatsD, Prometheus dan beberapa metric dari aplikasi lain yang terintegrasi. Sysdig secara otomatis mengambil metric dari berbagai tipe, dan melabelinya secara otomatis. Custom Metric juga dapat dilabeli sesuai kebutuhan pengguna. Biasanya metric akan berguna untuk membuat Dashboard hingga Alerts. Metric ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:1:1","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Sysdig Agent Untuk dapat berjalan pada lingkungan cloud native yang kita miliki, Sysdig menggunakan agent yang disebut dengan Sysdig Agent, di mana agent tersebut diwujudkan sebagai sebuah container atau sebuah service yang dapat di-deploy dengan atau tanpa container orchestrator seperti Kubernetes atau Mesos. ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:1:2","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Prerequisites Pastikan beberapa syarat ini terpenuhi sebelum melakukan tahap lebih lanjut. ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:2:0","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Membuat Akun Kita memerlukan sebuah akun free-trial untuk mencoba Sysdig. Akun ini kita perlukan agar dapat mengoperasikan dashboard front end Sysdig Monitor dari klaster OpenShift kita. Silahkan membuat akun Sysdig dengan alamat berikut. Membuat Akun Sysdig Isi beberapa data yang dibutuhkan seperti nama, jabatan pekerjaan, alamat email, nama perusahaan, dan negara. Kemudian pilih Trial Offer yang dibutuhkan, misalnya Sysdig Monitor. Untuk SaaS Region dapat dipilih berdasarkan di mana letak infrastruktur kita berada. Karena saya menggunakan layanan AWS di Amerika Serikat untuk menjalankan klaster OpenShift, maka saya memilih Region us-west. Kemudian untuk Primay Use Cases dapat di pilih apapun, misalnya Kubernetes Monitoring. Konfirmasi Email Jika kata sandi sudah dibuat, biasanya kita perlu menunggu sekitar 15 menit untuk dapat masuk ke front-end dari Setelah membuat akun, tunggu beberapa saat dan kita akan mendapatkan sebuah email untuk membuat kata sandi baru. ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:2:1","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Mendapatkan Access Key Untuk mendapatkan access key kita perlu masuk ke situs front end Sysdig. Kita dapat mengaksesnya dengan URL sesuai dengan Region yang kita gunakan. Region URL US East (North Virginia) app.sysdigcloud.com/#/login US West (Oregon) us2.app.sysdig.com/#/login European Union eu1.app.sysdig.com/#/login Setelah login, lalu masuk ke halaman Settings seperti berikut ini. Settings Kemudian, pilih Agent Installation maka akan terdapat Access Key yang nanti akan kita gunakan. Settings - Agent Installation ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:2:2","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Klaster OpenShift Di sini saya telah memiliki klaster OpenShift 4 dari hasil instalasi dengan metode IPI seperti yang telah saya tulis pada artikel sebelumnya (Quick Install OKD 4 di AWS). Dan pastikan bahwa OpenShift dapat dikelola dari komputer lokal kita menggunakan perintah oc atau origin-client. Klaster Openshift ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:2:3","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Konfigurasi OpenShift Jika prasyarat sebelumnya telah terpenuhi, maka kita dapat melanjutkan beberapa tahap berikut. ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:3:0","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Membuat Project Baru Buat sebuah project baru untuk deployment Sysdig Agent seperti berikut. $ oc adm new-project sysdig-agent --node-selector='app=sysdig-agent' ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:3:1","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Melabeli Node Labeli semua node dengan node selector seperti berikut ini. $ oc label node --all \"app=sysdig-agent\" ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:3:2","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Pindah Project Sekarang kita akan berpindah menuju project yang baru saja dibuat, jalankan perintah berikut. $ oc project sysdig-agent ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:3:3","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Membuat Service Account Kita perlu membuat service account baru untuk project sysdig-agent. $ oc create serviceaccount sysdig-agent ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:3:4","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Previlege Security Context Constraints Tambahkan service account sebelumnya ke previleged Security Context Constraint dengan perintah berikut ini. $ oc adm policy add-scc-to-user privileged -n sysdig-agent -z sysdig-agent ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:3:5","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Cluster Role Tambahkan service account sebelumnya ke Cluster Role cluster-reader seperti berikut. $ oc adm policy add-cluster-role-to-user cluster-reader -n sysdig-agent -z sysdig-agent ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:3:6","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Memasang Sysdig Agent Pada tahap ini saya akan menggunakan Helm untuk mempermudah dan mempercepat pemasangan Sysdig Agent pada klaster. ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:4:0","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Pasang Paket Helm Sebelumnya pasang terlebih dahulu paket helm di komputer lokal kita dengan perintah seperti berikut. $ sudo pacman -Sy helm Perhatian Saya menggunakan sistem GNU/Linux dengan distro Arch-based, maka di sini saya memakai package manager pacman. Silahkan sesuaikan dengan distro yang kalian gunakan. ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:4:1","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Menambah Repositori Tambahkan repositori Helm dari Sysdig ke komputer lokal. $ helm repo add sysdig https://charts.sysdig.com $ helm repo update ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:4:2","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Pasang Sysdig Agent dengan Helm Jalankan perintah berikut ini untuk memasang Sysdig Agent melalui Helm. $ helm install sysdig-agent \\ --set sysdig.accessKey=\u003caccess key\u003e \\ --set sysdig.settings.collector=ingest-us2.app.sysdig.com \\ --set sysdig.settings.collector_port=6443 \\ --set sysdig.settings.k8s_cluster_name=\u003cnama klaster\u003e \\ --set sysdig.settings.ssl=true \\ --set sysdig.settings.ssl_verify_certificate=false \\ sysdig/sysdig Sesuaikan accessKey dengan yang kita dapat dari front-end Sysdig di tahap sebelumnya. Sesuaikan juga k8s_cluster_name dengan nama klaster OpenShift kita. Sedangkan untuk collector dan collector_port disesuaikan dengan region dari akun Sysdig yang kita gunakan, di sini saya memakai ingest-us2.app.sysdig.com:6443 karena saya menggunakan akun Sysdig dengan region us-west. Untuk informasi selengkapnya dari masing-masing region, silahkan melihat alamat kolektor dari Sysdig. ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:4:3","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Pengujian Jika tahap-tahap sebelumnya telah dilakukan, sekarang kita akan menguji apakah Sysdig Agent berhasil terpasang pada klaster. ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:5:0","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Pods Coba periksa pods milik Sysdig Agents dengan perintah berikut. $ oc get pods Jika berhasil, maka kurang lebih akan muncul tampilan seperti berikut. NAME READY STATUS RESTARTS AGE sysdig-agent-2wcsj 1/1 Running 0 32m sysdig-agent-45hgx 1/1 Running 0 32m sysdig-agent-559z9 1/1 Running 0 32m sysdig-agent-89wqp 1/1 Running 0 32m sysdig-agent-b5vbn 1/1 Pending 0 32m sysdig-agent-b9rlt 1/1 Running 0 32m sysdig-agent-image-analyzer-2rjht 1/1 Running 0 32m sysdig-agent-image-analyzer-5vmp2 1/1 Running 0 32m sysdig-agent-image-analyzer-m6xkb 1/1 Running 0 32m sysdig-agent-image-analyzer-mhgb7 1/1 Running 0 32m sysdig-agent-image-analyzer-n8xm2 1/1 Running 0 32m sysdig-agent-image-analyzer-pgr9p 1/1 Running 0 32m sysdig-agent-image-analyzer-pn8kv 1/1 Running 0 32m sysdig-agent-image-analyzer-q4mvv 1/1 Running 0 32m sysdig-agent-image-analyzer-rstz5 1/1 Running 0 32m sysdig-agent-n4wqv 1/1 Running 0 32m sysdig-agent-pd745 1/1 Running 0 32m sysdig-agent-vsr4b 1/1 Running 0 32m ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:5:1","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Front End Buka kembali dashboard front-end Sysdig, apabila Sysdig Agent berhasil terpasang maka seharusnya pada halaman Get Started akan muncul tampilan seperti berikut. Front End Sysdig Selanjutnya coba buka Dashboard kemudian misalnya pilih saja Host Resource Usage, seharusnya akan tampil informasi penggunaan resource dari klaster seperti berikut ini. Host Resource Usage Sedangkan untuk menampilkan Overview kita perlu menunggu beberapa saat karena Sysdig membutuhkan waktu yang cukup lama untuk mengolah metric dari klaster. Jika sudah bisa ditampilkan, maka kurang lebih akan seperti berikut. Sysdig Monitor Overview ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:5:2","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Kesimpulan Jika kita ingin melakukan inspeksi lebih lanjut terhadap container yang ada pada klaster, sebenarnya kita dapat memilih menggunakan Sysdig Platform di mana kita juga akan mendapatkan Sysdig Secure untuk keperluan forensik atau kebutuhan lain terkait keamanan pada klaster. Pada bagian Settings di Sysdig Monitor kita akan mendapati beberapa fitur Notification Channels yang lumayan berguna. Fitur tersebut dapat kita kombinasikan dengan menu Alerts untuk mengirimkan pemberitahuan langsung melalui beberapa macam layanan seperti Email, Slack, hingga WebHook. Sebagai alternatif lain dari Sysdig kita dapat menggunakan tools seperti GAP Stack (Grafana, Alertmanager, Prometheus) atau DataDog. Sebelumnya saya mencoba untuk mengintegrasikan Sysdig pada OKD namun menemui issue pada pod Sysdig Agent, selanjutnya saya putuskan untuk mencobanya di klaster OpenShift dan Sysdig Monitor dapat berjalan tanpa kendala. ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:6:0","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Tools"],"content":"Referensi docs.sysdig.com/en/getting-started-with-sysdig-monitor.html docs.sysdig.com/en/host-requirements-for-agent-installation.html docs.sysdig.com/en/steps-for-openshift.html charts.sysdig.com/ docs.sysdig.com/en/saas-regions-and-ip-ranges.html docs.openshift.com/container-platform/4.6/cli_reference/helm_cli/getting-started-with-helm-on-openshift-container-platform.html www.openshift.com/blog/monitoring-openshift-three-tools kubernetes.io/docs/concepts/cluster-administration/system-metrics/ ","date":"2021-01-12","objectID":"/integrasi-sysdig-monitor-di-openshift/:7:0","tags":["Sysdig","OpenShift","Monitoring","SaaS"],"title":"Integrasi Sysdig Monitor di OpenShift","uri":"/integrasi-sysdig-monitor-di-openshift/"},{"categories":["Platform"],"content":"Membangun Cluster OKD 4 di AWS dengan Installer-Provisioned Infrastructure","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"OKD 4 memiliki installer yang menawarkan fleksibilitas dan kemudahan bagi pengguna. Proses instalasi hanya akan memakan waktu sekitar 40 menit hingga cluster OKD sudah dapat berjalan dan siap untuk dikelola. ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:0:0","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"OKD 4 OKD adalah distribusi dari Kubernetes yang menjadi upstream dari pengembangan OpenShift. OKD merupakan versi community dari OpenShift, yang dapat digunakan tanpa biaya subscription. Kode sumbernya dipublikasikan pada repositori Github, dan semua orang dapat berkontribusi untuk mengembangkannya. Silahkan lihat perbandingan antara OKD 4 dengan OKD 3 pada dokumentasi resmi OKD. ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:1:0","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Jenis Instalasi Pada umumnya terdapat 2 macam instalasi OKD 4 seperti berikut. IPI (Installer-Provisioned Infrastructure). Dengan metode IPI, installer akan bertindak sepenuhnya dalam proses instalasi cluster. Setiap machine harus mampu mengakses internet untuk menarik images yang diperlukan untuk inisialisasi ketika deployment cluster. IPI merupakan cara paling cepat untuk membangun cluster OKD yang dapat kita implementasikan pada AWS (Amazon Web Service), GCP (Google Cloud Platform), Azure, hingga baremetal. Dalam artikel ini saya akan menggunakan IPI sebagai metode instalasi. UPI (User-Provisioned Infrastructure). Mirip dengan IPI, namun lebih advanced, di mana kita dapat menggunakan metode UPI jika benar-benar concern terhadap keamanan. Biasanya cluster akan membutuhkan sebuah proxy dan akses ke internet akan lebih dibatasi. Karena akses ke internet yang lebih ketat, maka cluster juga memerlukan mirror registry yang lebih spesifik. UPI cenderung lebih rumit, namun memiliki pilihan konfigurasi yang sangat beragam dibandingkan metode IPI, misalnya seperti mengganti sistem operasi machine dengan RHCOS (Red Hat Enterprise Linux CoreOS). ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:1:1","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Installation Workflow OKD menggunakan sebuah bootstrap machine temporer pada saat inisialisasi konfigurasi guna menyediakan informasi yang diperlukan bagi control plane. Bootstrap machine dihidupkan dengan sebuah file konfigurasi bernama Ignition yang mendeskripsikan bagaimana proses pembangunan cluster akan dilakukan. Bootstrap machine akan membuat sebuah master machine yang digunakan sebagai control plane. Dan control plane kemudian akan membuat compute machine atau yang biasa disebut sebagai worker machine. Proses Bootstraping Setelah semua machine pada cluster di-inisialisasi, maka bootstrap machine akan di-destroy. Jika menggunakan metode UPI, kita perlu melakukan beberapa proses di atas secara manual. ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:2:0","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Minimum Requirements OKD 4 memiliki syarat minimum spesifikasi sistem yang cenderung mirip dengan OKD 3. Berikut ini adalah spesifikasi singkat sebagai gambarannya. Host Specs Masters 4 vCPUs dan 16 GB RAM Nodes 1 vCPUs dan 8 GB RAM Jika menggunakan AWS sebagai host, maka by-default OKD installer akan membuat instance dengan tipe m5.xlarge sebagai master dan tipe m5.large sebagai worker. Untuk lebih lengkapnya silahkan baca spesifikasi minimum di dokumentas resmi OKD dan jenis-jenis dari instance AWS EC2. ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:3:0","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Prerequisites Sebelum melakukan instalasi lebih lanjut, pastikan beberapa hal berikut sudah terpenuhi. ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:4:0","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Akses AWS Pasang paket aws-cli pada komputer lokal. $ sudo pacman -Sy aws-cli Perhatian Dalam artikel ini saya akan menggunakan AWS Programmatic Access sebagai credentials untuk mengelola AWS menggunakan aws-cli. Untuk informasi lebih lanjut silahkan baca dokumentasi AWS CLI. Saya memiliki AWS Programmatic Access yang terdiri dari aws_access_key_id dan aws_secret_access_key. Masukkan kedua key tersebut ke dalam konfigurasi aws cli. $ mkdir -p ~/.aws $ vim ~/.aws/credentials Isi file credentials dengan kedua key yang kita meliki, sehingga kurang lebih akan manjadi seperti berikut. [default] aws_access_key_id=AKIA3ANXUSNAUAXXXXXX aws_secret_access_key=+JDR1HWw4vrcFrLqbf+ewv/nJL/L6TlVAhXXXXXX ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:4:1","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"SSH Private Key Kita perlu menambahkan SSH key ke agent dan installer untuk menampilkan informasi ketika proses instalasi berjalan, atau untuk melakukan pengelolaan lebih lanjut terhadap cluster menggunakan installer. Di sini saya sudah memiliki SSH key seperti berikut. /home/pwn3r/.ssh ├── id_rsa ├── id_rsa.pub └── known_hosts Jika belum memiliki SSH key kita dapat membuatnya dengan ssh-keygen. $ ssh-keygen -t rsa -b 4096 -N '' -f ~/.ssh/id_rsa Kemudian jalankan ssh-agent di background. $ eval \"$(ssh-agent -s)\" Lalu tambahkan SSH key ke ssh-agent. $ ssh-add ~/.ssh/id_rsa ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:4:2","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Unduh Installer Program installer dapat diunduh dari https://github.com/openshift/okd/releases. Installer OKD 4 Untuk lebih mudahnya saya akan membuat sebuah direktori baru bernama okd pada home directory dan mengunduh installer ke dalam direktori tersebut. $ mkdir ~/okd $ cd ~/okd $ wget https://github.com/openshift/okd/releases/download/4.6.0-0.okd-2020-12-12-135354/openshift-install-linux-4.6.0-0.okd-2020-12-12-135354.tar.gz Perhatian Pastikan URL installer untuk perintah wget di atas sesuai dengan versi yang benar. Pada saat artikel ini diterbitkan, OKD terbaru berada pada versi 4.6. Ekstrak file tar.gz dengan perintah berikut. $ tar -xvf openshift-install*.tar.gz Kita akan memiliki sebuah file bernama openshift-install, jadikan file tersebut menjadi executable. $ chmod +x openshift-install ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:4:3","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Instalasi Untuk melakukan instalasi kita cukup menjalankan satu perintah seperti berikut. $ ./openshift-install create cluster --log-level=info Selanjutnya installer akan meminta beberapa informasi yang dibutuhkan, silahkan pilih atau isi sesuai dengan kebutuhan. Pull Secret bisa diperoleh dari situs Red Hat OpenShift Cluster Manager. Cukup tekan Copy pull secret dan paste pada terminal ketika installer memintanya. Pull Secret ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:5:0","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Hasil Proses akan berlangsung sedemikian rupa secara otomatis. Pada umumnya intalasi cluster OKD dengan konfigurasi default akan berlangsung sekitar 40 menit. Jika berhasil kurang lebih akan muncul tampilan seperti berikut. Proses Instalasi ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:5:1","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Pengujian Kita akan melakukan beberapa pemeriksaan terhadap cluster OKD 4. Selain lewat web browser, kita dapat menggunakan oc atau origin-client. Jika belum memilikinya maka lakukan pemasangan paket pada komputer lokal seperti berikut. $ yay -Sy origin-client Info Pada distro Arch-based, origin-client tersedia pada AUR (Arch User Repository). Untuk melakukan instalasi paket dari AUR, saya menggunakan AUR Helper bernama yay. ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:6:0","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Login sebagai System Admin Untuk bertindak sebagai sistem admin melalui perintah oc, kita me-export variabel environment seperti berikut. $ export KUBECONFIG=/home/pwn3r/okd/auth/kubeconfig Kemudian jalankan periksa user yang sedang berjalan di sesi oc saat ini. $ oc whoami Harusnya akan muncuk tampilan seperti berikut. system:admin ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:6:1","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Periksa Nodes Coba periksa apakah semua node sudah dalam keadaan berjalan dengan oc. $ oc get nodes Kurang lebih akan muncul tampilan seperti berikut. NAME STATUS ROLES AGE VERSION ip-10-0-130-52.us-west-1.compute.internal Ready master 5h41m v1.19.2+7070803-1008 ip-10-0-132-253.us-west-1.compute.internal Ready master 5h41m v1.19.2+7070803-1008 ip-10-0-155-103.us-west-1.compute.internal Ready worker 5h31m v1.19.2+7070803-1008 ip-10-0-166-37.us-west-1.compute.internal Ready worker 5h32m v1.19.2+7070803-1008 ip-10-0-225-80.us-west-1.compute.internal Ready master 5h41m v1.19.2+7070803-1008 ip-10-0-240-130.us-west-1.compute.internal Ready worker 5h32m v1.19.2+7070803-1008 Terlihat bahwa terdapat 3 node yang bertindak sebagai master, dan 3 node lain sebagai worker. ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:6:2","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Scaling MachineSet Periksa machineset yang ada dengan perintah berikut. $ oc get machineset -n openshift-machine-api Maka akan tampil machineset yang ada pada OKD. NAME DESIRED CURRENT READY AVAILABLE AGE itglab-f2l75-worker-us-west-1a 2 2 2 2 5h48m itglab-f2l75-worker-us-west-1b 1 1 1 1 5h48m Artinya machineset itglab-f2l75-worker-us-west-1a memiliki replika sebanyak 2 buah. Sedangkan itglab-f2l75-worker-us-west-1b hanya memiliki 1 replika. Sekarang coba lakukan scaling supaya machineset memiliki 2 buah replikasi. $ oc scale --replicas=2 machinesets itglab-f2l75-worker-us-west-1b -n openshift-machine-api Biasanya kita perlu menunggu beberapa saat supaya machine berjalan dan kemudian bergabung pada machineset itglab-f2l75-worker-us-west-1b. Lama durasi tergantung pada spesifikasi sistem yang kita gunakan di AWS. Periksa apakah scaling berhasil dilakukan dengan menjalankan kembali perintah berikut. $ oc get machineset -n openshift-machine-api Jika berhasil maka semua machineset akan menjadi seperti berikut. NAME DESIRED CURRENT READY AVAILABLE AGE itglab-f2l75-worker-us-west-1a 2 2 2 2 5h58m itglab-f2l75-worker-us-west-1b 2 2 2 2 5h58m ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:6:3","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Web Console OKD Sekarang coba akses OKD Console melalui web browser dengan alamat dan kata sandi seperti yang terlihat sebelumnya menggunakan username kubeadmin. OKD Web Console ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:6:4","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Destroy Cluster Installer OKD 4 juga memiliki fitur untuk menghapus semua resource yang telah dibuat sehingga saya tidak perlu repot-repot membersihkan satu region di AWS Console. Destroy cluster dapat dijalankan dengan perintah seperti berikut. $ ./openshift-install destroy cluster --log-level=info ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:6:5","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Kesimpulan OKD 4 memiliki installer yang tergolong mudah untuk diimplementasikan (pada AWS). Setiap node OKD 4 berjalan dengan sistem operasi FCOS (Fedora Core OS), namun jika kita menggunakan OpenShift maka yang digunakan adalah RHCOS (Red Hat Enterprise Linux CoreOS). OKD 4 menggunakan Prometheus untuk mendapatkan metric yang berguna untuk monitoring. Container Runtime yang dipakai oleh OKD 4 adalah CRI-O. ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:7:0","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Referensi docs.okd.io/latest/architecture/architecture-installation.html docs.okd.io/latest/installing/installing_aws/installing-aws-default.html wiki.archlinux.org/index.php/OpenShift github.com/openshift/okd#getting-started github.com/openshift/okd/blob/master/FAQ.md github.com/openshift/okd/releases docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html aws.amazon.com/ec2/instance-types/ ","date":"2021-01-09","objectID":"/quick-install-okd-4-di-aws/:8:0","tags":["OpenShift","OKD","AWS","PaaS"],"title":"Quick Install OKD 4 di AWS","uri":"/quick-install-okd-4-di-aws/"},{"categories":["Platform"],"content":"Instalasi Minishift untuk menjalankan cluster node OKD (OpenShift) di komputer lokal.","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Minishift membangun klaster single-node OKD (Openshift) pada VM (Virtual Machine) yang berdiri di atas Hypervisor milik komputer lokal. Dengan Minishift kita dapat mempelajari OKD dalam komputer sendiri sebelum menggunakan teknologi Openshift di lingkungan production sebenarnya. ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:0:0","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"OpenShift dan OKD OpenShift adalah distribusi dari Kubernetes yang memiliki fungsi serupa, namun memiliki beberapa fitur tambahan yang memanjakan. Seiring dengan populernya ide cloud computing, berbagai evolusi komputasi telah terjadi. Misalnya adalah metode dalam mengembangkan dan delivery aplikasi untuk sampai ke hadapan user. Seringkali aplikasi/product digital akan dikemas dalam bentuk container untuk alasan kompabilitas, skalabilitas, keamanan, hingga kecepatan pengembangan. Kubernetes awalnya diinisialisasi oleh Google dan kini dikembangkan oleh CNCF, sedangkan OpenShift dinaungi oleh Red Hat menawarkan kemampuan manajemen workloads aplikasi serta otomatisasi secara deklaratif. OpenShift merupakan paid-product, namun kita juga dapat menggunakan versi free of charge bernama OKD sebagai alternatif. OKD pernah bernama OpenShift Origin sebelum mengalami pergantian julukan. Saat artikel ini diterbitkan, OKD telah berkembang menjadi beberapa macam produk, beberapa diantaranya yaitu Self-Managed (seperti OpenShift Container Platform), hingga Managed (seperti Openshift Online dan Openshift Dedicated). OpenShift by Red Hat ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:1:0","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Katalog OKD OKD 3 by-default telah menyediakan dukungan bagi aplikasi dengan beberapa bahasa pemrograman. OKD 3 memiliki kickstart template seperti berikut : Rails untuk Ruby Django untuk Python Node.js CakePHP untuk PHP Dancer untuk Perl Maven untuk Java Sedangkan untuk basis data, OKD 3 juga telah menyediakan beberapa diantaranya : MySQL MongoDB PosgreSQL Tidak hanya itu saja, OKD 3 juga telah menawarkan fitur CI/CD Pipeline yang siap di-integrasikan dengan Jenkins, sebuah Middleware Apache, hingga Reverse-proxy NGINX. ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:1:1","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Minishift Minishift adalah sebuah tool yang membantu kita untuk menjalankan OpenShift di komputer lokal. Jika bermain dengan Kubernetes, biasanya kita akan menjumpai tool serupa bernama Minikube. Minishift akan membuat dan menjalankan sebuah VM di atas Hypervisor yang tersedia di komputer kita. Saat artikel ini diterbitkan, Minishift hanya mendukung hingga OKD versi 3.11 atau OpenShift 3. Arsitektur Minishift ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:1:2","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Prerequisites Pastikan bahwa komputer lokal kita memiliki spesifikasi yang cukup untuk memasang OKD/OpenShift. Secara default Minishift akan membuat sebuah VM dengan spesifikasi seperti berikut. Resources Value CPUs 2 core Memory 4 GB Storage 20 GB ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:2:0","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Mempersiapkan Environment Virtualiasi Minishift mendukung beberapa Hypervisor untuk membuat dan menjalankan VM. Beberapa diantaranya adalah sebagai berikut. Sistem Operasi Hypervisor Microsoft Windows Hyper-V GNU/Linux KVM MacOS hyperkit All Platform VirtualBox Karena saya menggunakan GNU/Linux, maka dalam artikel ini kita akan menggunakan KVM sebagai environment virtualiasi Minishift. Atau lebih tepatnya, saya menggunakan distro GNU/Linux Arch-based. ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:3:0","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Konfigurasi libvirt 1. Pasang paket-paket yang dibutuhkan untuk virtualisasi $ sudo pacman -Sy virt-manager kvm libvirt-runit qemu qemu-guest-agent-runit ebtables bridge-utils 2. Tambahkan user ke dalam grup kvm dan libvirt $ sudo usermod -aG kvm,libvirt $(whoami) $ newgrp libvirt $ id Jika sudah benar, seharusnya akan keluar output seperti berikut Group 3. Merubah konfigurasi qemu Ganti konfigurasi /etc/libvirt/qemu.conf agar menggunakan group kvm. $ sudo sed -ri 's/.?group\\s?=\\s?\".+\"/group = \"kvm\"/1' /etc/libvirt/qemu.conf 4. Menjalankan service libvirt $ sudo ln -s /etc/runit/sv/libvirtd /run/runit/service $ sudo ln -s /etc/runit/sv/virtlockd /run/runit/service $ sudo ln -s /etc/runit/sv/virtlogd /run/runit/service Perhatian Saya menggunakan runit sebagai sistem init di komputer lokal. Jika memakai systemd maka silahkan menggunakan perintah systemctl untuk mengelola service. 5. Menjalankan jaringan libvirt Periksa status jaringan yang tersedia saat ini. $ sudo virsh net-list --all Maka akan muncul output seperti berikut. Name State Autostart Persistent --------------------------------------------------------- default inactive no yes Artinya kita memiliki sebuah jaringan bernama default. Maka aktifkan dan buat supaya jaringan tersebut berjalan secara otomatis dengan perintah seperti berikut. $ sudo virsh net-start default $ sudo virsh net-autostart default ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:3:1","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Memasang Minishift Pasang paket-paket yang dibutuhkan. $ yay -Sy minishift docker-machine-kvm origin-client Info Pada distro Arch-based, minishift dan beberapa paket pendukung lainnya telah tersedia pada AUR (Arch User Repository). Untuk melakukan instalasi paket dari AUR, saya menggunakan AUR Helper bernama yay. ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:4:0","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Menjalankan OKD dengan Minishift Jalankan perintah seperti berikut. $ minishift start Atau kita dapat memberikan flags ketika menjalankan minishift untuk membuat VM dengan spesifikasi yang kita butuhkan. Misalnya saya ingin Minishift membuat VM dengan memory sebesar 3 GB, CPU sebanyak 1 core, dan Storage sebesar 8 GB saja. Jalankan perintah seperti berikut. $ minishift start --disk-size 8g --memory 3072 --cpus 1 Jika berhasil maka akan muncul output seperti berikut. OKD Berjalan ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:5:0","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Pengujian Minishift Periksa apakah VM benar-benar berhasil dibuat. $ sudo virsh list Akan muncul output seperti berikut jika benar. Id Name State --------------------------- 4 minishift running Memeriksa status Minishift dengan perintah berikut. $ minishift status Jika OKD berjalan maka kurang lebih akan muncul output seperti berikut. Minishift: Running Profile: minishift OpenShift: Running (openshift v3.11.0+1cd89d4-542) DiskUsage: 43% of 6.9G (Mounted On: /mnt/sda1) CacheUsage: 1.707 GB (used by oc binary, ISO or cached images) ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:5:1","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"SSH Remote Access Untuk mencoba mengakses VM Minishift melalui SSH kita dapat menjalankan perintah berikut. $ minishift ssh Remote Access Minishift ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:5:2","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Menghentikan Minishift Untuk menghentikan Minishift kita dapat menjalankan perintah berikut. $ minishift stop ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:5:3","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Menghapus Resource Minishift Jika ingin menghapus seluruh resource termasuk VM yang telah dibuat, kita dapat menjalankan perintah berikut. $ minishift delete --force ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:5:4","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Pengujian ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:6:0","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Web Console Seperti yang telah kita lihat sebelumnya. Bahwa web console telah dijalankan pada alamat https://192.168.42.192:8443/console. Sekarang buka alamat tersebut menggunakan web browser untuk memeriksa apakah web console benar-benar berjalan. Web Console OKD ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:6:1","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Command Line origin client atau oc adalah program berbasis teks yang digunakan untuk mengelola OKD (OpenShift) lewat terminal. Kita dapat melihat status OKD dengan perintah seperti berikut $ oc status Karena masih kosong, dan OKD belum kita perintah untuk menjalankan layanan apapun maka akan muncul output seperti berikut. In project My Project (myproject) on server https://192.168.42.156:8443 You have no services, deployment configs, or build configs. Run 'oc new-app' to create an application. ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:6:2","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Kesimpulan Jika dibandingkan dengan Minikube, maka seharusnya Minishift bisa dikatakan memiliki fungsi yang serupa. Sayangnya saat artikel ini dibuat Minishift hanya dapat digunakan untuk membangun OKD 3 (OpenShift 3), sedangkan untuk membangun OpenShift 4 di komputer lokal kita dapat menggunakan tool lain bernama CodeReady. Sayangnya CodeReady membutuhkan spesifikasi komputer yang cukup besar. Setelah kita perhatikan, By-default OKD yang dibangun oleh Minishift berjalan pada VM CentOS 7 Core untuk melakukan instalasi cluster. OKD adalah versi upstream dari pengembangan project OpenShift, artinya tentu saja OpenShift lebih stabil dan layak digunakan jika dibandingkan dengan OKD. Namun untuk belajar workflow dari OpenShift, OKD bisa dibilang cukup mumpuni (tentunya dengan effort yang mungkin lebih besar). ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:7:0","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Platform"],"content":"Referensi wiki.archlinux.org/index.php/OpenShift wiki.archlinux.org/index.php/Libvirt www.okd.io/#v3 docs.okd.io/3.11/architecture/index.html docs.okd.io/3.11/minishift/getting-started docs.okd.io/3.11/minishift/using/index.html www.openshift.com/blog/oc-command-newbies kubernetes.io/docs/concepts/overview/what-is-kubernetes ","date":"2021-01-05","objectID":"/instalasi-lokal-minishift-okd/:8:0","tags":["OpenShift","OKD","Minishift","PaaS"],"title":"Instalasi Lokal Minishift OKD","uri":"/instalasi-lokal-minishift-okd/"},{"categories":["Blog"],"content":"Menggunakan APEX root level domain untuk Github Pages","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"APEX Domain sering juga disebut bare domain atau Top Level Domain (TLD), merupakan domain utama tanpa imbuhan yang dapat kita pasang pada Github Pages supaya alamat situs web tidak lagi menggunakan subdomain bawaan Github. Kustomisasi domain pada Github Pages cukup mudah, dan mampu memberikan kesan profesional pada situs web. ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:0:0","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"Memilih Provider Perhatian Anggaplah kita sudah memiliki sebuah project yang di-host pada Github Pages, misalnya dalam artikel ini saya menggunakan remote repository dari blog init.web.id. Github Pages sebetulnya sudah menyediakan alamat domain bagi situs web Github Pages dengan menggunakan domain \u003cusername\u003e.github.io tanpa biaya. Namun kita juga dapat merubahnya sesuai keinginan kita, jika telah memiliki TLD sendiri. Saya memutuskan untuk menyewa domain init.web.id dan menggunakannya sebagai domain utama dari blog ini, untuk bahan belajar mencoba hal-hal baru. Domain dari DewaBiz.com Terdapat banyak sekali provider layanan sewa domain, dari yang berbayar hingga yang gratis. Karena sebelumnya saya sudah terbiasa berlangganan sewa VPS (Virtual Private Server) MikroTik CHR pada DewaBiz.com, saya ingat bahwa provider tersebut juga menyediakan jasa penyewaan domain yang dilengkapi fitur DNS Management. Saya akhirnya menggunakan jasa DewaBiz.com lagi, kali ini adalah untuk menyewa domain. ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:1:0","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"Pemesanan Domain Untuk melakukan pemesanan, kita cukup melakukan registrasi akun seperti pada umumnya. Kemudian mencari alamat domain yang ingin kita sewa, jika tersedia maka domain dapat kita pesan. Setelah melakukan pemesanan, maka lakukan pembayaran sesuai ketentuan yang berlaku pada masing-masing provider. Biasanya kita dapat melakukan transfer lewat ATM Bank, Internet Banking hingga lewat E-Wallet seperti LinkAja, GoPay, atau OVO. Jangan lupa untuk melakukan konfirmasi kepada customer service bahwa kalian telah melakukan pembayaran, dengan melampirkan bukti transaksi (biasanya berupa struk dari ATM atau screenshot jika dilakukan secara virtual) dan sebutkan juga nomor invoice dari pemesanan. Invoice Pemesanan ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:1:1","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"Konfigurasi GitHub Pages Bagian pertama yang perlu dilakukan adalah melakukan beberapa konfigurasi dari sisi Github. Berikut ini adalah beberapa hal yang perlu kita lakukan pada repository Github. ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:2:0","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"Membuat CNAME Record Untuk melakukan pointing domain, sebelumnya kita perlu membuat CNAME record di repository kita. Buat file baru dengan nama CNAME berisikan alamat custom domain yang telah kita sewa, yaitu init.web.id. $ echo \"init.web.id\" \u003e CNAME Lakukan commit dan upload perbahan tersebut ke remote repository Github. $ git add CNAME $ git commit -m \"Add CNAME record\" $ git push Sehingga direktori repository lokal kita menjadi seperti berikut. blog ├── about ├── categories ├── CNAME \u003c--------- Tambahkan file ini ├── css ├── favicon.ico ├── index.html ├── js ├── lib ├── page ├── posts ├── README.md ├── svg └── tags ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:2:1","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"Repository Settings Masuk ke halaman Settings dari repository Github kita untuk melakukan konfigurasi pada repository. Github Settings Lalu scroll ke bawah sampai bagian Github Pages, silahkan isi kolom tersebut dengan custom domain yang telah kita sewa. Github Settings Domain ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:2:2","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"DNS Management Sekarang kita menuju pada situs provider tempat kita menyewa domain (atau disebut registrar). Misalnya di sini saya menggunakan jasa dari DewaBiz.com, maka saya perlu login ke dalam member area lalu masuk ke menu DNS Management. Tambahkan beberapa record seperti berikut. DNS Management ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:3:0","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"Pengujian DNS Record Untuk melakukan pengujian, kita dapat menggunakan tools bernama dig. Jalankan perintah berikut pada terminal. $ dig init.web.id +noall +answer Jika record DNS berhasil diterapkan, maka akan muncul output seperti berikut. \u003e init.web.id 3600 IN A 185.199.108.153 \u003e init.web.id 3600 IN A 185.199.109.153 \u003e init.web.id 3600 IN A 185.199.110.153 \u003e init.web.id 3600 IN A 185.199.111.153 Perhatian Setelah melakukan semua konfigurasi di atas, pada umumnya akan membutuhkan beberapa waktu sekitar 15 menit hingga record DNS berhasil diterapkan. Jika lebih dari 15 menit tetap tidak berhasil, maka lakukan clear cache pada web browser. Namun jika tetap tidak bisa, maka ada konfigurasi yang masih belum tepat. ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:3:1","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"HTTPS Enforcement Github Pages menyediakan HTTPS gratis menggunakan Let’s Encrypt untuk meningkatkan keamanan situs web. Jika kita mengaktifkan fitur Enforce HTTPS, maka seluruh traffic akan di-rewrite menuju protokol HTTPS. ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:4:0","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"Mengaktifkan Enforce HTTPS Masuk ke Github Settings lalu centang Enforce HTTPS Enforce HTTPS Perhatian Untuk mengaktifkan Enforce HTTPS biasanya kita perlu menunggu beberapa waktu, karena Github Pages sedang melakukan tahap verifikasi dan generate sertifikat SSL. ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:4:1","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"Pengujian Enforce HTTPS Buka domain yang sudah kita pointing menggunakan web browser. Jika berhasil, maka akan muncul tampilan seperti berikut. Cek HTTPS ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:4:2","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"Kesimpulan Dengan menggunakan custom domain, maka situs web yang kita terbitkan akan terkesan lebih profesional (setidaknya ada effort lebih dalam membangunnya). Terdapat banyak provider layanan sewa domain yang ada di internet, tidak hanya DewaBiz.com, sesuaikan dengan kebutuhan kita. Selain menggunakan APEX domain / TLD, kita juga dapat menggunakan custom sub-domain seperti blog.\u003cdomain\u003e.com dengan konfigurasi yang relatif sama saja seperti di atas. ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:5:0","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"Referensi docs.github.com/en/free-pro-team@latest/github/working-with-github-pages/configuring-a-custom-domain-for-your-github-pages-site wiki.archlinux.org/index.php/Domain_name_resolution#Lookup_utilities ","date":"2021-01-01","objectID":"/custom-apex-domain-untuk-github-pages/:6:0","tags":["Domain","DNS","Github","Review"],"title":"Custom APEX Domain untuk Github Pages","uri":"/custom-apex-domain-untuk-github-pages/"},{"categories":["Blog"],"content":"Implementasi CI-CD Static Site Hugo dengan Github Actions.","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Hugo adalah static site generator untuk membangun situs web statis yang database-free. Karena Hugo berjalan tanpa koneksi basis data, maka dapat digunakanlah Github Pages sebagai hosting. Dalam meningkatkan efisiensi operasionalnya, Github Actions akan menjadi solusi continuous deployment. ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:0:0","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Remote Repository Anggap kita sudah memiliki sebuah project situs website Hugo bernama example dengan struktur direktori seperti di bawah. Lalu kita anggap bahwa project kita telah terintegrasi dengan remote repository di Github. example ├── archetypes │ └── default.md ├── config.toml ├── content │ └── posts ├── data ├── layouts ├── resources │ └── _gen │ ├── assets │ └── images ├── static └── themes └── hugo-theme-nix ├── archetypes │ └── default.md ├── exampleSite │ ├── config.toml │ ├── content │ │ ├── about.md │ │ └── post │ │ ├── creating-a-new-theme.md │ │ ├── goisforlovers.md │ │ ├── hugoisforlovers.md │ │ └── migrate-from-jekyll.md │ └── static │ ├── favicon.ico │ └── profile.jpg ├── i18n │ ├── en.yaml │ └── es.yaml ├── images │ ├── about.png │ ├── index.png │ ├── posts.png │ ├── screenshot.png │ └── tn.png ├── layouts │ ├── 404.html │ ├── _default │ │ ├── list.html │ │ └── single.html │ ├── index.html │ └── partials │ ├── footer.html │ ├── head-custom.html │ ├── header.html │ ├── head.html │ ├── pagination.html │ └── social.html ├── LICENSE.md ├── README.md ├── static │ └── css │ └── nix.css └── theme.toml Perhatian Artikel ini tidak membahas bagaimana caranya membuat sebuah situs Hugo. Silahkan membaca dokumentasi tentang Hugo yang lebih lengkap di Hugo Documentation. Project dalam repository lokal perlu diintegrasikan dengan remote repository di Github. Remote Repository example Jika belum maka silahkan menjalankan perintah berikut untuk melakukan inisialisasi repository. $ git init Kemudian silahkan login akun Github dan membuat sebuah repository baru, misalnya dengan nama example. Jika sudah, kembali ke terminal dan tambahkan remote repository baru dari Github dengan perintah berikut. $ git remote add origin git@github.com:\u003cusername-github\u003e/example.git ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:1:0","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Github Pages Kita perlu membuat remote repository lain di Github, misalnya dengan nama blog-public. Nantinya repository baru tersebut akan menampung file-file hasil generate Hugo secara otomatis dari repository example. Remote Repository blog-public Kemudian masuk ke Settings pada repository tersebut, dan aktifkan Source master pada bagian GitHub Pages Github Pages pada Repository blog-public ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:2:0","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Workflows Kembali ke terminal, buat sebuah direktori baru di project kita dengan nama .github lalu di dalamnya buat lagi sebuah direktori bernama workflows $ mkdir -p .github/workflows Jika sudah, di dalamnya kita buat sebuah file, misalnya bernama pages.yml dan di dalam file tersebut akan kita gunakan sebagai konfigurasi runner dari Github Actions. name: blog-publish on: push: branches: - master jobs: deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: submodules: false - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 'latest' extended: true - name: Build run: hugo --minify --environment production - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: external_repository: \u003cusername-github\u003e/blog-public publish_branch: master publish_dir: ./public deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEYS }} allow_empty_commit: false commit_message: ${{ github.event.head_commit.message }} ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:3:0","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Generate SSH Keys SSH Keys diperlukan untuk memberikan akses kepada Github Actions dalam memodifikasi repository external. $ ssh-keygen -t rsa -b 4096 -C \"\u003cemail-github@kalian.com\u003e\" -f master Nantinya akan ter-generate 2 file yaitu File master adalah private key File master.pub adalah public key ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:3:1","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Deploy Keys Salin public keys master.pub ke dalam clipboard dengan perintah seperti berikut $ xclip -selection clipboard \u003c master.pub Silahkan buka halaman Settings pada repository blog-public, lalu pilih Deploy keys. Tambahkan public keys dengan nama ACTIONS_DEPLOY_KEYS. Deploy keys di Repository blog-public ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:3:2","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Secrets Salin private keys master ke dalam clipboard dengan perintah seperti berikut $ xclip -selection clipboard \u003c master Buka halaman Settings pada repository example, lalu pilih Secrets. Tambahkan secret baru dengan nama ACTIONS_DEPLOY_KEYS, berisi private key yang baru saja kita salin. Secrets di Repository example ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:3:3","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Pengujian Semua perubahan telah dilakukan pada direktori project Hugo example, sekarang kita akan melakukan pengujian apakah dengan melakukan push ke remote repository akan memberikan efek ke repository blog-public. ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:4:0","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Tambahkan perubahan ke staging Tambahkan seluruh file yang sudah ada di repository lokal menjadi berstatus staging. $ git add . ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:4:1","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Commit Sebelum melakukan commit biasanya kita perlu melakukan konfigurasi username dan email akun Github kalian. $ git config user.name \"\u003cusername-github\u003e\" $ git config user.email \"\u003cemail-github@kalian.com\u003e\" Lalu commit semua file yang berada di dalam mode staging dengan perinah berikut. $ git commit -m \"Commit Pertama Kali\" ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:4:2","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Push ke remote repository Jika sudah lakukan lakukan push ke remote repository Github. $ git push --set-upstream origin master Perhatian Untuk autentikasi git saat ingin melakukan push dengan SSH silahkan baca dokumentasi Github. Jika berhasil, maka seharusnya proses deployment melalui Github Actions akan langsung berjalan seperti berikut. Deployment ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:4:3","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Hasil Berikut ini adalah hasil setelah melakukan push dan proses deployment pada Github Actions berjalan. Hasil pada Repository blog-public Terlihat bahwa Github Actions berhasil menjalankan push secara otomatis ke repository eksternal blog-public. Dan hasil build Hugo dapat kita buka pada Github Pages dengan URL berikut. https://\u003cusername-github\u003e.github.io/blog-public Hasil Build ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:5:0","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Kesimpulan Dengan penerapan CI/CD memakai Github Actions, proses penyuntingan dan berbagai hal operasional lain menjadi dipangkas. Tentu berkat implementasi konsep automation semua menjadi lebih efisien. Beberapa keuntungan yang kita peroleh adalah sebagai berikut. Tidak perlu melakukan build secara manual. Repository utama (example) dapat kita jadikan private repository. Aktivitas push hasil build Hugo dilakukan secara otomatis, tiap kali ada perubahan. ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:6:0","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["Blog"],"content":"Referensi gohugo.io/documentation docs.github.com/en/free-pro-team@latest/actions github.com/marketplace/actions/github-pages-action ","date":"2020-12-19","objectID":"/continuous-deployment-hugo-dengan-github-actions/:7:0","tags":["Hugo","Github","CI-CD","Automation","Review"],"title":"Continuous Deployment Hugo dengan Github Actions","uri":"/continuous-deployment-hugo-dengan-github-actions/"},{"categories":["GNU/Linux"],"content":"Beralih menggunakan runit - sebuah UNIX init scheme dengan service supervision.","date":"2020-12-16","objectID":"/beralih-ke-runit/","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"Runit merupakan sebuah UNIX init scheme dengan service supervision. Pada dasarnya hal ini berarti Runit mampu menyediakan automatic starting sebuah services ketika sistem operasi dijalankan untuk pertamakali, serta automatic monitoring and restarting sebuah service jika terjadi sebuah interupsi. ","date":"2020-12-16","objectID":"/beralih-ke-runit/:0:0","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"Systemd vs Runit Ketika artikel ini diterbitkan, systemd nyaris menguasai semua distro sistem operasi GNU/Linux. Misalnya Fedora, Debian, Ubuntu, dan banyak lagi lainnya sudah beralih dari init system sebelumnya lalu menggunakan systemd. Hal ini terjadi karena systemd menawarkan banyak hal yang terintegrasi, hampir segala hal pada sistem operasi akan di-handle olehnya. Systemd and GNU/Linux ","date":"2020-12-16","objectID":"/beralih-ke-runit/:1:0","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"Kontroversi systemd systemd memang menjadi kontroversi karena beberapa hal. Sebagian orang menganggap bahwa systemd tidak menghormati filosofi Unix. Saya ingat ketika awal sekali mengenal GNU/Linux, bahwa GNU/Linux adalah sistem operasi yang Unix-like dan Unix memiliki filosofi sebagai berikut : Tugas sebuah program adalah melakukan satu hal, dan melakukannya dengan baik. Sistem yang besar dan kompleks merupakan gabungan dari program-program kecil yang bekerja sama. Teks adalah antarmuka yang universal. Segala hal di Unix adalah file. systemd dianggap tidak conform dengan filosofi Unix diatas sehingga banyak yang menolaknya. systemd awalnya dikembangkan oleh Lennart Pottering, seorang developer yang saat artikel ini diterbitkan tengah bekerja untuk Red Hat. Dia sebelumnya juga membuat program yang tak kalah kontroversial yaitu Avahi dan PulseAudio. Silahkan baca tentang Lennart Pottering di Wikipedia. Beberapa kritik lain terhadap systemd misalnya karena systemd tidak hanya menjadi init system tapi juga mengambil ali banyak fungsi. Misalnya systemd berusaha mengatur network, cron, fstab, syslog atau rsyslog, ntp, dan banyak lainnya. Artinya systemd bukanlah sebuah program yang melakukan satu hal saja, tapi banyak hal. Kemudian, systemd dikritik karena logging file-nya tidak berbasis teks seperti Unix dan GNU/Linux pada umumnya, melainkan binary log file. ","date":"2020-12-16","objectID":"/beralih-ke-runit/:1:1","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"Runit Sebagai Alternatif Berbagai penolakan tentu saja terjadi, tidak sedikit developer yang kemudian melakukan fork lalu mengembangkan distro GNU/Linux yang bebas dari systemd. Misalnya Artix Linux, yang merupakan fork dari project Arch Linux dengan maksud membebaskan pengguna Arch dari cengkeraman systemd. Artix menawarkan beberapa alternatif sebagai pengganti systemd, misalnya OpenRC, S6, dan tentu saja Runit. /etc/runit/sv/foo ├── log │ ├── run │ └── supervise │ ├── control │ ├── lock │ ├── ok │ ├── pid │ ├── stat │ └── status ├── run └── supervise ├── control ├── lock ├── ok ├── pid ├── stat └── status Pada distro Artix, biasanya direktori sebuah service akan terlihat seperti di atas. Anggaplah /etc/runit/sv adalah templatedir, dan /etc/runit/sv/foo adalah direktori konfigurasi service. Maka kelak service yang berjalan akan bernama sebagai foo juga. Dalam direktori foo biasanya kita hanya diwajibkan untuk membuat sebuah file executable bernama run, berisikan baris perintah untuk mengeksekusi program yang akan dijadikan sebagai sebuah service. Namun jika kita membutuhkan logging, kita dapat memanfaatkan svlogd dengan membuat sebuah direktori bernama log di dalam /etc/runit/sv/foo, kemudian buat lagi sebuah file bernama run di dalam direktori log tersebut. Isi dari file-file run tersebut akan kita bahas dibawah. ","date":"2020-12-16","objectID":"/beralih-ke-runit/:1:2","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"Beralih ke Runit Dalam dokumentasi ini kita akan belajar tentang : Membuat sebuah runit template untuk untuk konfigurasi monitored service. Konfigurasi monitored service untuk pertamakali. Mengelola monitored service secara manual. runit sv ","date":"2020-12-16","objectID":"/beralih-ke-runit/:2:0","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"0. Prerequisites Pastikan paket dari runit sudah terpasang pada sistem. Sebagian besar distro GNU/Linux biasanya memiliki paket tersebut pada repository mereka. Misalnya, jika kita menggunakan sebuah distro Arch-based maka kita dapat memasang paket dengan perintah berikut. $ sudo pacman -Sy runit Perhatian Pada distro Artix biasanya kita tidak perlu melakukan pemasangan paket Runit. Kita diperkenankan memilih init system apa yang akan digunakan pada waktu mengunduh berkas ISO installer. Periksa apakah runit telah terpasang pada sistem, dengan mencari sebuah process bernama runsvdir dengan perintah. $ sudo ps -ef | grep runsvdir Jika runit telah terpasang, harusnya akan keluar output seperti berikut. root 1090 1 0 Dec15 ? 00:00:00 runsvdir -P /run/runit/service log:.............. Di sini runsvdir merupakan hal paling pertama dari beberapa lainnya yang akan kita pahami. runit memang diarancang untuk mengambil pendekatan yang terasa sangat Unixy, yaitu dengan cara memecah fungsionalitas utama menjadi beberapa utilities kecil yang masing-masing unitnya bertanggung jawab menjalankan sebuah tugas. Pendekatan tersebut membuat komponen-komponen kecilnya mampu dibentuk dengan beberapa metode sesuai dengan yang kita butuhkan. Core unit yang terdapat pada runit beberapa diantaranya adalah runsvdir, runsv, chpst, svlogd, dan sv. Nantinya, dalam dokumentasi ini kita akan mengkombinasikan beberapa hal diatas untuk kofigurasi runit dan menjalankan sebuah managed service. ","date":"2020-12-16","objectID":"/beralih-ke-runit/:2:1","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"1. Membuat sebuah Template Hal pertama yang perlu kita lakukan adalah memperhatikan lebih dalam apa yang sebenarnya terjadi pada output runsvdir -P /run/runit/service log:...... Pada dasarnya, dalam output tersebut terdapat sebuah perintah yang mengawasi direktori /run/runit/service, karena di dalamnya terdapat file konfigurasi dari monitored service. Sebuah monitored service dikonfigurasi dengan menambahkan sebuah subdirektori ke dalam /run/runit/service berisikan sebuah berkas script run di dalamnya. Ketika runsvdir menemukan sebuah konfigurasi baru, maka ia akan menjalankan process runsvbaru untuk mengelola service. Ingat, bahwa salah satu Filosofi Unix berbunyi tugas sebuah program adalah melakukan satu hal, dan melakukannya dengan baik. Pastikan bahwa direktori /etc/runit/sv/ ada. Di dalamnya kita akan membuat direktori baru bernama foo. $ sudo mkdir -p /etc/runit/sv/foo Lalu di dalam direktori tersebut kita buat sebuah file template bernama run untuk ilustrasi. #!/bin/sh exec 2\u003e\u00261 exec chpst -u foo /opt/example/foo-service.sh Jangan lupa file run harus menjadi executable dengan cara berikut. $ sudo chmod +x /etc/runit/sv/foo/run Script run di atas akan mengeksekusi script foo-service.sh yang nantinya akan kita buat di dalam direktori /opt/example. Terdapat juga chpst yang berfungsi agar nantinya eksekusi akan dijalankan oleh user bernama foo, kita akan buat juga usernya nanti. Runit menawarkan svlogd untuk mengelola logfile dari sebuah service, kita akan mencoba membuatnya juga. Mari buat direktori baru bernama log. $ sudo mkdir /etc/runit/sv/foo/log Di dalam direktori tersebut, kita akan membuat file baru lagi bernama run berisikan script berikut. #!/bin/sh exec chpst -u foo svlogd -tt /var/log/foo Pada script diatas svlogd akan menghasilkan output dari template yang sebelumnya kita buat. Output yang muncul akan ditampung pada direktori /var/log/foo yang kita buat nanti. ","date":"2020-12-16","objectID":"/beralih-ke-runit/:2:2","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"2. Menyiapkan Logging Directory Buat sebuah direktori untuk menampung log dari service. $ sudo mkdir -p /var/log/foo Lalu kita membutuhkan user baru bernama foo sebagai ilustrasi. $ sudo useradd foo Direktori log seharusnya menjadi milik user foo supaya user tersebut mampu menulis di dalamnya, sehingga kita perlu merubah kepemilikannya dengan perintah berikut. $ sudo chown foo:foo /var/log/foo ","date":"2020-12-16","objectID":"/beralih-ke-runit/:2:3","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"3. Membuat Program Ilustrasi Buat sebuah direktori baru untuk meletakkan file program ilustrasi. $ sudo mkdir -p /opt/example Dari sini kita akan melanjutkan dengan membuat program sebagai ilustrasi bernama foo-service.sh yang terletak pada direktori /opt/example. #!/bin/bash echo \"Menjalankan service...\" for i in {1..30} do echo \"Melakukan sesuatu...\" sleep 1 done echo \"Oh tidak, program crash!\" \u003e\u00262 exit 1 Jangan lupa untuk menjadikan file tersebut executable seperti berikut. $ sudo chmod +x /opt/example/foo-script.sh Kemudian jadikan direktori serta file di dalamnya menjadi milik user foo. $ sudo chown -R foo:foo /opt/example Program foo-script.sh akan mensimulasikan sebuah process yang dieksekusi menggunakan runit sesuai dengan template yang sebelumnya telah kita buat. foo-script.sh akan crash setiap 30 detik, dan setiap output nya akan dicatat ke dalam log. ","date":"2020-12-16","objectID":"/beralih-ke-runit/:2:4","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"4. Mengelola Service Kita tiba pada tahap menggunakan sv untuk pengelolaan service dari ilustrasi yang telah kita buat sebelumnya. Untuk menjalankan service kita perlu melakukan symlink direktori template ke dalam direktori runsvdir. Enable service $ sudo ln -s /etc/runit/sv/foo /run/runit/service Ketika melakukan perintah ln -s diatas, direktori template dari service tersebut (/etc/runit/sv/foo) akan dijadikan sebagai titik link yang ditambahkan ke dalam direktori runsvdir pada /run/runit/service. Lalu runsvdir terus melakukan pengawasan pada service yang baru saja kita tambahkan. Sehingga pada saat process terinterupsi (misalnya oleh reboot atau kill) maka service tersebut akan kembali dinyalakan secara otomatis. Itulah yang dimaksud dengan supervision di dalam sebuah sistem init. Memeriksa status service Kemudian lakukan pemeriksaan, apakah service berhasil dijalankan. $ sudo sv status /run/runit/service/foo Jika berhasil, seharusnya akan keluar output seperti berikut. run: foo: (pid 16998) 3s; run: log: (pid 16997) 3s Menghentikan service Coba hentikan service dengan perintah berikut. $ sudo sv down /run/runit/service/foo Jika berhasil dihentikan, maka akan keluar output seperti berikut. ok: down: example: 1s, normally up Menyalakan service Nyalakan lagi kemudian periksa lagi statusnya dengan perintah seperti berikut ini. $ sudo sv up /run/runit/service/foo $ sudo sv status /run/runit/service/foo Jika berhasil berjalan, maka akan muncul output sebagai berikut. run: foo: (pid 18146) 16s; run: log: (pid 16997) 250s Melihat logfile Sekarang kita akan coba melihat apakah logging berhasil dilakukan. $ sudo tail -f /var/log/foo/current svlogd akan membuat sebuah file baru bernama current dalam direktori log yang sudah kita siapkan. Nantinya file tersebut akan menampung tiap output dari service yang sedang berjalan. Apabila berhasil, seharusnya akan muncul output seperti berikut. 2020-12-16_17:38:43.31313 Melakukan sesuatu... 2020-12-16_17:38:44.31422 Melakukan sesuatu... 2020-12-16_17:38:45.31513 Melakukan sesuatu... 2020-12-16_17:39:13.34046 Oh tidak, program crash! 2020-12-16_17:39:13.34372 Menjalankan service... 2020-12-16_17:39:13.34375 Melakukan sesuatu... 2020-12-16_17:39:14.34453 Melakukan sesuatu... 2020-12-16_17:39:15.34541 Melakukan sesuatu... Terlihat seperti diatas, bahwa program foo-script.sh berhasil dijalankan, berhenti setiap 30 detik, kemudian runit akan berusaha menyalakannya lagi. Tidak terbatas seperti tail -f saja, namun svlogd mampu melakukan log rotation otomatis layaknya logrotate, bahkan svlogd mampu melakukannya tanpa perlu mematikan service terlebih dahulu. Disable service Untuk menghilangkan sebuah service dari runsvdir kita perlu menghapus symlink yang sebelumnya kita buat. $ sudo unlink /run/runit/service/example Setelah dihapus, maka service akan berhenti seketika dan tidak akan dimuat ketika sistem operasi booting. ","date":"2020-12-16","objectID":"/beralih-ke-runit/:2:5","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"Perbandingan Perintah Runit vs Systemd Systemd memang memiliki lebih banyak perintah daripada Runit, namun jika dibandingkan maka berikut ini adalah beberapa perintah yang umum digunakan dalam mengelola service dari kedua init system tersebut. Usage Systemd Runit Menjalankan service systemctl start \u003cservice\u003e sv up \u003cservice\u003e Mematikan service systemctl stop \u003cservice\u003e sv down \u003cservice\u003e Menyalakan ulang service systemctl restart \u003cservice\u003e sv restart \u003cservice\u003e Enable service at boot systemctl enable \u003cservice\u003e ln -s /etc/runit/sv/\u003ctemplate dir\u003e /run/runit/\u003crunsvdir\u003e Disable service from boot systemctl disable \u003cservice\u003e unlink /run/runit/\u003crunsvdir\u003e/\u003cservice\u003e ","date":"2020-12-16","objectID":"/beralih-ke-runit/:3:0","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"Manakah yang lebih baik? Dalam pekerjaan, systemd tetap digunakan pada server-server customer yang saya jumpai. Tidak ada masalah bagi saya, karena itulah prosedur yang diterapkan di perusahaan-perusaahan tersebut. Tentu sebuah server yang berada dalam skala production membutuhkan stabilitas tinggi, nyaris semua yang saya kelola menggunakan berbagai platform dari Red Hat. Dan RHEL (Red Hat Enterprise Linux) sendiri adalah salah satu distro GNU/Linux yang paling bergantung pada systemd. Saya mengakui bahwa systemd adalah sistem yang modern. Yang menurut saya kurang adalah sistem logging dengan journald, file log yang dihasilkan bukanlah textfile. Sebelumnya, dengan rsyslog kita bebas memakai beragam tool seperti cat, grep, tail, atau head. Tetapi dengan journald kita dibatasi hanya bisa menggunakan satu tool yaitu journalctl. Untuk pemakaian di komputer pribadi, tentu saja saya lebih prefer menggunakan Runit. Bukan tanpa alasan, runit mengkonsumsi resouce (seperti RAM dan CPU) yang relatif lebih sedikit daripada systemd. Dependency yang digunakan oleh runit juga tidak sebanyak systemd, berarti runit juga lebih ramah dalam urusan penggunaan storage. Untuk kecepatan, saya berani mengadu kecepatan antara runit melawan systemd, karena telah memiliki pengalaman pribadi bahwa runit menang telak! Runit membuat sistem operasi saya booting lebih cepat daripada systemd. Terlepas dari semua itu, saya juga belum membutuhkan systemd dengan segala bloated features nya untuk urusan pribadi (itu terlalu berlebihan, saya bahkan tidak pernah menggunakan itu semua secara keseluruhan), yang saya perlukan pada komputer pribadi adalah program dapat berjalan sesuai dengan yang saya kehendaki. Sehingga saya menyimpulkan bahwa runit layak dijadikan sebagai alternatif. ","date":"2020-12-16","objectID":"/beralih-ke-runit/:4:0","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"Referensi smarden.org/runit devnull.web.id/debian/pengenalan-systemd.html kchard.github.io/runit-quickstart ihatesystemd.com wiki.gentoo.org/wiki/Comparison_of_init_systems wiki.archlinux.org/index.php/init ","date":"2020-12-16","objectID":"/beralih-ke-runit/:5:0","tags":["Environment","Review"],"title":"Beralih ke Runit","uri":"/beralih-ke-runit/"},{"categories":["GNU/Linux"],"content":"Berbicara sedikit tentang GNU/Linux Ricing - Kebebasan dalam membangun environment desktop ramah sumberdaya dan sesuai kebutuhan","date":"2020-12-14","objectID":"/membahas-linux-ricing/","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Istilah rice/ricing pasti tidak asing lagi bagi orang yang suka mengkustomisasi desktop sistem operasi Unix-like, khususnya pada GNU/Linux yang aktivitasnya biasa disebut “Ricing / Linux Rice”. Mereka gemar berdiskusi di komunitas reddit dan grup Linuxer Desktop Art di Facebook, serta grup Dotfiles Indonesia di Telegram untuk sharing atau hanya sekedar melihat-lihat indahnya sistem operasi unix-like. Arch-Chan ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:0:0","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Pengenalan “Linux Rice” Pertama-tama saya akan sedikit menjelaskan mengenai apa yang disebut “Linux Rice”. Linux Rice berasal dari 2 kata “Linux” yaitu sistem operasi GNU/Linux itu sendiri dan “Rice” yaitu beras. Bukan! yang dimaksud “Rice” disini bukanlah beras yang biasa kita makan, tapi akronim dari “Race Inspired Cosmetic Enhancements”. Race Inspired Cosmetic Enhancements. (R.I.C.E.) adalah istilah yang merujuk pada mobil sport buatan Asia (biasanya Honda Civic) yang memiliki banyak modifikasi kosmetik dan sedikit atau tanpa modifikasi internal. Intinya disini kata “Rice” awalnya digunakan untuk modifikasi pada mobil. Race Inspired Cosmetic Enhancements (R.I.C.E.) Apa hubungannya modifikasi mobil dengan sistem operasi GNU/Linux? Dari sini jelas bahwa kata “Rice” artinya modifikasi, kemudian istilah tersebut diserap oleh mereka yang gemar memodifikasi tampilan desktop di sistem operasi GNU/Linux menjadi “Ricing”. ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:1:0","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Komponen dasar dalam Ricing Ada banyak sekali cara untuk mengkustomisasi desktop di sistem operasi GNU/Linux. Dimulai dari pengenalan sebuah Window Manager atau disingkat WM. ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:2:0","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Window Manager Window Manager adalah sistem perangkat lunak yang mengontrol tata letak dan tampilan window dalam sistem windowing yang merupakan salah satu dari komponen Desktop Environment pada GUI. WM sendiri dibagi menjadi 3 jenis. Stacking adalah Window Manager yang sistem window-nya bertumpuk antara satu dengan yang lain. Kita biasa merasakan workflow WM jenis ini misalnya pada DE GNOME3 yang menggunakan Mutter dan KDE yang menggunakan Kwin. Namun tidak semua WM dapat berdiri sendiri (standalone) contoh yang WM yang dapat berdiri sendiri dengan mudahnya adalah openbox, fluxbox, hingga xfwm pada DE XFCE. Tiling adalah Window Manager yang sistem window-nya tersusun kotak-kotak antara satu dengan lainnya secara otomatis meskipun masih terdapat sistem floating/stacking, disebut tiling karena memiliki workflow seperti susunan ubin. Contohnya i3wm, dan bspwm. Dynamic. Seperti pada namanya, jenis Window Manager ini dapat berganti-ganti diantara Stacking maupun Tiling sesuai selera pengguna. Contohnya dwm dan awesomewm. ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:2:1","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Panel / Bar / Dock Panel / Bar / Dock adalah program yang digunakan untuk menampilkan informasi baterai, daftar aplikasi yang dibuka, system tray, dan waktu. Jika pada sistem operasi Micros*ft Wind*ws, kita biasa menyebutnya Taskbar. Di GNU/Linux contohnya adalah plank, tint2, polybar, dzen2, dan lemonbar. ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:2:2","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Application Launcher Application Launcher adalah program yang digunakan untuk membuka atau menjalankan suatu program selain menggunakan Terminal Emulator. Contohnya adalah dmenu lalu ada penggantinya yang lebih menawarkan banyak fitur, yaitu rofi. ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:2:3","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Notification Daemon Notification Daemon (lebih suka saya sebut sebagai Notify Daemon) adalah program yang digunakan sebagai penampil notifikasi. Contohnya adalah dunst, xfce4-notifyd milik XFCE, dll. ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:2:4","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Terminal Emulator Terminal Emulator adalah program yang digunakan untuk berinteraksi dengan sesi Unix Shell seperti mengatur sistem, hingga menjalankan program, dengan mengetikkan perintah berbasis teks (CLI). TE merupakan komponen terpenting digunakan untuk Ricing. Contoh Terminal Emulator ada banyak sekali, misalnya rxvt-unicode (urxvt), xfce4-terminal pada XFCE, termite, simple terminal (st), kitty, dan masih banyak lagi. ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:2:5","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Display Manager (Optional) Display Manager atau DM adalah program yang digunakan untuk masuk ke sesi GUI bagi sistem operasi GNU/Linux. Setelah masuk ke DM, kendali sepenuhnya diberikan kepada WM. DM menyediakan fitur seperti memilih sesi DE/WM yang akan digunakan, serta terdapat juga fitur reboot, halt, dan suspend. Meski sering digunakan karena kemudahannya bagi pengguna, tetapi tidak sedikit pula orang yang menggunakan sistem operasi GNU/Linux tanpa DM. Biasanya mereka menggunakan startx langsung (xorg-xinit). Contoh DM adalah lightdm, gdm milik GNOME, dan slim. ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:2:6","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Window Compositor (Optional) Compositor adalah program yang berfungsi untuk mengatur animasi seperti bayangan dan tranparansi pada WM. Contohnya adalah compton, lalu penerusnya yaitu picom. ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:2:7","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Alasan memilih WM daripada DE Dari semua penjelasan diatas, mengapa saya lebih memilih WM dengan custom environment, daripada DE yang sudah lengkap (instant) tinggal digunakan? Seringkali banyak yang bilang Ribet sekali jadi orang! Ada beberapa alasan mengapa menggunakan WM lebih baik daripada menggunakan DE (menurut saya). Ingin belajar lebih dalam mengenai workflow desktop pada sistem operasi GNU/Linux. Mengetahui bahwa GUI pada sistem operasi GNU/Linux dapat diminimalisir komponen-komponen penyusunnya (dependencies), karena banyak sekali komponen yang tidak pernah saya perlukan pada DE namun sudah pre-installed. Dengan alasan nomor 2 jelas sekali bahwa WM akan sangat ringan dan tidak menyita banyak resources seperti RAM dan processor. Kebebasan memilih komponen penyusun desktop seperti yang saya sudah jelaskan di atas. System Monitoring ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:3:0","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Apa yang saya gunakan? Karena saya masih terbiasa dengan WM jenis stacking yang terkesan normal, serta dikarenakan resolusi layar minim (1600 x 900). Berbeda dengan WM tiling yang lebih dioptimalkan untuk developer dengan layar lebarnya. Saya memutuskan memilih openbox dengan segala kesederhanaanya serta dukungan yang luas. ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:4:0","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Penutup Cukup rumit dan membingungkan bukan? Bagi pemula biasanya akan lebih mudah untuk memulai dari menggunakan dotfiles milik orang lain. Dengan begitu kita tidak terlalu banyak melakukan konfigurasi dari dasar, dan tidak perlu membuat theme, icon hingga artwork sendiri. Setelah merasa cukup familiar dengan environment tersebut barulah mencoba membangun environment kalian sendiri. Jika sudah merasa mampu menyusun dokumentasi environment dengan baik, maka lanjutkan belajar membuat dotfiles sendiri. Selama proses belajar, tak perlu malu untuk berbagi screenshot ke komunitas seperti Linuxer Desktop Art, atau Dotfiles Indonesia untuk meminta pendapat dari sesama pegiat Desktop Ricing. ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:5:0","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["GNU/Linux"],"content":"Referensi 0xlt.me dwarmstrong.org/openbox devpy.me/your-guide-to-a-comfortable-linux-desktop-with-openbox openbox.org addy-dclxvi.github.io bandithijo.github.io wiki.archlinux.org/Desktop_environment Linuxer Desktop Art Dotfiles Indonesia ","date":"2020-12-14","objectID":"/membahas-linux-ricing/:6:0","tags":["Customization","Tweaks","Environment"],"title":"Membahas Linux Ricing","uri":"/membahas-linux-ricing/"},{"categories":["Blog"],"content":"This article shows the basic Markdown syntax and format.","date":"2020-12-12","objectID":"/basic-markdown-syntax/","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"This initial article offers a sample of basic Markdown syntax that can be used in Hugo content files. In the future, this article will be the basic guide in writing the other posts on this blog. Note This article is a shameful copy of the great Grav original page. Let’s face it: Writing content for the Web is tiresome. WYSIWYG editors help alleviate this task, but they generally result in horrible code, or worse yet, ugly web pages. Markdown is a better way to write HTML, without all the complexities and ugliness that usually accompanies it. Some of the key benefits are: Markdown is simple to learn, with minimal extra characters, so it’s also quicker to write content. Less chance of errors when writing in Markdown. Produces valid XHTML output. Keeps the content and the visual display separate, so you cannot mess up the look of your site. Write in any text editor or Markdown application you like. Markdown is a joy to use! John Gruber, the author of Markdown, puts it like this: The overriding design goal for Markdown’s formatting syntax is to make it as readable as possible. The idea is that a Markdown-formatted document should be publishable as-is, as plain text, without looking like it’s been marked up with tags or formatting instructions. While Markdown’s syntax has been influenced by several existing text-to-HTML filters, the single biggest source of inspiration for Markdown’s syntax is the format of plain text email. – John Gruber Without further delay, let us go over the main elements of Markdown and what the resulting HTML looks like! Tip  Bookmark this page for easy future reference! ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:0:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"1 Headings Headings from h2 through h6 are constructed with a # for each level: ## h2 Heading ### h3 Heading #### h4 Heading ##### h5 Heading ###### h6 Heading The HTML looks like this: \u003ch2\u003eh2 Heading\u003c/h2\u003e \u003ch3\u003eh3 Heading\u003c/h3\u003e \u003ch4\u003eh4 Heading\u003c/h4\u003e \u003ch5\u003eh5 Heading\u003c/h5\u003e \u003ch6\u003eh6 Heading\u003c/h6\u003e Heading IDs To add a custom heading ID, enclose the custom ID in curly braces on the same line as the heading: ### A Great Heading {#custom-id} The HTML looks like this: \u003ch3 id=\"custom-id\"\u003eA Great Heading\u003c/h3\u003e ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:1:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"2 Comments Comments should be HTML compatible. \u003c!-- This is a comment --\u003e Comment below should NOT be seen: ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:2:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"3 Horizontal Rules The HTML \u003chr\u003e element is for creating a “thematic break” between paragraph-level elements. In Markdown, you can create a \u003chr\u003e with any of the following: ___: three consecutive underscores ---: three consecutive dashes ***: three consecutive asterisks The rendered output looks like this: ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:3:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"4 Body Copy Body copy written as normal, plain text will be wrapped with \u003cp\u003e\u003c/p\u003e tags in the rendered HTML. So this body copy: Lorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad. The HTML looks like this: \u003cp\u003eLorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad.\u003c/p\u003e A line break can be done with one blank line. ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:4:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"5 Inline HTML If you need a certain HTML tag (with a class) you can simply use HTML: Paragraph in Markdown. \u003cdiv class=\"class\"\u003e This is \u003cb\u003eHTML\u003c/b\u003e \u003c/div\u003e Paragraph in Markdown. ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:5:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"6 Emphasis ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:6:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Bold For emphasizing a snippet of text with a heavier font-weight. The following snippet of text is rendered as bold text. **rendered as bold text** __rendered as bold text__ The HTML looks like this: \u003cstrong\u003erendered as bold text\u003c/strong\u003e ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:6:1","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Italics For emphasizing a snippet of text with italics. The following snippet of text is rendered as italicized text. *rendered as italicized text* _rendered as italicized text_ The HTML looks like this: \u003cem\u003erendered as italicized text\u003c/em\u003e ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:6:2","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Strikethrough In GFMGitHub flavored Markdown you can do strikethroughs. ~~Strike through this text.~~ The rendered output looks like this: Strike through this text. The HTML looks like this: \u003cdel\u003eStrike through this text.\u003c/del\u003e ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:6:3","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Combination Bold, italics, and strikethrough can be used in combination. ***bold and italics*** ~~**strikethrough and bold**~~ ~~*strikethrough and italics*~~ ~~***bold, italics and strikethrough***~~ The rendered output looks like this: bold and italics strikethrough and bold strikethrough and italics bold, italics and strikethrough The HTML looks like this: \u003cem\u003e\u003cstrong\u003ebold and italics\u003c/strong\u003e\u003c/em\u003e \u003cdel\u003e\u003cstrong\u003estrikethrough and bold\u003c/strong\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003estrikethrough and italics\u003c/em\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e\u003cstrong\u003ebold, italics and strikethrough\u003c/strong\u003e\u003c/em\u003e\u003c/del\u003e ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:6:4","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"7 Blockquotes For quoting blocks of content from another source within your document. Add \u003e before any text you want to quote: \u003e **Fusion Drive** combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. The rendered output looks like this: Fusion Drive combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. The HTML looks like this: \u003cblockquote\u003e \u003cp\u003e \u003cstrong\u003eFusion Drive\u003c/strong\u003e combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. \u003c/p\u003e \u003c/blockquote\u003e Blockquotes can also be nested: \u003e Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. \u003e\u003e Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. The rendered output looks like this: Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:7:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"8 Lists ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:8:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Unordered A list of items in which the order of the items does not explicitly matter. You may use any of the following symbols to denote bullets for each list item: * valid bullet - valid bullet + valid bullet For example: * Lorem ipsum dolor sit amet * Consectetur adipiscing elit * Integer molestie lorem at massa * Facilisis in pretium nisl aliquet * Nulla volutpat aliquam velit * Phasellus iaculis neque * Purus sodales ultricies * Vestibulum laoreet porttitor sem * Ac tristique libero volutpat at * Faucibus porta lacus fringilla vel * Aenean sit amet erat nunc * Eget porttitor lorem The rendered output looks like this: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Phasellus iaculis neque Purus sodales ultricies Vestibulum laoreet porttitor sem Ac tristique libero volutpat at Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem The HTML looks like this: \u003cul\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit \u003cul\u003e \u003cli\u003ePhasellus iaculis neque\u003c/li\u003e \u003cli\u003ePurus sodales ultricies\u003c/li\u003e \u003cli\u003eVestibulum laoreet porttitor sem\u003c/li\u003e \u003cli\u003eAc tristique libero volutpat at\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ul\u003e ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:8:1","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Ordered A list of items in which the order of items does explicitly matter. 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa 4. Facilisis in pretium nisl aliquet 5. Nulla volutpat aliquam velit 6. Faucibus porta lacus fringilla vel 7. Aenean sit amet erat nunc 8. Eget porttitor lorem The rendered output looks like this: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem The HTML looks like this: \u003col\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit\u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ol\u003e Tip If you just use 1. for each number, Markdown will automatically number each item. For example: 1. Lorem ipsum dolor sit amet 1. Consectetur adipiscing elit 1. Integer molestie lorem at massa 1. Facilisis in pretium nisl aliquet 1. Nulla volutpat aliquam velit 1. Faucibus porta lacus fringilla vel 1. Aenean sit amet erat nunc 1. Eget porttitor lorem The rendered output looks like this: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:8:2","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Task Lists Task lists allow you to create a list of items with checkboxes. To create a task list, add dashes (-) and brackets with a space ([ ]) before task list items. To select a checkbox, add an x in between the brackets ([x]). The rendered output looks like this: Write the press release Update the website Contact the media ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:8:3","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"9 Code ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:9:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Inline Code Wrap inline snippets of code with `. In this example, `\u003csection\u003e\u003c/section\u003e` should be wrapped as **code**. The rendered output looks like this: In this example, \u003csection\u003e\u003c/section\u003e should be wrapped as code. The HTML looks like this: \u003cp\u003e In this example, \u003ccode\u003e\u0026lt;section\u0026gt;\u0026lt;/section\u0026gt;\u003c/code\u003e should be wrapped with \u003cstrong\u003ecode\u003c/strong\u003e. \u003c/p\u003e ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:9:1","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Indented Code Or indent several lines of code by at least four spaces, as in: // Some comments line 1 of code line 2 of code line 3 of code The rendered output looks like this: // Some comments line 1 of code line 2 of code line 3 of code The HTML looks like this: \u003cpre\u003e \u003ccode\u003e // Some comments line 1 of code line 2 of code line 3 of code \u003c/code\u003e \u003c/pre\u003e ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:9:2","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Block Fenced Code Use “fences” ``` to block in multiple lines of code with a language attribute. ```markdown Sample text here... ``` The HTML looks like this: \u003cpre language-html\u003e \u003ccode\u003eSample text here...\u003c/code\u003e \u003c/pre\u003e ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:9:3","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Syntax Highlighting GFMGitHub Flavored Markdown also supports syntax highlighting. To activate it, simply add the file extension of the language you want to use directly after the first code “fence”, ```js, and syntax highlighting will automatically be applied in the rendered HTML. For example, to apply syntax highlighting to JavaScript code: ```js grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; ``` The rendered output looks like this: grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; Note Syntax highlighting page in Hugo Docs introduces more about syntax highlighting, including highlight shortcode. ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:9:4","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"10 Tables Tables are created by adding pipes as dividers between each cell, and by adding a line of dashes (also separated by bars) beneath the header. Note that the pipes do not need to be vertically aligned. | Option | Description | | ------ | ----------- | | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | The rendered output looks like this: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. The HTML looks like this: \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eOption\u003c/th\u003e \u003cth\u003eDescription\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003edata\u003c/td\u003e \u003ctd\u003epath to data files to supply the data that will be passed into templates.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eengine\u003c/td\u003e \u003ctd\u003eengine to be used for processing templates. Handlebars is the default.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eext\u003c/td\u003e \u003ctd\u003eextension to be used for dest files.\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e Right or center aligned text Adding a colon on the right side of the dashes below any heading will right align text for that column. Adding colons on both sides of the dashes below any heading will center align text for that column. | Option | Description | |:------:| -----------:| | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | The rendered output looks like this: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:10:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"11 Links ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:11:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Basic Link \u003chttps://assemble.io\u003e \u003ccontact@revolunet.com\u003e [Assemble](https://assemble.io) The rendered output looks like this (hover over the link, there is no tooltip): https://assemble.io contact@revolunet.com Assemble The HTML looks like this: \u003ca href=\"https://assemble.io\"\u003ehttps://assemble.io\u003c/a\u003e \u003ca href=\"mailto:contact@revolunet.com\"\u003econtact@revolunet.com\u003c/a\u003e \u003ca href=\"https://assemble.io\"\u003eAssemble\u003c/a\u003e ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:11:1","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Add a Title [Upstage](https://github.com/upstage/ \"Visit Upstage!\") The rendered output looks like this (hover over the link, there should be a tooltip): Upstage The HTML looks like this: \u003ca href=\"https://github.com/upstage/\" title=\"Visit Upstage!\"\u003eUpstage\u003c/a\u003e ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:11:2","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"Named Anchors Named anchors enable you to jump to the specified anchor point on the same page. For example, each of these chapters: ## Table of Contents * [Chapter 1](#chapter-1) * [Chapter 2](#chapter-2) * [Chapter 3](#chapter-3) will jump to these sections: ## Chapter 1 \u003ca id=\"chapter-1\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 2 \u003ca id=\"chapter-2\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 3 \u003ca id=\"chapter-3\"\u003e\u003c/a\u003e Content for chapter one. Note The specific placement of the anchor tag seems to be arbitrary. They are placed inline here since it seems to be unobtrusive, and it works. ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:11:3","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"12 Footnotes Footnotes allow you to add notes and references without cluttering the body of the document. When you create a footnote, a superscript number with a link appears where you added the footnote reference. Readers can click the link to jump to the content of the footnote at the bottom of the page. To create a footnote reference, add a caret and an identifier inside brackets ([^1]). Identifiers can be numbers or words, but they can’t contain spaces or tabs. Identifiers only correlate the footnote reference with the footnote itself — in the output, footnotes are numbered sequentially. Add the footnote using another caret and number inside brackets with a colon and text ([^1]: My footnote.). You don’t have to put footnotes at the end of the document. You can put them anywhere except inside other elements like lists, block quotes, and tables. This is a digital footnote[^1]. This is a footnote with \"label\"[^label] [^1]: This is a digital footnote [^label]: This is a footnote with \"label\" This is a digital footnote1. This is a footnote with “label”2 ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:12:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["Blog"],"content":"13 Images Images have a similar syntax to links but include a preceding exclamation point. ![Minion](https://octodex.github.com/images/minion.png) or: ![Alt text](https://octodex.github.com/images/stormtroopocat.jpg \"The Stormtroopocat\") The Stormtroopocat Like links, images also have a footnote style syntax: ![Alt text][id] The Dojocat With a reference later in the document defining the URL location: [id]: https://octodex.github.com/images/dojocat.jpg \"The Dojocat\" This is a digital footnote ↩︎ This is a footnote with “label” ↩︎ ","date":"2020-12-12","objectID":"/basic-markdown-syntax/:13:0","tags":["Documentation","Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"}]